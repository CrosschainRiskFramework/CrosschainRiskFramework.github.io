{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#introduction","title":"Introduction","text":"<p>With several layer-one protocols gaining meaningful traction over the last few years and layer-two protocols taking center stage in the scalability roadmap for Ethereum, it is increasingly becoming clear that the future will be multichain. This thesis is further reinforced by emerging patterns such as modular blockchains, application-specific chains, and fractal scaling. A multichain world is one in which disparate chains co-exist as thriving ecosystems. </p> <p>In the absence of a countervailing force, the proliferation of chains would naturally lead to increased fragmentation and the siloing of ecosystems. Crosschain protocols directly address this problem by enabling interoperation across distinct chains. They reduce fragmentation, enable scalability, and improve market efficiency. In addition, such protocols potentially open up new design spaces for novel crosschain native applications and use cases. Hence, crosschain protocols have emerged as a crucial building block enabling the multichain future. </p> <p>The growth and adoption of such protocols over the last couple of years have been astounding. The total value locked in token bridges on Ethereum alone, which only offers a partial picture of the scale of adoption of such protocols, reached a high of US$27B in late 2021. There are currently numerous crosschain-focused projects and significant venture capital funding backing such efforts.</p> <p>The flip side to this rapid growth and adoption has been the slew of high-profile hacks and failures of these protocols. Between 2021 and 2022, more than US$2.5B was stolen in bridge hacks, which is more than two-thirds of all DeFI hacks in that period. In addition, roughly US$1B was at risk from vulnerabilities discovered in such protocols. The knock-on effects of these failures included extended disruptions to underlying chains and increased regulatory scrutiny. Overall, these events have undermined confidence in crosschain infrastructure and the viability of a multichain future. They have also highlighted shortcomings in how crosschain protocols are designed, built, and operated today and the need to understand their risks and challenges better.</p> <p>To this end, this document provides a high-level systematic overview of the security risks in crosschain protocols by identifying, classifying, and analyzing the risk elements inherent in the design, implementation, and operation of such infrastructure. In addition, it offers a set of risk controls and best practices to mitigate the likelihood and severity of risks. While this document provides a general toolkit for reasoning about crosschain protocols, it does not directly analyze individual protocols. </p> <p>While this document is still a work in progress, its ultimate objective is to enable progress toward more secure, robust, and decentralized crosschain protocols that can serve as solid foundations for a multichain future. We highly encourage contributions and feedback from the community towards this end.</p>"},{"location":"#types-of-crosschain-interaction","title":"Types of Crosschain Interaction","text":"<p>Broadly defined, crosschain protocols enable the exchange of data and value across chains through one of the following three types of interactions:</p>"},{"location":"#asset-exchange","title":"Asset Exchange","text":"<p>Asset Exchange involves coordinating the transfer of ownership of an asset in one network with a corresponding transfer of ownership in another. This enables two or more parties to swap assets across networks under pre-agreed exchange terms.</p>"},{"location":"#asset-transfer","title":"Asset Transfer","text":"<p>Asset Transfer involves moving the value of an asset from a source ledger to a destination ledger. It enables assets in one network to be used inside applications in another. For instance, a user might want to transfer her ETH from Ethereum to Avalanche so she can use it as collateral in a lending protocol on Avalanche. This typically involves locking an asset in the source ledger and minting a synthetic representation on the destination ledger.</p>"},{"location":"#general-purpose-messaging","title":"General-purpose Messaging","text":"<p>General-purpose messaging refers to the communication of any data across chains. It can enable asset exchanges and transfers but also orchestrate complex application behavior across chains for a broad range of use cases. Examples include coordinating and managing DAO governance and actions across chains. </p>"},{"location":"#stakeholders","title":"Stakeholders","text":"<p>Crosschain protocols can have several distinct stakeholders with direct or indirect involvement in the system. These stakeholders can be individuals, groups, or organizations and have different roles, constraints, goals, and incentives. Consequently, the types and magnitudes of risk borne by each stakeholder might vary considerably across protocols. Understanding the dynamics of crosschain risk from the perspective of different actors will aid in a more sound analysis. To this end, we identify the main stakeholders in crosschain protocols below:</p>"},{"location":"#users","title":"Users","text":"<p>Users are the primary customers of the service offered by a crosschain protocol. They interact with the system directly to exchange assets or transfer data and value across chains. A user might directly interface with a crosschain protocol (e.g., token bridge) or through an intermediary application. A user's involvement with a protocol is typically short-lived and ends once their crosschain transaction has settled.</p>"},{"location":"#liquidity-providers","title":"Liquidity Providers","text":"<p>In a crosschain asset exchange, a liquidity provider is the counter-party to a user. For a fee, it exchanges its assets in one network for a user's assets in another. It might compete with other liquidity providers to offer this service and have defined performance and service-level constraints in its operations. Liquidity providers typically maintain longer exposure to the risks of a protocol and might also need to account for market-related risks beyond protocol risks.  </p>"},{"location":"#bridge-wrapped-token-holders","title":"Bridge-wrapped Token Holders","text":"<p>A common approach to enabling the transfer of assets from one chain to another is through a lock-and-mint mechanism, in which crosschain protocols lock assets on one network and mint corresponding synthetic assets on another. These synthetic assets are, in effect, a liability of the bridge that can later be redeemed for the underlying asset. We refer to any entity that holds such synthetic assets as a bridge token holder. A bridge token holder might or might not be a user of a crosschain protocol. More importantly, such stakeholders are exposed to the idiosyncratic risks of a protocol so long as they hold the asset. If a protocol's underlying assets are compromised the corresponding synthetic assets could lose some or all of their value.</p>"},{"location":"#bridge-validators","title":"Bridge Validators","text":"<p>Crosschain protocols typically coordinate several off-chain systems and actors that collectively ensure the integrity of state communication across chains. Such entities might be responsible for verifying, validating, proving, attesting, or relaying crosschain states. How different protocols coordinate and incentivize such actors to offer specific security properties varies significantly. However, in general, bridge validators are the primary entities that ensure the security and continued operation of a crosschain protocol and thus represent a significant source of potential risk to the overall system.</p>"},{"location":"#bridge-operators","title":"Bridge Operators","text":"<p>Bridge operators are actors that can update or reconfigure key elements of a crosschain protocol (e.g., upgrading on-chain smart contracts, updating validator registries, or moving contract funds). How many bridge operators a protocol has, what they are allowed to change and what policies govern their actions can significantly influence the risk profile of a protocol and varies considerably across projects.</p>"},{"location":"#bridge-developers","title":"Bridge Developers","text":"<p>Bridge developers design, build, test, and maintain the codebase behind a crosschain protocol. Given the complex nature of such systems, the possibility of introducing bugs and vulnerabilities is considerable. The experience and competence of such teams, their development practices, and the policies and procedures they put in place to respond to incidents significantly influence a protocol's level of implementation risk.</p> <p>In addition to the direct stakeholders discussed above, crosschain protocols also have indirect stakeholders. These entities have interest in or influence over the security and efficacy of crosschain protocols, even though they might not directly interact with them. Indirect stakeholders include: </p> <ul> <li> <p>Blockchain Network Participants: Recent bridge hacks have shown how failures in crosschain protocols can cause significant disruptions and halts of the underlying blockchains, impacting all network participants. </p> </li> <li> <p>Crosschain Applications: Applications built atop crosschain protocols have independent economic value that could influence the security of the underlying bridge. In addition, they have their own stakeholders that are impacted by the operations of the crosschain protocol.</p> </li> <li> <p>Bridge Protocol Investors: Investors of bridge protocols can directly or indirectly influence the operations and security of a protocol. For instance, the security guarantees of Proof-of-Stake bridges depend on the value of the bridge tokens staked. The market actions of investors could significantly influence the price of these tokens and consequently the security of the bridge.</p> </li> </ul> <p>For brevity, the rest of this document primarily focuses only on direct stakeholders of crosschain protocols.</p>"},{"location":"#security-risks","title":"Security Risks","text":"<p>At its essence, crosschain communication creates a dependency relationship between two or more networks. Such dependency relationships typically involve state change in one network driving state change in another. These relationships can be unidirectional or bidirectional, transient or persistent. The goal of crosschain protocols is to enable and guarantee the integrity of these dependencies. Specifically, given two networks, a source, and a destination, where the state in the destination network is dependent on the state in the source network, crosschain protocols must guarantee the following core security properties:</p> <ol> <li>Only states that are valid and final in the source network are communicated to the destination network</li> <li>All relevant state transitions in the source network are relayed to the destination network in a timely manner</li> <li>Any invariants that emerge from the crosschain interactions are preserved</li> </ol> <p>This document primarily discusses and assesses the risk of crosschain protocols by considering factors that affect these core security requirements. </p>"},{"location":"authors/authors/","title":"Authors","text":""},{"location":"authors/authors/#authors","title":"Authors","text":"<p>This document builds on a lot of excellent prior work by numerous authors. A list of the essential references used in the creation of this framework can be found here. </p> <p>The authors of the content on this website as at January 27 2023 are listed below. The order is roughly based on the level of direct contributions to the document. While the list is updated periodically to reflect the state of contributions to the document, a more up-to-date list of contributors can always be found on Github. The initial commits by Peter Robinson were based on a Google Doc co-authored by Ermyas Abebe and Peter Robinson.</p> Name Preferred contact method Links Ermyas Abebe Telegram Peter Robinson Telegram Arjun Chand Telegram Mark Murdock Telegram David Hyland-Wood Telegram <p>If you are interested in contributing please refer to the How to Contribute section of this document.</p>"},{"location":"authors/code-of-conduct/","title":"Code of conduct","text":""},{"location":"authors/code-of-conduct/#code-of-conduct","title":"Code of Conduct","text":"<p>The Crosschain Risk Framework community consists of its online presence  in this website and associated GitHub repository. These outlets are managed  by the Crosschain Risk Framework Management Committee, whose members are  listed in the Management Committee section of this site.</p> <p>We strive to be an open and inclusive community where anyone can contribute.  Contributions should be judged on their own merits; we don\u2019t care about your  gender identity, race, political beliefs, age, or similar attributes.</p> <p>If we see that one or more members of the community are generally abusive,  harassing others, or seem to be trying to intimidate them into leaving  the community, we will first ask those who are doing so to take a break  from participation for a while. If you see any evidence of such activity,  please let us know by contacting the Management Committee via Telegram.</p>"},{"location":"authors/committee/","title":"Committee","text":""},{"location":"authors/committee/#management-committee","title":"Management Committee","text":"<p>The management committee for this website / repo is shown below. Please use Telegram to contact them.</p> Name Affiliation Preferred contact method Links Arjun Chand LI.FI Telegram Ermyas Abebe - Telegram Mark Murdock LI.FI Telegram Max Klenk LI.FI Telegram Peter Robinson - Telegram Vaibhav Chellani Socket Telegram"},{"location":"authors/contributing/","title":"Contributing","text":""},{"location":"authors/contributing/#how-to-contribute","title":"How to Contribute","text":"<p>Development is done on GitHub in the https://github.com/CrosschainRiskFramework/CrosschainRiskFramework.github.io repository.</p> <p>To add content, request new features or report issues, please open an issue on GitHub.</p> <p>To submit a patch, please open a pull request on GitHub. If you  are thinking of making a large contribution, open an issue for  it before starting work, to get comments from the community.  Someone may be already working on the same thing, or there  may be reasons why that feature isn't implemented.</p> <p>To make it easier to review and accept your pull request, please  follow these guidelines:</p> <ul> <li> <p>Anything other than a trivial contribution requires a Contributor    License Agreement (CLA), giving us permission to use your code. If    your contribution is too small to require a CLA (e.g. fixing a    spelling mistake), place the text \"CLA: trivial\" on a line by itself    separated by an empty line from the rest of the commit message. It is    not sufficient to only place the text in the GitHub pull request    description.</p> </li> <li> <p>To amend a missing \"CLA: trivial\" line after submission, do the following:</p> <p>git commit --amend [add the line, save and quit the editor] git push -f</p> </li> <li> <p>Patches should be as current as possible; expect to have to rebase often. We    do not accept merge commits, you will have to remove them (usually by    rebasing) before it will be acceptable.</p> </li> <li> <p>Clean builds via GitHub Actions are required, and they are started automatically whenever a PR is created or updated.</p> </li> </ul>"},{"location":"authors/contributions/","title":"Authors and Contributing","text":""},{"location":"authors/contributions/#authors","title":"Authors","text":"<p>This document builds on a lot of excellent prior work by numerous authors. A list of the essential references used in the creation of this framework can be found here. </p> <p>The authors of the content on this website as at January 27 2023 are listed below. The order is roughly based on the level of direct contributions to the document. While the list is updated periodically to reflect the state of contributions to the document, a more up-to-date list of contributors can always be found on Github. The initial commits by Peter Robinson were based on a Google Doc co-authored by Ermyas Abebe and Peter Robinson.</p> Name Preferred contact method Links Ermyas Abebe Telegram Peter Robinson Telegram Arjun Chand Telegram Mark Murdock Telegram David Hyland-Wood Telegram <p>If you are interested in contributing please refer to the How to Contribute section of this document.</p>"},{"location":"authors/contributions/#management-committee","title":"Management Committee","text":"<p>The management committee for this website / repo is shown below. Please use Telegram to contact them.</p> Name Affiliation Preferred contact method Links Arjun Chand LI.FI Telegram Ermyas Abebe - Telegram Mark Murdock LI.FI Telegram Max Klenk LI.FI Telegram Peter Robinson - Telegram Vaibhav Chellani Socket Telegram"},{"location":"authors/contributions/#code-of-conduct","title":"Code of Conduct","text":"<p>The Crosschain Risk Framework community consists of its online presence  in this website and associated GitHub repository. These outlets are managed  by the Crosschain Risk Framework Management Committee, whose members are  listed in the Management Committee section of this site.</p> <p>We strive to be an open and inclusive community where anyone can contribute.  Contributions should be judged on their own merits; we don\u2019t care about your  gender identity, race, political beliefs, age, or similar attributes.</p> <p>If we see that one or more members of the community are generally abusive,  harassing others, or seem to be trying to intimidate them into leaving  the community, we will first ask those who are doing so to take a break  from participation for a while. If you see any evidence of such activity,  please let us know by contacting the Management Committee via Telegram.</p>"},{"location":"authors/contributions/#how-to-contribute","title":"How to Contribute","text":"<p>Development is done on GitHub in the https://github.com/CrosschainRiskFramework/CrosschainRiskFramework.github.io repository.</p> <p>To add content, request new features or report issues, please open an issue on GitHub.</p> <p>To submit a patch, please open a pull request on GitHub. If you  are thinking of making a large contribution, open an issue for  it before starting work, to get comments from the community.  Someone may be already working on the same thing, or there  may be reasons why that feature isn't implemented.</p> <p>To make it easier to review and accept your pull request, please  follow these guidelines:</p> <ul> <li> <p>Anything other than a trivial contribution requires a Contributor    License Agreement (CLA), giving us permission to use your code. If    your contribution is too small to require a CLA (e.g. fixing a    spelling mistake), place the text \"CLA: trivial\" on a line by itself    separated by an empty line from the rest of the commit message. It is    not sufficient to only place the text in the GitHub pull request    description.</p> </li> <li> <p>To amend a missing \"CLA: trivial\" line after submission, do the following:</p> <p>git commit --amend [add the line, save and quit the editor] git push -f</p> </li> <li> <p>Patches should be as current as possible; expect to have to rebase often. We    do not accept merge commits, you will have to remove them (usually by    rebasing) before it will be acceptable.</p> </li> <li> <p>Clean builds via GitHub Actions are required, and they are started automatically whenever a PR is created or updated.</p> </li> </ul>"},{"location":"comparison/comparison/","title":"Comparison","text":"<p>Nothing here yet.</p>"},{"location":"faq/faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/faq/#how-can-i-contribute","title":"How can I contribute?","text":"<p>Please submit a pull request to the  repo behind this website</p>"},{"location":"faq/faq/#crosschain-cross-chain-or-crosschain","title":"Crosschain, Cross-chain, or CrossChain?","text":"<p>Blockchain is written blockchain and not BlockChain or block-chain. To  be consistent, we feel communications across blockchains should  be known as crosschain.</p>"},{"location":"faq/faq/#what-is-a-network","title":"What is a Network?","text":"<p>The term network is used throughout this website to mean a blockchain, a sidechain, a rollup, or  some other blockchain-like system. </p>"},{"location":"framework/01intro/introduction/","title":"Introduction","text":"<p>With several layer-one protocols gaining meaningful traction over the last few years and layer-two protocols taking center stage in the scalability roadmap for Ethereum, it is increasingly becoming clear that the future will be multichain. This thesis is further reinforced by emerging patterns such as modular blockchains, application-specific chains, and fractal scaling. A multichain world is one in which disparate chains co-exist as thriving ecosystems. </p> <p>In the absence of a countervailing force, the proliferation of chains would naturally lead to increased fragmentation and the siloing of ecosystems. Crosschain protocols directly address this problem by enabling interoperation across distinct chains. They reduce fragmentation, enable scalability, and improve market efficiency. In addition, such protocols potentially open up new design spaces for novel crosschain native applications and use cases. Hence, crosschain protocols have emerged as a crucial building block enabling the multichain future. </p> <p>The growth and adoption of such protocols over the last couple of years have been astounding. The total value locked in token bridges on Ethereum alone, which only offers a partial picture of the scale of adoption of such protocols, reached a high of US$27B in late 2021. There are currently numerous crosschain-focused projects and significant venture capital funding backing such efforts.</p> <p>The flip side to this rapid growth and adoption has been the slew of high-profile hacks and failures of these protocols. Between 2021 and 2022, more than US$2.5B was stolen in bridge hacks, which is more than two-thirds of all DeFI hacks in that period. In addition, roughly US$1B was at risk from vulnerabilities discovered in such protocols. The knock-on effects of these failures included extended disruptions to underlying chains and increased regulatory scrutiny. Overall, these events have undermined confidence in crosschain infrastructure and the viability of a multichain future. They have also highlighted shortcomings in how crosschain protocols are designed, built, and operated today and the need to understand their risks and challenges better.</p> <p>To this end, this document provides a high-level systematic overview of the security risks in crosschain protocols by identifying, classifying, and analyzing the risk elements inherent in the design, implementation, and operation of such infrastructure. In addition, it offers a set of risk controls and best practices to mitigate the likelihood and severity of risks. While this document provides a general toolkit for reasoning about crosschain protocols, it does not directly analyze individual protocols. </p> <p>While this document is still a work in progress, its ultimate objective is to enable progress toward more secure, robust, and decentralized crosschain protocols that can serve as solid foundations for a multichain future. We highly encourage contributions and feedback from the community towards this end.</p>"},{"location":"framework/01intro/introduction/#types-of-crosschain-interaction","title":"Types of Crosschain Interaction","text":"<p>Broadly defined, crosschain protocols enable the exchange of data and value across chains through one of the following three types of interactions:</p>"},{"location":"framework/01intro/introduction/#asset-exchange","title":"Asset Exchange","text":"<p>Asset Exchange involves coordinating the transfer of ownership of an asset in one network with a corresponding transfer of ownership in another. This enables two or more parties to swap assets across networks under pre-agreed exchange terms.</p>"},{"location":"framework/01intro/introduction/#asset-transfer","title":"Asset Transfer","text":"<p>Asset Transfer involves moving the value of an asset from a source ledger to a destination ledger. It enables assets in one network to be used inside applications in another. For instance, a user might want to transfer her ETH from Ethereum to Avalanche so she can use it as collateral in a lending protocol on Avalanche. This typically involves locking an asset in the source ledger and minting a synthetic representation on the destination ledger.</p>"},{"location":"framework/01intro/introduction/#general-purpose-messaging","title":"General-purpose Messaging","text":"<p>General-purpose messaging refers to the communication of any data across chains. It can enable asset exchanges and transfers but also orchestrate complex application behavior across chains for a broad range of use cases. Examples include coordinating and managing DAO governance and actions across chains. </p>"},{"location":"framework/01intro/introduction/#stakeholders","title":"Stakeholders","text":"<p>Crosschain protocols can have several distinct stakeholders with direct or indirect involvement in the system. These stakeholders can be individuals, groups, or organizations and have different roles, constraints, goals, and incentives. Consequently, the types and magnitudes of risk borne by each stakeholder might vary considerably across protocols. Understanding the dynamics of crosschain risk from the perspective of different actors will aid in a more sound analysis. To this end, we identify the main stakeholders in crosschain protocols below:</p>"},{"location":"framework/01intro/introduction/#users","title":"Users","text":"<p>Users are the primary customers of the service offered by a crosschain protocol. They interact with the system directly to exchange assets or transfer data and value across chains. A user might directly interface with a crosschain protocol (e.g., token bridge) or through an intermediary application. A user's involvement with a protocol is typically short-lived and ends once their crosschain transaction has settled.</p>"},{"location":"framework/01intro/introduction/#liquidity-providers","title":"Liquidity Providers","text":"<p>In a crosschain asset exchange, a liquidity provider is the counter-party to a user. For a fee, it exchanges its assets in one network for a user's assets in another. It might compete with other liquidity providers to offer this service and have defined performance and service-level constraints in its operations. Liquidity providers typically maintain longer exposure to the risks of a protocol and might also need to account for market-related risks beyond protocol risks.  </p>"},{"location":"framework/01intro/introduction/#bridge-wrapped-token-holders","title":"Bridge-wrapped Token Holders","text":"<p>A common approach to enabling the transfer of assets from one chain to another is through a lock-and-mint mechanism, in which crosschain protocols lock assets on one network and mint corresponding synthetic assets on another. These synthetic assets are, in effect, a liability of the bridge that can later be redeemed for the underlying asset. We refer to any entity that holds such synthetic assets as a bridge token holder. A bridge token holder might or might not be a user of a crosschain protocol. More importantly, such stakeholders are exposed to the idiosyncratic risks of a protocol so long as they hold the asset. If a protocol's underlying assets are compromised the corresponding synthetic assets could lose some or all of their value.</p>"},{"location":"framework/01intro/introduction/#bridge-validators","title":"Bridge Validators","text":"<p>Crosschain protocols typically coordinate several off-chain systems and actors that collectively ensure the integrity of state communication across chains. Such entities might be responsible for verifying, validating, proving, attesting, or relaying crosschain states. How different protocols coordinate and incentivize such actors to offer specific security properties varies significantly. However, in general, bridge validators are the primary entities that ensure the security and continued operation of a crosschain protocol and thus represent a significant source of potential risk to the overall system.</p>"},{"location":"framework/01intro/introduction/#bridge-operators","title":"Bridge Operators","text":"<p>Bridge operators are actors that can update or reconfigure key elements of a crosschain protocol (e.g., upgrading on-chain smart contracts, updating validator registries, or moving contract funds). How many bridge operators a protocol has, what they are allowed to change and what policies govern their actions can significantly influence the risk profile of a protocol and varies considerably across projects.</p>"},{"location":"framework/01intro/introduction/#bridge-developers","title":"Bridge Developers","text":"<p>Bridge developers design, build, test, and maintain the codebase behind a crosschain protocol. Given the complex nature of such systems, the possibility of introducing bugs and vulnerabilities is considerable. The experience and competence of such teams, their development practices, and the policies and procedures they put in place to respond to incidents significantly influence a protocol's level of implementation risk.</p> <p>In addition to the direct stakeholders discussed above, crosschain protocols also have indirect stakeholders. These entities have interest in or influence over the security and efficacy of crosschain protocols, even though they might not directly interact with them. Indirect stakeholders include: </p> <ul> <li> <p>Blockchain Network Participants: Recent bridge hacks have shown how failures in crosschain protocols can cause significant disruptions and halts of the underlying blockchains, impacting all network participants. </p> </li> <li> <p>Crosschain Applications: Applications built atop crosschain protocols have independent economic value that could influence the security of the underlying bridge. In addition, they have their own stakeholders that are impacted by the operations of the crosschain protocol.</p> </li> <li> <p>Bridge Protocol Investors: Investors of bridge protocols can directly or indirectly influence the operations and security of a protocol. For instance, the security guarantees of Proof-of-Stake bridges depend on the value of the bridge tokens staked. The market actions of investors could significantly influence the price of these tokens and consequently the security of the bridge.</p> </li> </ul> <p>For brevity, the rest of this document primarily focuses only on direct stakeholders of crosschain protocols.</p>"},{"location":"framework/01intro/introduction/#security-risks","title":"Security Risks","text":"<p>At its essence, crosschain communication creates a dependency relationship between two or more networks. Such dependency relationships typically involve state change in one network driving state change in another. These relationships can be unidirectional or bidirectional, transient or persistent. The goal of crosschain protocols is to enable and guarantee the integrity of these dependencies. Specifically, given two networks, a source, and a destination, where the state in the destination network is dependent on the state in the source network, crosschain protocols must guarantee the following core security properties:</p> <ol> <li>Only states that are valid and final in the source network are communicated to the destination network</li> <li>All relevant state transitions in the source network are relayed to the destination network in a timely manner</li> <li>Any invariants that emerge from the crosschain interactions are preserved</li> </ol> <p>This document primarily discusses and assesses the risk of crosschain protocols by considering factors that affect these core security requirements. </p>"},{"location":"framework/20categories/categories-of-risk/","title":"Categories of Risk","text":"<p>Crosschain protocols are generally complex systems that are exposed to numerous sources of risk. Classifying these risks enables better reasoning about the inherent limits and challenges of protocols and the considerations and mitigations of different risk factors. To this end, this section identifies four key categories of risk in crosschain communication:</p> <ul> <li> <p>Network Consensus Risk: One of the core security assumptions of crosschain communication is that the state communicated from one network to another is valid according to the consensus rules of the underlying network. Failures in the safety or liveness properties of an underlying network can thus risk creating inconsistent state changes across chains that cannot be reconciled. Such risks are often beyond the control boundary of crosschain infrastructure and likely represent a fundamental security limitation to bridging across independent sovereign chains. The impact of a failure of this type would simultaneously affect all bridges exposed to the underlying faulty network. However, risk controls can be enacted to limit the magnitude of such failures (e.g. containing and isolating the impact of failures in any single network).</p> </li> <li> <p>Protocol Architecture Risk: As will be discussed further in a subsequent section, crosschain protocols can be viewed through a layered architecture. The design assumptions and constraints under which protocols at each layer guarantee relevant security properties can be a source of significant risk. For instance, at the messaging layer, architectures that introduce new trusted parties often offer weaker guarantees than those that solely rely on the security of the underlying networks.</p> </li> <li> <p>Protocol Implementation Risk: Building crosschain protocols involves creating complex on-chain and off-chain components while accounting for the peculiarities and pitfalls of different programming languages, frameworks, virtual machines, and runtime environments. Inevitably, such complexity increases the likelihood of bugs and vulnerabilities. This type of risk has thus far been the most common cause of bridge hacks witnessed over the last couple of years.</p> </li> <li> <p>Protocol Operation Risk: The operation of a crosschain bridge involves the management of various components, potentially by distinct actors. Such activities could include the upgrade and management of bridge smart contracts and the operation of various off-chain systems (e.g. external validator nodes). Failures and oversights in these operational activities can present a significant source of risk to protocols. Having robust, secure, decentralized, and transparent mechanisms and processes for managing such systems is crucial to ensuring the security of crosschain bridges.</p> </li> </ul>"},{"location":"framework/20categories/10network/network/","title":"Network Consensus Risk","text":"<p>Crosschain protocols enable the coordination of state changes across networks. This typically requires sending state information from a source network to one or more destination networks and performing consequent state changes. A fundamental assumption in this process is that: a) states in the source network are valid and final according to its consensus rules, and b) the underlying network can process all transactions in a timely manner.</p> <p>From the perspective of risk in crosschain protocols, there are at least three considerations relating to these assumptions:</p> <ol> <li>Protocols should only communicate states that have been finalized in the source network</li> <li>Protocol security should be resilient to network liveness failures</li> <li>Protocols should mitigate the impact of network safety violations</li> </ol>"},{"location":"framework/20categories/10network/network/#transaction-finality","title":"Transaction Finality","text":"<p>A transaction that is irrevocably included in a ledger is considered final. What this means, in practice, is that reverting such a transaction would incur significant economic costs to a majority of validators, as to be considered highly improbable. How finality is achieved varies across networks and can either be probabilistic or deterministic. Networks with deterministic finality offer definite assurance about the permanence of the state of a network after some time. In contrast, probabilistic models offer only degrees of confidence, with increasing assurance attained over time. For deterministic models, finality could be instantly achieved after a single block or eventually after several blocks. </p> <p>Networks with slower finality times increase latency in crosschain communication, which impacts the customer experience. However, crosschain protocols must ensure that strong assurances about the finality of a given state are achieved before relaying it across chains. Crosschain protocols, which optimize for performance and relay information prematurely, risk creating inconsistencies across networks and the possible loss of a party's funds.</p>"},{"location":"framework/20categories/10network/network/#network-delays-and-liveness-failures","title":"Network Delays and Liveness Failures","text":"<p>Some crosschain protocols rely considerably on the underlying networks processing transactions within a given period. For instance, protocols might assume that fraud proofs can be delivered within a time window. Such protocols must account for aberrations in transaction latency caused by network congestions and delays. Moreover, some consensus protocols trade-off liveness for safety under certain conditions, halting for extended periods if a portion of their validators are offline or unreachable. </p>"},{"location":"framework/20categories/10network/network/#network-safety-violations","title":"Network Safety Violations","text":"<p>A fundamental problem for crosschain protocols connecting sovereign networks is a scenario in which a network experiences a significant state reversion. This could result from active network attacks (e.g., 51% attack), hard forks, or bugs in protocol implementations. The likelihood of such failures is higher in chains with fewer validators, lower economic security, or new consensus protocols. </p> <p>Such risks are often beyond the control boundary of crosschain infrastructure and affect all crosschain protocols connected to a network simultaneously. Hence, for crosschain protocols spanning independent networks, this likely represents a fundamental security limitation to the security guarantees that such protocols can offer. </p> <p>However, crosschain protocols can reduce the impact of such failure in one network by limiting its contagion to other chains. If a consensus failure in one network can cascade to affect all other chains, then the security of a bridge is dependent on its weakest link. Additionally, crosschain protocol builders should conduct adequate due diligence on the security and decentralisation properties of the networks they integrate.</p>"},{"location":"framework/20categories/20architecture/architecture/","title":"Protocol Architecture Risk","text":"<p>Risks that stem from the security properties, assumptions, trade-offs, and limitations of the design of a protocol are collectively referred to as Protocol Architecture Risks.  To methodically analyze protocol architecture risk, we first discuss a conceptual model for organizing crosschain protocols into layers of abstraction based on scope and functionality. The framework is primarily based on the work by L2Beat and Socket and is illustrated in the diagram below. In this framework, each layer depends on layers below it for functionality and security. Hence, the architectural risks at each layer subsume those below it. </p> <p> </p> Layers of Crosschain Communication Protocols"},{"location":"framework/20categories/20architecture/architecture/#messaging-protocol","title":"Messaging Protocol","text":"<p>Messaging protocols provide the following two foundational capabilities that are relied upon by crosschain applications built on top of them.</p> <ol> <li>Transmission of state information from a source network to a destination network in a timely manner</li> <li>Ensuring the validity and finality of any information sent from a source network to a destination network</li> </ol> <p>Messaging protocols must ensure the transmission of all crosschain messages (capability 1) while providing strong guarantees about their validity and finality (capability 2) in the source network. The former mainly highlights liveness and censorship resistance property, while the latter emphasizes safety. The architecture of crosschain protocols is largely differentiated by how they offer guarantees around safety. An ideal construction would introduce no additional trust assumptions beyond what is assumed about the underlying networks. For a message sent from a source network to a destination network, this would involve the destination networks independently:</p> <ol> <li>Validating that a state transition that resulted in a given message is valid according to the state transition rules of the source network and</li> <li>Verifying that the message has been finalized according to its consensus rules of the source network</li> </ol> <p>A protocol that performs one or both of the above verifications to ensure the validity of a remote network's state is considered trustless or trust-minimized. Conversely, a protocol that relies on intermediaries or a subset of network validators vouching for the validity of a remote state is considered trusted, or semi-trusted. In line with this, four broad architectural patterns are identified below. Not all crosschain protocols in the wild neatly fit into these categories, and some employ hybrid approaches. </p>"},{"location":"framework/20categories/20architecture/architecture/#state-validating-protocols","title":"State Validating Protocols","text":"<p>In State Validating Protocols, a destination chain independently verifies that any state it receives is valid and final according to the source network's state transition and consensus rules. This model inherits the security guarantees of the underlying networks without introducing new trust assumptions.  </p> <p>The only examples of such architecture, at present, are the native bridges between layer-one networks and their associated rollups (Optimistic and Zero-Knowledge rollups). In such models, there is, in effect, only a single source of truth, the state of the layer-one network. This is different from crosschain communication across independent layer-one networks. Hence, while this model offers significant security advantages, applying it across separate networks is currently not viable. However, with advances in Zero-Knowledge cryptography, this could change. Efforts such as stateless Ethereum focus on having succinct proofs of the network's state that clients can independently verify. An example of a protocol that offers similar properties is the Mina protocol. Such capabilities could eventually enable state-validating protocols across distinct layer-ones.</p> <p> </p> State Validating Crosschain Protocols <p>Considerations: While this approach offers strong security guarantees from a design perspective, it is worth noting that implementation and operational risks are still present.</p>"},{"location":"framework/20categories/20architecture/architecture/#consensus-verifying-protocols","title":"Consensus Verifying Protocols","text":"<p>In Consensus Verifying Protocols, a destination network independently verifies that a crosschain state has been finalized according to the consensus rules of the source chain. This is typically achieved by running the light-client protocol of the source chain on the destination chain.  Examples of this type of verification include checking that sufficient proof-of-work has been expended on a block, in the case of Proof-of-Work protocols, or that a quorum of network validators has signed a block in BFT-based protocols. Similar to State Validating protocols, this approach does not introduce new trust assumptions beyond what's employed by the underlying network protocols. </p> <p>However, light-client consensus verifications differ from the consensus verifications performed by full nodes and do not offer the same security guarantees. For instance, the Ethereum light-client protocol relies on verifying the attestations of a small subset of randomly selected validators, called the sync committee, in place of the complete Casper FFG consensus protocol employed by full nodes. Because of the smaller size of this validator set and the lack of slashing, this model offers relatively weaker security guarantees. In addition, unlike State Validating Protocols discussed above Consensus Verifying Protocols do not execute and verify the validity of transactions and hence offer lesser security.</p> <p>A significant constraint to the overall viability of such approaches is the complexity associated with building and maintaining such protocols and the costs associated with operating them. In addition, the cost of running such infrastructure is a function of the source network's block production rate rather than the demand for crosschain messaging. Hence, such bridges might need to charge high fees and gain significant usage to offset operational costs. </p> <p>There are two distinct models of such protocols based on whether the consensus verification is performed on-chain or off-chain. </p>"},{"location":"framework/20categories/20architecture/architecture/#on-chain-consensus-verification","title":"On-chain Consensus Verification","text":"<p>This model involves performing light-client verification of a source chain's consensus in the execution environment of the destination. First, block headers from a source network are sent to a destination network by off-chain actors called Relayers. The destination chain then performs consensus verification on the block, typically through logic implemented in a smart contract. A user can then prove that a state exists in the source network using a Merkle proof against the verified block header on the destination. This proof can then be used to trigger a subsequent transaction on the destination chain. </p> <p>Because of the constraints of most smart contract languages and blockchain execution environments, such models can be complicated to build and prohibitively expensive to operate (e.g., gas costs).</p> <p> </p> On-chain Consensus Verifying Protocols <p>Considerations:</p> <p>Safety:</p> <ul> <li>What are the security properties of the light-client protocols of the underlying networks?</li> <li>How does the protocol deal with the security limitations and potential attack vectors of the associated light-client protocols (e.g., Eclipse Attacks, Long-range attacks)? What is the likelihood of such attacks?</li> <li>How long can the bridge go without receiving new blocks before the bridge's security is affected?</li> <li>The increased complexity of building such protocols significantly increases implementation risk.</li> </ul> <p>Liveness:</p> <ul> <li>Is the role of relaying blocks across chains permissionless? If the role is permissioned, then Relayers can censor or delay transactions.</li> <li>What are the costs of operating the bridge? Are these sustainable under low-demand scenarios? </li> <li>What are the financial incentives for relayers? Given these entities incur network fees associated with relaying blocks to different destination networks, how are they compensated? Is this model sustainable?</li> </ul> <p>Other:</p> <ul> <li>Can the on-chain implementation adapt to changes in the source network's consensus protocol? What are there challenges and constraints to making such changes?</li> </ul>"},{"location":"framework/20categories/20architecture/architecture/#validity-proof-based-consensus-verification","title":"Validity-Proof based Consensus Verification","text":"<p>In this model, an off-chain system called a Prover generates a SNARK proof that a state in a source network has been finalized according to its consensus protocol. The proof is sent to a destination chain, which then verifies its validity using logic implemented in a smart contract (Verifier). Hence, this model shifts most of the complexity and cost of performing light-client consensus verification off-chain while retaining the security advantages of crosschain consensus verification.</p> <p>These types of bridges are also referred to as Zero-knowledge Bridges (ZK Bridges). However, this terminology is misleading, as such protocols rely only on the succinctness properties of SNARKs and do not apply information hiding (i.e., Zero-knowledge).</p> <p> </p> Validaity Proof Protocols (ZK Bridges) <p>Considerations:</p> <p>The same considerations as those laid out for On-chain Consensus Verification schemes apply to these protocols. Additional considerations include:</p> <p>Safety:</p> <ul> <li>What are the trusted setup assumptions of the underlying cryptographic mechanisms? </li> <li>The increased complexity of building such protocols increases implementation risk.</li> </ul> <p>Liveness:</p> <ul> <li>Is the role of prover permissionless? If not, how many provers are there? What are the criteria for becoming a prover? How are they coordinated? <ul> <li>Provers can technically censor transactions or become a source of liveness issues for the network</li> <li>Carrying out an eclipse attack against a single prover is more tractable than several provers</li> <li>How are provers incentivized?</li> <li>The computations performed by a prover can be expensive, which might discourage participation.</li> </ul> </li> </ul>"},{"location":"framework/20categories/20architecture/architecture/#third-party-attestation-protocols","title":"Third-party Attestation Protocols","text":"<p>The above approaches derive their security guarantees from the underlying chains because they involve each chain locally verifying, to some extent, the validity of the state from another chain. This avoids introducing additional trust assumptions and offers better security guarantees. However, such protocols are complex and costly to build, operate, and scale across diverse ecosystems. </p> <p>Hence, most crosschain protocols introduce intermediary sources of trust in the form of third-party attestors (also referred to as validators). These third-party attestors attest to the validity of crosschain messages from a source network and then send them to a destination network. A destination network accepts as valid any state that is certified by a majority of the trusted third-party attestors. Hence the safety and liveness properties of such protocols rely on a threshold of honest attestors (M of N security model).</p> <p> </p> Third-party Attestation Protocols <p> </p> Third-party Attestation Protocols with Intermediary Network <p>Protocols in this category vary widely on at least the following three dimensions:</p> <ol> <li>Coordination mechanism: Off-chain communication, Dedicated intermediary network</li> <li>Cryptographic mechanism: Multi-Signature, Threshold signature, Trusted Execution Environment (e.g., Intel SGX)</li> <li>Security model (Proof-of-Authority, Proof-of-Stake)</li> </ol> <p>The security model of these protocols defines the security properties of and assumptions about the third-party attestors.  There are generally two models, Proof-of-Authority and Proof-of-Stake, which are further discussed below.</p>"},{"location":"framework/20categories/20architecture/architecture/#proof-of-authority","title":"Proof-of-Authority","text":"<p>Proof-of-Authority models rely on reputable legal entities serving as attestors. These bridges assume that a) such parties are strongly incentivized to maintain their reputation and would thus not act maliciously and b) that in the event of misbehavior, stakeholders can pursue legal recourse against such entities. These assumptions are difficult to reason about and rely on external structural assurances (e.g., legal systems) instead of internal protocol mechanisms.</p> <p>Considerations:</p> <p>Safety:</p> <ul> <li>How many distinct attestors does the protocol have? What are the specific honesty threshold assumptions for guaranteeing safety and liveness? What are the particular characteristics of the cryptographic schemes used?</li> <li>How reputable are these entities? How important are trust and reputation to the operation of the businesses of these entities?</li> <li>Are there contractual terms governing the operation of these entities? In what jurisdictions are the entities domiciled?</li> <li>How do the above disincentives to misbehavior compare against the TVL or total volume transacted by layers atop the messaging bridge?</li> <li>Can the claims around decentralization be verified on-chain? For instance: <ul> <li>The number of validators and the threshold for achieving a quorum. Multi-signature schemes are easier to verify on-chain compared to MPC or threshold signature schemes. </li> <li>The active validator set. While a bridge might employ many validators, it is possible that only a few actively participate in validating and attesting to messages. This could be because the economics of validating messages are not worthwhile to some validators. This means that the effective validator set is smaller, and the decentralization and security guarantees of the bridge weaker. The Ronin bridge hack highlights an example of this scenario.</li> </ul> </li> </ul> <p>Liveness:</p> <ul> <li>Can regulations coerce these entities to censor transactions?</li> <li>Do such entities have competing interests with users of this bridge? e.g., Trading firms that might benefit from cross-domain MEV?</li> </ul>"},{"location":"framework/20categories/20architecture/architecture/#proof-of-stake","title":"Proof-of-Stake","text":"<p>Proof-of-Stake models rely on validators having financial incentives to behave honestly according to the rules of the protocol. This is typically achieved by having each validator stake funds in the protocol that can be slashed if the validator misbehaves. Unlike proof-of-authority schemes, this offers an immediate and in-protocol method of punishing malicious behavior. </p> <p>Considerations:</p> <p>Safety:</p> <ul> <li>How many distinct attestors does the protocol have? What are the specific thresholds for guaranteeing safety and liveness? What are the particular characteristics of the cryptographic schemes used?</li> <li>Can the claims around decentralization be verified on-chain? For instance: <ul> <li>The distribution of staked tokens across validators (i.e., concentrated amongst few parties vs. diffuse across many parties)</li> <li>The number of validators and the threshold for achieving a quorum (multi-signature schemes might be easier to verify on-chain than threshold signature schemes). </li> <li>The active validator set. While a bridge might employ many validators, it is possible that only a few actively participate in validating and attesting to messages. </li> </ul> </li> <li>What exactly is staked by validators? Is it a bridge-specific token? What are the dynamics that drive the value of such tokens? How liquid is the token?</li> <li>How does the value of staked funds compare against the volume of assets transacted across the bridge?</li> <li>What is the cost of bribing or corrupting a threshold of such validators to violate safety or liveness?</li> <li>How does the bridge adapt to active misbehavior by a portion of the validators?</li> </ul> <p>Liveness:</p> <ul> <li>Can regulations coerce these entities to censor transactions?</li> <li>Do such entities have competing interests with users of this bridge? e.g., Trading firms that might benefit from cross-domain MEV?</li> </ul>"},{"location":"framework/20categories/20architecture/architecture/#optimistic-protocols","title":"Optimistic Protocols","text":"<p>Optimistic crosschain protocols rely on two types of bridge validators, Attestors and Watchers. These validators have different names in different protocols. Attestors certify the validity of crosschain messages from a source network and submit them to destination networks. Attestors lock some stake in the source network that can be slashed in the case of proveable misbehavior. Watchers observe these attestations on-chain and submit fraud proofs within a time window if they are invalid. If invalid attestations are submitted, the responsible attestors are slashed, and the watcher that reported the fraud is rewarded. The Watcher role can either be permissioned or permissionless. </p> <p>Such bridges assume that: a) attestors are incentivized to sign only legitimate transactions because their bonded funds will be slashed if not, b) if an attestor signs a fraudulent transaction, at least one honest watcher will report the fraud within the allotted fraud window, and c) watchers are disincentivized from submitting invalid fraud reports. </p> <p>Thus, optimistic bridges have a 1 of N security model, which relies on one honest actor watching the system to verify crosschain transactions correctly. A large number of active watchers increases the security of such protocols. An ideal construction of such a protocol involves a permissionless watcher set. Such a model would make it difficult for an attacker to bribe a set of known watchers to overlook fraud. However, a permissionless watcher set might involve notable liveness tradeoffs for some protocols. </p> <p>Considerations:</p> <p>Attestors:</p> <ul> <li>How many attestors are employed by the bridge to sign and validate transactions? Is this set of attestors centralized? If so, can the attestors conduct a Denial-of-Service (DoS) attack by not signing a Merkle root? In such cases, will the system halt?</li> <li>What exactly is the bonded stake of attestors? Is it a bridge-specific token? What are the dynamics that drive the value of such tokens?</li> <li>What is the cost of bribing or corrupting the attestors to violate safety? Is this correlated with the price of a token?</li> <li>Can attestors censor messages? Can such entities be removed from the set of attestors to prevent censorship?</li> <li>How will the liveness of an application be affected if an attestor faces downtime? Will the application stop receiving messages?</li> </ul> <p>Watchers:</p> <ul> <li>Is the watcher role permissionless?</li> <li>If not, how many watchers are watching the network to detect fraudulent transactions? </li> <li>Is this role decentralized in terms of the distinct entities involved? Are watchers geographically distributed and operating for high availability? Are there ways of verifying that these entities are active?  </li> <li>How are watchers incentivized? Is the model sustainable? How does the protocol ensure watchers do not get front-run?</li> <li>Is the optimistic bridge \u201cspam-proof\u201d \u2013 meaning can an actor watching the system arbitrarily dispute transactions without penalty? Can such actors permanently halt a communication channel by spamming it?</li> <li>Can watchers censor messages? Can such entities be removed from the set of actors watching the system to prevent censorship?</li> <li>Do the actors watching the system have competing interests with users of the bridge? e.g., trading firms that could benefit from front-running a significant volume crosschain transaction or from cross-domain MEV?</li> </ul> <p>A number of protocols employ a hybrid approach to bridging that leverages different approaches for a more robust crosschain solution. For example, Celer Inter-chain Message (Celer IM), utilizes a proof of stake approach by default but offers an optimistic-rollup inspired security model as a fallback solution in the worst-case scenario where validators behave maliciously in the PoS approach. </p>"},{"location":"framework/20categories/20architecture/architecture/#coordination-protocols","title":"Coordination Protocols","text":"<p>Coordination Protocols allow applications to be spread across blockchains. They allow  functionality and data on one blockchain to be combined with functionality on another  blockchain. They allow state to be updated across two or more chains atomically, or for actions to occur on one chain based on the state of a contract on another chain.</p> <p>General Purpose Atomic Crosschain Transaction (GPACT) (github) and Cross Framework are examples of Coordination Protocols. Both are a type of two-phase commitment protocol. The first phase executes segments of the crosschain execution on various chains, recording a set of provisional state updates to be applied. The end of this phase is to request that the crosschain transaction be committed. The second phase performs the update; applying the provisional state updates. If the second phase did not complete, then it is reapplied as many times as needed to complete the algorithm. If in the first phase any segment of the crosschain transaction fails, then the second phase is to discard the provisional updates on all chains.</p> <p>The Tree Two Phase Commit protocol is a variant of the two-phase commit protocol that aims to better utilise underlying communications infrastructure. The participants in a distributed transaction are invoked in an order defined by a tree structure, where the root of the tree is the instigator of the transaction and is called the coordinator. The coordinator is responsible for managing the two phases of the commitment protocol. This idea of a coordinator managing the protocol is where the  term Coordination Protocol comes from.</p> <p>Coordination Protocols sit on top of crosschain messaging protocols. They rely on the messaging protocols to honestly provide information about events that have occurred on  remote chains. For example, a segment of a crosschain transaction could execute and  have provisional updates. The coordination protocol would rely on messaging protocols to communicate this information to the coordination contract on a remote chain such that the information can be trusted.</p> <p>Considerations:</p> <ul> <li>Coordination protocols rely on messaging protocols communicating information from    remote chains honestly. </li> <li>The messaging protocol used to prove events occurred on one chain may be different   from that used to prove events occurred on other chains, despite all of the chains    being involved in the same crosschain transaction. Having multiple messaging    protocols, one for each chain information will be transferred from, will increase    the complexity of the overall crosschain system. </li> <li>The configuration parameters for the messaging protocols will be chain specific. For instance, the    finality time for transactions on different chains will depend on the consensus    protocol and other security parameters of the chain. Having this chain specific    configuration increases the complexity of the overall crosschain system.</li> <li>Coordination Protocols require at least two transactions per chain where updates    occur, and the chain which acts as the coordination point also has at least two    transactions. This is in contrast to simplistic crosschain protocols that don't provide   atomic updates across chains that require only one transaction per chain. The    increased number of transactions means that the latency for applications using    these protocols will be higher than for simplistic non-atomic protocols.</li> <li>The incentivization at the application level must be designed such that parties   executing the crosschain transactions for the application are incentivised to    unlock all provisional state updates on all chains, irrespective of the outcome   of the overall crosschain transaction (that is committed or discarded).</li> <li>Different coordination protocols provide different features and different security   guarantees. Understanding the differences is important as the protocols are not   interchangeable. For example:<ul> <li>True atomicity: Some protocols (Cross Framework) do not provide true atomicity.  They rely on segments being executed on each chain, and then being reversed if there is a failure on any chain. This is in contrast to other protocols (GPACT) that provide locking and true atomicity. Not providing true atomicity means that  other transactions may interact with the transaction state prior to it being  rolled-back.</li> <li>Isolation: Crosschain transactions are executed concurrently with other transactions.    That is, there could be multiple transactions reading from and writing to the state     of the same contract while a crosschain transaction is in progress. This occurs because    the segments of crosschain transactions are not all executed simultaneously, and are     executed as a two phase commitment protocol. Isolation ensures that concurrent     execution of transactions leaves the contract state in the same state that would     have been obtained if the transactions were executed sequentially. For coordination     protocols this comes down to the locking mechanisms provided by the protocol:     lock on write, lock on read, or no locking.</li> <li>Function call returning values: Some protocols allow function call return results whereas others do not provide this capability. </li> </ul> </li> </ul>"},{"location":"framework/20categories/20architecture/architecture/#token-bridges","title":"Token Bridges","text":"<p>One of the most common crosschain use cases is the transfer of assets from one network to another. This enables assets in one network to be used inside applications in another. For instance, a user might want to transfer her ETH from Ethereum to Avalanche so she can use it as collateral in a lending protocol on Avalanche. A token bridge is a protocol that enables this requirement. It often relies on an underlying messaging protocol for crosschain message communication. </p> <p>A core security requirement of such a protocol is preventing crosschain double-spends by ensuring that the original asset's value can only be realized in one network. There are two models for enabling this requirement, depending on the characteristics of the underlying asset.</p>"},{"location":"framework/20categories/20architecture/architecture/#lock-and-mint","title":"Lock and Mint","text":"<p>In this model, token bridges mimic the transfer of an asset by locking the original asset in the source network and issuing a synthetic representation on the destination. The original asset remains encumbered for as long as the synthetic token exists in the destination. A user can redeem the original asset by burning the corresponding synthetic token on the destination network.</p> <p>This approach is commonly employed today because it is the only way to transfer assets to a network they are not natively issued in. For instance, moving the native assets of layer-one protocols (e.g., ETH, SOL, AVAX) to different chains necessitates this model. </p> <p>Lock and Mint protocols must preserve the following core security invariants at all times:</p> <ol> <li>Every synthetic token has a corresponding locked asset in the source network.</li> <li>There can only be a single outstanding claim (i.e., synthetic token) against a locked asset.  </li> </ol> <p>Thus the total supply of synthetic tokens across networks must match the number of assets locked in a source network. If these invariants fail, the synthetic tokens become partially unbacked, meaning that each asset on the destination network is not backed by an asset on the source network. In extreme cases, where no assets on the source network are backing the assets on the destination network, the synthetic tokens become worthless. Because synthetic tokens are effectively IOUs issued by the token bridge, token holders carry perpetual exposure to such risks. </p> <p>From a design perspective, there are two inherent risks that this model creates: 1) funds locked on a source network create sizable honeypots that attract malicious actors 2) synthetic assets carry a perpetual risk for token holders. This risk is often hidden from token holders because bridge-specific synthetic assets are usually not distinctly identified as such. </p> <p>Considerations: The following are essential considerations for Users and Token Holders</p> <ul> <li>Are synthetic assets clearly labeled and identifiable?</li> <li>Are there alternatives to using this model for the specific asset? i.e., is there another version of the asset (or a substitute asset) that is natively issued on the destination and could be used instead of the bridge-wrapped asset?</li> <li>Transaction Failure Scenarios:<ul> <li>Does the protocol ensure atomicity of crosschain transactions? </li> <li>If not, how are failed transactions handled?</li> <li>Do refunds require trusted intermediaries (admins and bridge operators)?</li> </ul> </li> <li>How efficiently are refunds processed?</li> <li>What are the trust assumptions and security properties of the underlying messaging protocol?</li> </ul>"},{"location":"framework/20categories/20architecture/architecture/#burn-and-mint","title":"Burn and Mint","text":"<p>Some assets have a specified issuer that can authoritatively mint original assets on several networks (e.g., Circle for USDC). A user that holds such assets in one network might want to swap them for the same asset in another network. While Liquidity Networks generally satisfy this requirement, an issuer might want to rebalance the supply of these assets across networks based on differences in demand. Burn-and-mint mechanism address this requirement. Specifically, to move an asset from one network to another, the asset is first burnt on the source and an equivalent amount minted on the destination. The process ensures that the total supply of assets across networks remains constant. </p> <p>The risk posed by this mechanism is comparatively lower than lock-and-mint mechanisms for a couple of reasons: 1) it does not create honeypots that attract malicious actors, and 2) token holders possess original assets instead of bridge-specific IOUs.  </p> <p>Considerations:</p> <ul> <li>What are the trust assumptions and security properties of the underlying messaging protocol?</li> <li>Transaction Failure Scenarios:<ul> <li>Does the protocol ensure atomicity of crosschain transactions? </li> <li>If not, how are failed transactions handled?</li> </ul> </li> </ul>"},{"location":"framework/20categories/20architecture/architecture/#liquidity-networks","title":"Liquidity Networks","text":"<p>Liquidity networks enable the exchange of assets between users and Liquidity Providers (LPs) across different networks. For example, Alice has ETH on Ethereum and would like to swap this for AVAX on Avalanche. Bob, a liquidity provider, has sufficient AVAX on Avalanche that he is willing to swap for ETH for a fee. Liquidity networks enable these two parties to swap their assets without having to trust each other. There are a number of desirable security properties for such protocols, such as atomicity and fairness, which are discussed later in the considerations section.</p> <p>Typically, such protocols involve liquidity providers locking their assets upfront in smart contracts. LPs can provide liquidity for several assets across different networks. A user that wants to swap its assets advertises its requirement to LPs, typically through some off-chain mechanism. LPs bid to service the request, and the best offer is selected. The specifics of this discovery and matching process between users and LPs vary across protocols. Once a user identifies its preferred LP, it commences the swap by locking its funds on the source network, thus committing to the agreed exchange terms. </p> <p>In such protocols, liquidity providers generally bear higher risk because they have funds locked for extended periods in smart contracts. These funds could be stolen because of failures in the underlying messaging protocol or hacks on the liquidity network contracts. Unlike users, LPs maintain long-term exposure to such risks of protocol failure.</p> <p>There are generally three types of liquidity networks based on the degree to which they rely on underlying messaging layer protocols to coordinate the swap. The first model involves the transacting parties coordinating an exchange without needing a messaging protocol; the second relies on messaging protocols for one leg of the trade; the last depends on messaging protocol to coordinate the whole exchange. Each of these is discussed further below.</p>"},{"location":"framework/20categories/20architecture/architecture/#local-verification","title":"Local Verification","text":"<p>Liquidity networks that rely solely on the parties involved in the exchange verifying each other's transactions during execution and settlement are referred to as locally verified. Liquidity networks based on Atomic Swap protocols are locally verified. Atomic swaps are crosschain peer-to-peer swaps leveraging Hash Timelock Contract (HTLC) protocols. HTLCs ensure that the crosschain swaps are time-bound and are either executed fully within a given timeframe or aborted. If the time limit for the swap expires, the user's funds are refunded. For example, in Connext NXTP, users receive a refund if a swap is not completed within 72 hours. From the user's perspective, the worst-case scenario involves having their funds locked for a fixed period of time and the opportunity cost of capital that this entails. Examples: Connext NXTP and Liquality.</p>"},{"location":"framework/20categories/20architecture/architecture/#hybrid-verification","title":"Hybrid Verification","text":"<p>In hybrid verification schemes, LPs and users interact through atomic swaps at the liquidity layer. This enables users to receive desired assets instantly on the destination network. On the other hand, LPs receive their assets on the source network (along with the fees for fronting liquidity to the users) via the messaging layer with latency. For example, in Hop, users receive desired assets instantly, whereas LPs (Hop Bonders) receive assets in 1 day via the Hop optimistic messaging protocol. Hence, these approaches offer the speed of atomic swaps and the security of optimistically verified messaging protocols.</p> <p>From a security standpoint, liquidity networks that use hybrid verification mechanisms are locally verified for users and optimistically verified for LPs, where 1-of-N honest watchers ensure the safety of transactions. From the perspective of the user, the worst-case scenario involves delayed withdrawal of its funds via a slow, optimistically verified route. Examples: Connext Amarok, Hop, and Across.</p>"},{"location":"framework/20categories/20architecture/architecture/#message-protocol-reliant-verification","title":"Message Protocol Reliant Verification","text":"<p>These types of liquidity networks rely on the underlying messaging layer protocol to verify and coordinate swaps between parties. For example, the Wormhole bridge relies on 19 validators (called Guardians) to verify transactions on the source chain, determine their legitimacy, and release the desired assets on the destination network. </p> <p>From a security standpoint, such liquidity networks rely on the security properties of the underlying messaging layer. The worst-case scenario involves a complete loss of user and LP funds due to failures in the security of the messaging protocol.</p> <p>Considerations:</p> <p>Safety</p> <ul> <li>What are the trust assumptions and security properties of the underlying messaging protocol?</li> <li>Does the approach ensure atomicity of the exchange? Is there a possibility that one party might not get their owed funds? What are these conditions? Which party does this scenario affect?</li> <li>How are midway failures in multi-hop routes handled?</li> <li>Does the user always receive their requested asset, or are there scenarios where they might end up with intermediary assets (e.g., bridge-minted tokens)?</li> <li>What are the trust assumptions placed on the off-chain mechanisms that support this protocol and the parties that operate them? </li> </ul> <p>Liveness</p> <ul> <li>Is the role of an LP permissionless? How many LPs does the protocol have? Can these entities censor user swaps?</li> <li>Can the off-chain mechanisms that support the protocol censor transactions? </li> </ul> <p>Other</p> <ul> <li>What are the fairness properties of the protocol? Does it disadvantage one party over another (e.g., optionality)? </li> <li>Can LPs grief users by refusing to fulfill exchange requests? If so, are there mechanisms to penalize such behavior (e.g., slashing)?</li> <li>How much liquidity does the protocol have across routes? How are liquidity shortages for in-flight transactions handled? </li> </ul>"},{"location":"framework/20categories/20architecture/architecture/#bridge-aggregation-protocols","title":"Bridge Aggregation Protocols","text":"<p>Bridge aggregators operate similarly to Decentralised Exchange (DEX) aggregators. They integrate several different bridges and enable users to find the most optimal option for their cross-chain asset exchange and transfer requirements, based on factors such as cost, speed, slippage, and security. Because bridges often only support a limited number of tokens, bridge aggregators also integrate DEXs and DEX aggregators, which allows users to exchange a wide range of assets across chains. For example, if a user wants to swap USDC on Arbitrum to ETH on Ethereum, they would need a bridge aggregator that supports DEXs. Such an aggregator would transfer USDC from Arbitrum to Ethereum and swap it for ETH via a DEX. </p> <p>Most aggregators have an on-chain and an off-chain component for routing crosschain transactions:</p> <ul> <li> <p>Off-chain Components: An off-chain routing algorithm finds the most efficient route for a crosschain exchange by comparing quotes from different liquidity sources for a specific trade. It filters, ranks, and recommends routes based on rule sets and user preferences. This information is communicated through an API to front-end components, which showcase the routes to the user. Although centralized, the off-chain components of an aggregator are necessary because the quotes and routes of bridges are only served off-chain. Moreover, computing the optimal routes off-chain reduces cost and improves efficiency and user experience.</p> </li> <li> <p>On-chain Components: After a user selects a route, the aggregator's smart contracts, which integrate the contracts for different bridges, DEXs, and DEX aggregators supported by the bridge aggregator, execute the crosschain transaction. While the bridge aggregator's smart contract abstracts away the complexities of dealing with multiple bridges and DEXs, it adds another layer of smart contract risks.</p> </li> </ul> <p>Bridge aggregation protocols can be classified based on how they interact with their users:</p> <p>Indirectly via other dApps</p> <p>In such systems, bridge aggregation protocols work in the background and do not directly interact with the end users. Instead, the bridge aggregation protocols are integrated into a dApp\u2019s crosschain service offering. For example, in MetaMask Bridges, crosschain transfers are executed via two bridge aggregation protocols: LI.FI and Socket.</p> <p>From the perspective of dApps, the benefits of bridge aggregators include the following:</p> <ul> <li>Access to liquidity from multiple sources (bridges, DEXs, and DEX aggregators).</li> <li>Connectivity with more blockchains.</li> <li>No single point of failure, as bridge aggregators provide fallback solutions in the form of alternate bridges.</li> <li>Improved user experience as users get the optimal route for a crosschain swap.</li> <li>Bridge aggregators bear the costs of integrating and maintaining multiple bridges.</li> <li>Assessment of bridges is complicated and time-consuming as there are many factors to consider, such as speed, costs, security, trust assumptions, and others. Bridge aggregators save the dApps from the hassle of making this assessment and choosing a bridge as they get access to multiple bridges, enabling them to inherit the strengths of each bridge and overcome their limitations.</li> </ul> <p>Directly via their front-end</p> <p>In such systems, bridge aggregation protocols interact directly with the end-user via front-ends hosted by them. For example, LI.FI and Socket offer bridge aggregation services directly to users via TransferTo.xyz and Bungee, respectively.</p> <p>From the perspective of users, the benefits of bridge aggregators include the following:</p> <ul> <li>The convenience of having multiple bridges, DEXs, and DEX aggregators all on one platform saves users time and money.</li> <li>Rather than assessing bridges and choosing which one to use, users get access to multiple bridges (and DEXs).</li> <li>Finding the optimal route and quote for their crosschain swap via routing algorithms.</li> <li>Ability to compare different routes and choose one based on their preference.</li> </ul> <p>Considerations:</p> <ul> <li>Because aggregators enable multi-step or multi-hop bridging, there is an increased chance that a user's transaction might fail midway. How does the aggregator handle or mitigate these scenarios?</li> <li>Aggregators combine a wide range of protocols (i.e., different bridges and DEXs) with different security properties and risks. Users must largely trust aggregators to offer a curated set of options to minimize risk. What decision criteria does an aggregator use to select bridges it integrates? How are security and risk considerations surfaced to the user?</li> <li>Does the aggregator introduce additional trust assumptions beyond what is required by the underlying bridge? What are these assumptions, and under what conditions do they apply? </li> <li>What is the impact of failures of the off-chain components of an aggregator? Can such outages impact user funds?</li> <li>By adding a layer atop other protocols bridge aggregators add additional implementation risk.</li> </ul>"},{"location":"framework/20categories/20architecture/bridge-aggregation-protocols/","title":"Bridge aggregation protocols","text":""},{"location":"framework/20categories/20architecture/bridge-aggregation-protocols/#bridge-aggregation-protocols","title":"Bridge Aggregation Protocols","text":"<p>Bridge aggregators operate similarly to Decentralised Exchange (DEX) aggregators. They integrate several different bridges and enable users to find the most optimal option for their cross-chain asset exchange and transfer requirements, based on factors such as cost, speed, slippage, and security. Because bridges often only support a limited number of tokens, bridge aggregators also integrate DEXs and DEX aggregators, which allows users to exchange a wide range of assets across chains. For example, if a user wants to swap USDC on Arbitrum to ETH on Ethereum, they would need a bridge aggregator that supports DEXs. Such an aggregator would transfer USDC from Arbitrum to Ethereum and swap it for ETH via a DEX. </p> <p>Most aggregators have an on-chain and an off-chain component for routing crosschain transactions:</p> <ul> <li> <p>Off-chain Components: An off-chain routing algorithm finds the most efficient route for a crosschain exchange by comparing quotes from different liquidity sources for a specific trade. It filters, ranks, and recommends routes based on rule sets and user preferences. This information is communicated through an API to front-end components, which showcase the routes to the user. Although centralized, the off-chain components of an aggregator are necessary because the quotes and routes of bridges are only served off-chain. Moreover, computing the optimal routes off-chain reduces cost and improves efficiency and user experience.</p> </li> <li> <p>On-chain Components: After a user selects a route, the aggregator's smart contracts, which integrate the contracts for different bridges, DEXs, and DEX aggregators supported by the bridge aggregator, execute the crosschain transaction. While the bridge aggregator's smart contract abstracts away the complexities of dealing with multiple bridges and DEXs, it adds another layer of smart contract risks.</p> </li> </ul> <p>Bridge aggregation protocols can be classified based on how they interact with their users:</p> <p>Indirectly via other dApps</p> <p>In such systems, bridge aggregation protocols work in the background and do not directly interact with the end users. Instead, the bridge aggregation protocols are integrated into a dApp\u2019s crosschain service offering. For example, in MetaMask Bridges, crosschain transfers are executed via two bridge aggregation protocols: LI.FI and Socket.</p> <p>From the perspective of dApps, the benefits of bridge aggregators include the following:</p> <ul> <li>Access to liquidity from multiple sources (bridges, DEXs, and DEX aggregators).</li> <li>Connectivity with more blockchains.</li> <li>No single point of failure, as bridge aggregators provide fallback solutions in the form of alternate bridges.</li> <li>Improved user experience as users get the optimal route for a crosschain swap.</li> <li>Bridge aggregators bear the costs of integrating and maintaining multiple bridges.</li> <li>Assessment of bridges is complicated and time-consuming as there are many factors to consider, such as speed, costs, security, trust assumptions, and others. Bridge aggregators save the dApps from the hassle of making this assessment and choosing a bridge as they get access to multiple bridges, enabling them to inherit the strengths of each bridge and overcome their limitations.</li> </ul> <p>Directly via their front-end</p> <p>In such systems, bridge aggregation protocols interact directly with the end-user via front-ends hosted by them. For example, LI.FI and Socket offer bridge aggregation services directly to users via TransferTo.xyz and Bungee, respectively.</p> <p>From the perspective of users, the benefits of bridge aggregators include the following:</p> <ul> <li>The convenience of having multiple bridges, DEXs, and DEX aggregators all on one platform saves users time and money.</li> <li>Rather than assessing bridges and choosing which one to use, users get access to multiple bridges (and DEXs).</li> <li>Finding the optimal route and quote for their crosschain swap via routing algorithms.</li> <li>Ability to compare different routes and choose one based on their preference.</li> </ul> <p>Considerations:</p> <ul> <li>Because aggregators enable multi-step or multi-hop bridging, there is an increased chance that a user's transaction might fail midway. How does the aggregator handle or mitigate these scenarios?</li> <li>Aggregators combine a wide range of protocols (i.e., different bridges and DEXs) with different security properties and risks. Users must largely trust aggregators to offer a curated set of options to minimize risk. What decision criteria does an aggregator use to select bridges it integrates? How are security and risk considerations surfaced to the user?</li> <li>Does the aggregator introduce additional trust assumptions beyond what is required by the underlying bridge? What are these assumptions, and under what conditions do they apply? </li> <li>What is the impact of failures of the off-chain components of an aggregator? Can such outages impact user funds?</li> <li>By adding a layer atop other protocols bridge aggregators add additional implementation risk.</li> </ul>"},{"location":"framework/20categories/20architecture/coordination/","title":"Coordination","text":""},{"location":"framework/20categories/20architecture/coordination/#coordination-protocols","title":"Coordination Protocols","text":"<p>Coordination Protocols allow applications to be spread across blockchains. They allow  functionality and data on one blockchain to be combined with functionality on another  blockchain. They allow state to be updated across two or more chains atomically, or for actions to occur on one chain based on the state of a contract on another chain.</p> <p>General Purpose Atomic Crosschain Transaction (GPACT) (github) and Cross Framework are examples of Coordination Protocols. Both are a type of two-phase commitment protocol. The first phase executes segments of the crosschain execution on various chains, recording a set of provisional state updates to be applied. The end of this phase is to request that the crosschain transaction be committed. The second phase performs the update; applying the provisional state updates. If the second phase did not complete, then it is reapplied as many times as needed to complete the algorithm. If in the first phase any segment of the crosschain transaction fails, then the second phase is to discard the provisional updates on all chains.</p> <p>The Tree Two Phase Commit protocol is a variant of the two-phase commit protocol that aims to better utilise underlying communications infrastructure. The participants in a distributed transaction are invoked in an order defined by a tree structure, where the root of the tree is the instigator of the transaction and is called the coordinator. The coordinator is responsible for managing the two phases of the commitment protocol. This idea of a coordinator managing the protocol is where the  term Coordination Protocol comes from.</p> <p>Coordination Protocols sit on top of crosschain messaging protocols. They rely on the messaging protocols to honestly provide information about events that have occurred on  remote chains. For example, a segment of a crosschain transaction could execute and  have provisional updates. The coordination protocol would rely on messaging protocols to communicate this information to the coordination contract on a remote chain such that the information can be trusted.</p> <p>Considerations:</p> <ul> <li>Coordination protocols rely on messaging protocols communicating information from    remote chains honestly. </li> <li>The messaging protocol used to prove events occurred on one chain may be different   from that used to prove events occurred on other chains, despite all of the chains    being involved in the same crosschain transaction. Having multiple messaging    protocols, one for each chain information will be transferred from, will increase    the complexity of the overall crosschain system. </li> <li>The configuration parameters for the messaging protocols will be chain specific. For instance, the    finality time for transactions on different chains will depend on the consensus    protocol and other security parameters of the chain. Having this chain specific    configuration increases the complexity of the overall crosschain system.</li> <li>Coordination Protocols require at least two transactions per chain where updates    occur, and the chain which acts as the coordination point also has at least two    transactions. This is in contrast to simplistic crosschain protocols that don't provide   atomic updates across chains that require only one transaction per chain. The    increased number of transactions means that the latency for applications using    these protocols will be higher than for simplistic non-atomic protocols.</li> <li>The incentivization at the application level must be designed such that parties   executing the crosschain transactions for the application are incentivised to    unlock all provisional state updates on all chains, irrespective of the outcome   of the overall crosschain transaction (that is committed or discarded).</li> <li>Different coordination protocols provide different features and different security   guarantees. Understanding the differences is important as the protocols are not   interchangeable. For example:<ul> <li>True atomicity: Some protocols (Cross Framework) do not provide true atomicity.  They rely on segments being executed on each chain, and then being reversed if there is a failure on any chain. This is in contrast to other protocols (GPACT) that provide locking and true atomicity. Not providing true atomicity means that  other transactions may interact with the transaction state prior to it being  rolled-back.</li> <li>Isolation: Crosschain transactions are executed concurrently with other transactions.    That is, there could be multiple transactions reading from and writing to the state     of the same contract while a crosschain transaction is in progress. This occurs because    the segments of crosschain transactions are not all executed simultaneously, and are     executed as a two phase commitment protocol. Isolation ensures that concurrent     execution of transactions leaves the contract state in the same state that would     have been obtained if the transactions were executed sequentially. For coordination     protocols this comes down to the locking mechanisms provided by the protocol:     lock on write, lock on read, or no locking.</li> <li>Function call returning values: Some protocols allow function call return results whereas others do not provide this capability. </li> </ul> </li> </ul>"},{"location":"framework/20categories/20architecture/liquidity-networks/","title":"Liquidity networks","text":""},{"location":"framework/20categories/20architecture/liquidity-networks/#liquidity-networks","title":"Liquidity Networks","text":"<p>Liquidity networks enable the exchange of assets between users and Liquidity Providers (LPs) across different networks. For example, Alice has ETH on Ethereum and would like to swap this for AVAX on Avalanche. Bob, a liquidity provider, has sufficient AVAX on Avalanche that he is willing to swap for ETH for a fee. Liquidity networks enable these two parties to swap their assets without having to trust each other. There are a number of desirable security properties for such protocols, such as atomicity and fairness, which are discussed later in the considerations section.</p> <p>Typically, such protocols involve liquidity providers locking their assets upfront in smart contracts. LPs can provide liquidity for several assets across different networks. A user that wants to swap its assets advertises its requirement to LPs, typically through some off-chain mechanism. LPs bid to service the request, and the best offer is selected. The specifics of this discovery and matching process between users and LPs vary across protocols. Once a user identifies its preferred LP, it commences the swap by locking its funds on the source network, thus committing to the agreed exchange terms. </p> <p>In such protocols, liquidity providers generally bear higher risk because they have funds locked for extended periods in smart contracts. These funds could be stolen because of failures in the underlying messaging protocol or hacks on the liquidity network contracts. Unlike users, LPs maintain long-term exposure to such risks of protocol failure.</p> <p>There are generally three types of liquidity networks based on the degree to which they rely on underlying messaging layer protocols to coordinate the swap. The first model involves the transacting parties coordinating an exchange without needing a messaging protocol; the second relies on messaging protocols for one leg of the trade; the last depends on messaging protocol to coordinate the whole exchange. Each of these is discussed further below.</p>"},{"location":"framework/20categories/20architecture/liquidity-networks/#local-verification","title":"Local Verification","text":"<p>Liquidity networks that rely solely on the parties involved in the exchange verifying each other's transactions during execution and settlement are referred to as locally verified. Liquidity networks based on Atomic Swap protocols are locally verified. Atomic swaps are crosschain peer-to-peer swaps leveraging Hash Timelock Contract (HTLC) protocols. HTLCs ensure that the crosschain swaps are time-bound and are either executed fully within a given timeframe or aborted. If the time limit for the swap expires, the user's funds are refunded. For example, in Connext NXTP, users receive a refund if a swap is not completed within 72 hours. From the user's perspective, the worst-case scenario involves having their funds locked for a fixed period of time and the opportunity cost of capital that this entails. Examples: Connext NXTP and Liquality.</p>"},{"location":"framework/20categories/20architecture/liquidity-networks/#hybrid-verification","title":"Hybrid Verification","text":"<p>In hybrid verification schemes, LPs and users interact through atomic swaps at the liquidity layer. This enables users to receive desired assets instantly on the destination network. On the other hand, LPs receive their assets on the source network (along with the fees for fronting liquidity to the users) via the messaging layer with latency. For example, in Hop, users receive desired assets instantly, whereas LPs (Hop Bonders) receive assets in 1 day via the Hop optimistic messaging protocol. Hence, these approaches offer the speed of atomic swaps and the security of optimistically verified messaging protocols.</p> <p>From a security standpoint, liquidity networks that use hybrid verification mechanisms are locally verified for users and optimistically verified for LPs, where 1-of-N honest watchers ensure the safety of transactions. From the perspective of the user, the worst-case scenario involves delayed withdrawal of its funds via a slow, optimistically verified route. Examples: Connext Amarok, Hop, and Across.</p>"},{"location":"framework/20categories/20architecture/liquidity-networks/#message-protocol-reliant-verification","title":"Message Protocol Reliant Verification","text":"<p>These types of liquidity networks rely on the underlying messaging layer protocol to verify and coordinate swaps between parties. For example, the Wormhole bridge relies on 19 validators (called Guardians) to verify transactions on the source chain, determine their legitimacy, and release the desired assets on the destination network. </p> <p>From a security standpoint, such liquidity networks rely on the security properties of the underlying messaging layer. The worst-case scenario involves a complete loss of user and LP funds due to failures in the security of the messaging protocol.</p> <p>Considerations:</p> <p>Safety</p> <ul> <li>What are the trust assumptions and security properties of the underlying messaging protocol?</li> <li>Does the approach ensure atomicity of the exchange? Is there a possibility that one party might not get their owed funds? What are these conditions? Which party does this scenario affect?</li> <li>How are midway failures in multi-hop routes handled?</li> <li>Does the user always receive their requested asset, or are there scenarios where they might end up with intermediary assets (e.g., bridge-minted tokens)?</li> <li>What are the trust assumptions placed on the off-chain mechanisms that support this protocol and the parties that operate them? </li> </ul> <p>Liveness</p> <ul> <li>Is the role of an LP permissionless? How many LPs does the protocol have? Can these entities censor user swaps?</li> <li>Can the off-chain mechanisms that support the protocol censor transactions? </li> </ul> <p>Other</p> <ul> <li>What are the fairness properties of the protocol? Does it disadvantage one party over another (e.g., optionality)? </li> <li>Can LPs grief users by refusing to fulfill exchange requests? If so, are there mechanisms to penalize such behavior (e.g., slashing)?</li> <li>How much liquidity does the protocol have across routes? How are liquidity shortages for in-flight transactions handled? </li> </ul>"},{"location":"framework/20categories/20architecture/messaging/","title":"Messaging","text":""},{"location":"framework/20categories/20architecture/messaging/#messaging-protocol","title":"Messaging Protocol","text":"<p>Messaging protocols provide the following two foundational capabilities that are relied upon by crosschain applications built on top of them.</p> <ol> <li>Transmission of state information from a source network to a destination network in a timely manner</li> <li>Ensuring the validity and finality of any information sent from a source network to a destination network</li> </ol> <p>Messaging protocols must ensure the transmission of all crosschain messages (capability 1) while providing strong guarantees about their validity and finality (capability 2) in the source network. The former mainly highlights liveness and censorship resistance property, while the latter emphasizes safety. The architecture of crosschain protocols is largely differentiated by how they offer guarantees around safety. An ideal construction would introduce no additional trust assumptions beyond what is assumed about the underlying networks. For a message sent from a source network to a destination network, this would involve the destination networks independently:</p> <ol> <li>Validating that a state transition that resulted in a given message is valid according to the state transition rules of the source network and</li> <li>Verifying that the message has been finalized according to its consensus rules of the source network</li> </ol> <p>A protocol that performs one or both of the above verifications to ensure the validity of a remote network's state is considered trustless or trust-minimized. Conversely, a protocol that relies on intermediaries or a subset of network validators vouching for the validity of a remote state is considered trusted, or semi-trusted. In line with this, four broad architectural patterns are identified below. Not all crosschain protocols in the wild neatly fit into these categories, and some employ hybrid approaches. </p>"},{"location":"framework/20categories/20architecture/messaging/#state-validating-protocols","title":"State Validating Protocols","text":"<p>In State Validating Protocols, a destination chain independently verifies that any state it receives is valid and final according to the source network's state transition and consensus rules. This model inherits the security guarantees of the underlying networks without introducing new trust assumptions.  </p> <p>The only examples of such architecture, at present, are the native bridges between layer-one networks and their associated rollups (Optimistic and Zero-Knowledge rollups). In such models, there is, in effect, only a single source of truth, the state of the layer-one network. This is different from crosschain communication across independent layer-one networks. Hence, while this model offers significant security advantages, applying it across separate networks is currently not viable. However, with advances in Zero-Knowledge cryptography, this could change. Efforts such as stateless Ethereum focus on having succinct proofs of the network's state that clients can independently verify. An example of a protocol that offers similar properties is the Mina protocol. Such capabilities could eventually enable state-validating protocols across distinct layer-ones.</p> <p> </p> State Validating Crosschain Protocols <p>Considerations: While this approach offers strong security guarantees from a design perspective, it is worth noting that implementation and operational risks are still present.</p>"},{"location":"framework/20categories/20architecture/messaging/#consensus-verifying-protocols","title":"Consensus Verifying Protocols","text":"<p>In Consensus Verifying Protocols, a destination network independently verifies that a crosschain state has been finalized according to the consensus rules of the source chain. This is typically achieved by running the light-client protocol of the source chain on the destination chain.  Examples of this type of verification include checking that sufficient proof-of-work has been expended on a block, in the case of Proof-of-Work protocols, or that a quorum of network validators has signed a block in BFT-based protocols. Similar to State Validating protocols, this approach does not introduce new trust assumptions beyond what's employed by the underlying network protocols. </p> <p>However, light-client consensus verifications differ from the consensus verifications performed by full nodes and do not offer the same security guarantees. For instance, the Ethereum light-client protocol relies on verifying the attestations of a small subset of randomly selected validators, called the sync committee, in place of the complete Casper FFG consensus protocol employed by full nodes. Because of the smaller size of this validator set and the lack of slashing, this model offers relatively weaker security guarantees. In addition, unlike State Validating Protocols discussed above Consensus Verifying Protocols do not execute and verify the validity of transactions and hence offer lesser security.</p> <p>A significant constraint to the overall viability of such approaches is the complexity associated with building and maintaining such protocols and the costs associated with operating them. In addition, the cost of running such infrastructure is a function of the source network's block production rate rather than the demand for crosschain messaging. Hence, such bridges might need to charge high fees and gain significant usage to offset operational costs. </p> <p>There are two distinct models of such protocols based on whether the consensus verification is performed on-chain or off-chain. </p>"},{"location":"framework/20categories/20architecture/messaging/#on-chain-consensus-verification","title":"On-chain Consensus Verification","text":"<p>This model involves performing light-client verification of a source chain's consensus in the execution environment of the destination. First, block headers from a source network are sent to a destination network by off-chain actors called Relayers. The destination chain then performs consensus verification on the block, typically through logic implemented in a smart contract. A user can then prove that a state exists in the source network using a Merkle proof against the verified block header on the destination. This proof can then be used to trigger a subsequent transaction on the destination chain. </p> <p>Because of the constraints of most smart contract languages and blockchain execution environments, such models can be complicated to build and prohibitively expensive to operate (e.g., gas costs).</p> <p> </p> On-chain Consensus Verifying Protocols <p>Considerations:</p> <p>Safety:</p> <ul> <li>What are the security properties of the light-client protocols of the underlying networks?</li> <li>How does the protocol deal with the security limitations and potential attack vectors of the associated light-client protocols (e.g., Eclipse Attacks, Long-range attacks)? What is the likelihood of such attacks?</li> <li>How long can the bridge go without receiving new blocks before the bridge's security is affected?</li> <li>The increased complexity of building such protocols significantly increases implementation risk.</li> </ul> <p>Liveness:</p> <ul> <li>Is the role of relaying blocks across chains permissionless? If the role is permissioned, then Relayers can censor or delay transactions.</li> <li>What are the costs of operating the bridge? Are these sustainable under low-demand scenarios? </li> <li>What are the financial incentives for relayers? Given these entities incur network fees associated with relaying blocks to different destination networks, how are they compensated? Is this model sustainable?</li> </ul> <p>Other:</p> <ul> <li>Can the on-chain implementation adapt to changes in the source network's consensus protocol? What are there challenges and constraints to making such changes?</li> </ul>"},{"location":"framework/20categories/20architecture/messaging/#validity-proof-based-consensus-verification","title":"Validity-Proof based Consensus Verification","text":"<p>In this model, an off-chain system called a Prover generates a SNARK proof that a state in a source network has been finalized according to its consensus protocol. The proof is sent to a destination chain, which then verifies its validity using logic implemented in a smart contract (Verifier). Hence, this model shifts most of the complexity and cost of performing light-client consensus verification off-chain while retaining the security advantages of crosschain consensus verification.</p> <p>These types of bridges are also referred to as Zero-knowledge Bridges (ZK Bridges). However, this terminology is misleading, as such protocols rely only on the succinctness properties of SNARKs and do not apply information hiding (i.e., Zero-knowledge).</p> <p> </p> Validaity Proof Protocols (ZK Bridges) <p>Considerations:</p> <p>The same considerations as those laid out for On-chain Consensus Verification schemes apply to these protocols. Additional considerations include:</p> <p>Safety:</p> <ul> <li>What are the trusted setup assumptions of the underlying cryptographic mechanisms? </li> <li>The increased complexity of building such protocols increases implementation risk.</li> </ul> <p>Liveness:</p> <ul> <li>Is the role of prover permissionless? If not, how many provers are there? What are the criteria for becoming a prover? How are they coordinated? <ul> <li>Provers can technically censor transactions or become a source of liveness issues for the network</li> <li>Carrying out an eclipse attack against a single prover is more tractable than several provers</li> <li>How are provers incentivized?</li> <li>The computations performed by a prover can be expensive, which might discourage participation.</li> </ul> </li> </ul>"},{"location":"framework/20categories/20architecture/messaging/#third-party-attestation-protocols","title":"Third-party Attestation Protocols","text":"<p>The above approaches derive their security guarantees from the underlying chains because they involve each chain locally verifying, to some extent, the validity of the state from another chain. This avoids introducing additional trust assumptions and offers better security guarantees. However, such protocols are complex and costly to build, operate, and scale across diverse ecosystems. </p> <p>Hence, most crosschain protocols introduce intermediary sources of trust in the form of third-party attestors (also referred to as validators). These third-party attestors attest to the validity of crosschain messages from a source network and then send them to a destination network. A destination network accepts as valid any state that is certified by a majority of the trusted third-party attestors. Hence the safety and liveness properties of such protocols rely on a threshold of honest attestors (M of N security model).</p> <p> </p> Third-party Attestation Protocols <p> </p> Third-party Attestation Protocols with Intermediary Network <p>Protocols in this category vary widely on at least the following three dimensions:</p> <ol> <li>Coordination mechanism: Off-chain communication, Dedicated intermediary network</li> <li>Cryptographic mechanism: Multi-Signature, Threshold signature, Trusted Execution Environment (e.g., Intel SGX)</li> <li>Security model (Proof-of-Authority, Proof-of-Stake)</li> </ol> <p>The security model of these protocols defines the security properties of and assumptions about the third-party attestors.  There are generally two models, Proof-of-Authority and Proof-of-Stake, which are further discussed below.</p>"},{"location":"framework/20categories/20architecture/messaging/#proof-of-authority","title":"Proof-of-Authority","text":"<p>Proof-of-Authority models rely on reputable legal entities serving as attestors. These bridges assume that a) such parties are strongly incentivized to maintain their reputation and would thus not act maliciously and b) that in the event of misbehavior, stakeholders can pursue legal recourse against such entities. These assumptions are difficult to reason about and rely on external structural assurances (e.g., legal systems) instead of internal protocol mechanisms.</p> <p>Considerations:</p> <p>Safety:</p> <ul> <li>How many distinct attestors does the protocol have? What are the specific honesty threshold assumptions for guaranteeing safety and liveness? What are the particular characteristics of the cryptographic schemes used?</li> <li>How reputable are these entities? How important are trust and reputation to the operation of the businesses of these entities?</li> <li>Are there contractual terms governing the operation of these entities? In what jurisdictions are the entities domiciled?</li> <li>How do the above disincentives to misbehavior compare against the TVL or total volume transacted by layers atop the messaging bridge?</li> <li>Can the claims around decentralization be verified on-chain? For instance: <ul> <li>The number of validators and the threshold for achieving a quorum. Multi-signature schemes are easier to verify on-chain compared to MPC or threshold signature schemes. </li> <li>The active validator set. While a bridge might employ many validators, it is possible that only a few actively participate in validating and attesting to messages. This could be because the economics of validating messages are not worthwhile to some validators. This means that the effective validator set is smaller, and the decentralization and security guarantees of the bridge weaker. The Ronin bridge hack highlights an example of this scenario.</li> </ul> </li> </ul> <p>Liveness:</p> <ul> <li>Can regulations coerce these entities to censor transactions?</li> <li>Do such entities have competing interests with users of this bridge? e.g., Trading firms that might benefit from cross-domain MEV?</li> </ul>"},{"location":"framework/20categories/20architecture/messaging/#proof-of-stake","title":"Proof-of-Stake","text":"<p>Proof-of-Stake models rely on validators having financial incentives to behave honestly according to the rules of the protocol. This is typically achieved by having each validator stake funds in the protocol that can be slashed if the validator misbehaves. Unlike proof-of-authority schemes, this offers an immediate and in-protocol method of punishing malicious behavior. </p> <p>Considerations:</p> <p>Safety:</p> <ul> <li>How many distinct attestors does the protocol have? What are the specific thresholds for guaranteeing safety and liveness? What are the particular characteristics of the cryptographic schemes used?</li> <li>Can the claims around decentralization be verified on-chain? For instance: <ul> <li>The distribution of staked tokens across validators (i.e., concentrated amongst few parties vs. diffuse across many parties)</li> <li>The number of validators and the threshold for achieving a quorum (multi-signature schemes might be easier to verify on-chain than threshold signature schemes). </li> <li>The active validator set. While a bridge might employ many validators, it is possible that only a few actively participate in validating and attesting to messages. </li> </ul> </li> <li>What exactly is staked by validators? Is it a bridge-specific token? What are the dynamics that drive the value of such tokens? How liquid is the token?</li> <li>How does the value of staked funds compare against the volume of assets transacted across the bridge?</li> <li>What is the cost of bribing or corrupting a threshold of such validators to violate safety or liveness?</li> <li>How does the bridge adapt to active misbehavior by a portion of the validators?</li> </ul> <p>Liveness:</p> <ul> <li>Can regulations coerce these entities to censor transactions?</li> <li>Do such entities have competing interests with users of this bridge? e.g., Trading firms that might benefit from cross-domain MEV?</li> </ul>"},{"location":"framework/20categories/20architecture/messaging/#optimistic-protocols","title":"Optimistic Protocols","text":"<p>Optimistic crosschain protocols rely on two types of bridge validators, Attestors and Watchers. These validators have different names in different protocols. Attestors certify the validity of crosschain messages from a source network and submit them to destination networks. Attestors lock some stake in the source network that can be slashed in the case of proveable misbehavior. Watchers observe these attestations on-chain and submit fraud proofs within a time window if they are invalid. If invalid attestations are submitted, the responsible attestors are slashed, and the watcher that reported the fraud is rewarded. The Watcher role can either be permissioned or permissionless. </p> <p>Such bridges assume that: a) attestors are incentivized to sign only legitimate transactions because their bonded funds will be slashed if not, b) if an attestor signs a fraudulent transaction, at least one honest watcher will report the fraud within the allotted fraud window, and c) watchers are disincentivized from submitting invalid fraud reports. </p> <p>Thus, optimistic bridges have a 1 of N security model, which relies on one honest actor watching the system to verify crosschain transactions correctly. A large number of active watchers increases the security of such protocols. An ideal construction of such a protocol involves a permissionless watcher set. Such a model would make it difficult for an attacker to bribe a set of known watchers to overlook fraud. However, a permissionless watcher set might involve notable liveness tradeoffs for some protocols. </p> <p>Considerations:</p> <p>Attestors:</p> <ul> <li>How many attestors are employed by the bridge to sign and validate transactions? Is this set of attestors centralized? If so, can the attestors conduct a Denial-of-Service (DoS) attack by not signing a Merkle root? In such cases, will the system halt?</li> <li>What exactly is the bonded stake of attestors? Is it a bridge-specific token? What are the dynamics that drive the value of such tokens?</li> <li>What is the cost of bribing or corrupting the attestors to violate safety? Is this correlated with the price of a token?</li> <li>Can attestors censor messages? Can such entities be removed from the set of attestors to prevent censorship?</li> <li>How will the liveness of an application be affected if an attestor faces downtime? Will the application stop receiving messages?</li> </ul> <p>Watchers:</p> <ul> <li>Is the watcher role permissionless?</li> <li>If not, how many watchers are watching the network to detect fraudulent transactions? </li> <li>Is this role decentralized in terms of the distinct entities involved? Are watchers geographically distributed and operating for high availability? Are there ways of verifying that these entities are active?  </li> <li>How are watchers incentivized? Is the model sustainable? How does the protocol ensure watchers do not get front-run?</li> <li>Is the optimistic bridge \u201cspam-proof\u201d \u2013 meaning can an actor watching the system arbitrarily dispute transactions without penalty? Can such actors permanently halt a communication channel by spamming it?</li> <li>Can watchers censor messages? Can such entities be removed from the set of actors watching the system to prevent censorship?</li> <li>Do the actors watching the system have competing interests with users of the bridge? e.g., trading firms that could benefit from front-running a significant volume crosschain transaction or from cross-domain MEV?</li> </ul> <p>A number of protocols employ a hybrid approach to bridging that leverages different approaches for a more robust crosschain solution. For example, Celer Inter-chain Message (Celer IM), utilizes a proof of stake approach by default but offers an optimistic-rollup inspired security model as a fallback solution in the worst-case scenario where validators behave maliciously in the PoS approach. </p>"},{"location":"framework/20categories/20architecture/token-bridges/","title":"Token bridges","text":""},{"location":"framework/20categories/20architecture/token-bridges/#token-bridges","title":"Token Bridges","text":"<p>One of the most common crosschain use cases is the transfer of assets from one network to another. This enables assets in one network to be used inside applications in another. For instance, a user might want to transfer her ETH from Ethereum to Avalanche so she can use it as collateral in a lending protocol on Avalanche. A token bridge is a protocol that enables this requirement. It often relies on an underlying messaging protocol for crosschain message communication. </p> <p>A core security requirement of such a protocol is preventing crosschain double-spends by ensuring that the original asset's value can only be realized in one network. There are two models for enabling this requirement, depending on the characteristics of the underlying asset.</p>"},{"location":"framework/20categories/20architecture/token-bridges/#lock-and-mint","title":"Lock and Mint","text":"<p>In this model, token bridges mimic the transfer of an asset by locking the original asset in the source network and issuing a synthetic representation on the destination. The original asset remains encumbered for as long as the synthetic token exists in the destination. A user can redeem the original asset by burning the corresponding synthetic token on the destination network.</p> <p>This approach is commonly employed today because it is the only way to transfer assets to a network they are not natively issued in. For instance, moving the native assets of layer-one protocols (e.g., ETH, SOL, AVAX) to different chains necessitates this model. </p> <p>Lock and Mint protocols must preserve the following core security invariants at all times:</p> <ol> <li>Every synthetic token has a corresponding locked asset in the source network.</li> <li>There can only be a single outstanding claim (i.e., synthetic token) against a locked asset.  </li> </ol> <p>Thus the total supply of synthetic tokens across networks must match the number of assets locked in a source network. If these invariants fail, the synthetic tokens become partially unbacked, meaning that each asset on the destination network is not backed by an asset on the source network. In extreme cases, where no assets on the source network are backing the assets on the destination network, the synthetic tokens become worthless. Because synthetic tokens are effectively IOUs issued by the token bridge, token holders carry perpetual exposure to such risks. </p> <p>From a design perspective, there are two inherent risks that this model creates: 1) funds locked on a source network create sizable honeypots that attract malicious actors 2) synthetic assets carry a perpetual risk for token holders. This risk is often hidden from token holders because bridge-specific synthetic assets are usually not distinctly identified as such. </p> <p>Considerations: The following are essential considerations for Users and Token Holders</p> <ul> <li>Are synthetic assets clearly labeled and identifiable?</li> <li>Are there alternatives to using this model for the specific asset? i.e., is there another version of the asset (or a substitute asset) that is natively issued on the destination and could be used instead of the bridge-wrapped asset?</li> <li>Transaction Failure Scenarios:<ul> <li>Does the protocol ensure atomicity of crosschain transactions? </li> <li>If not, how are failed transactions handled?</li> <li>Do refunds require trusted intermediaries (admins and bridge operators)?</li> </ul> </li> <li>How efficiently are refunds processed?</li> <li>What are the trust assumptions and security properties of the underlying messaging protocol?</li> </ul>"},{"location":"framework/20categories/20architecture/token-bridges/#burn-and-mint","title":"Burn and Mint","text":"<p>Some assets have a specified issuer that can authoritatively mint original assets on several networks (e.g., Circle for USDC). A user that holds such assets in one network might want to swap them for the same asset in another network. While Liquidity Networks generally satisfy this requirement, an issuer might want to rebalance the supply of these assets across networks based on differences in demand. Burn-and-mint mechanism address this requirement. Specifically, to move an asset from one network to another, the asset is first burnt on the source and an equivalent amount minted on the destination. The process ensures that the total supply of assets across networks remains constant. </p> <p>The risk posed by this mechanism is comparatively lower than lock-and-mint mechanisms for a couple of reasons: 1) it does not create honeypots that attract malicious actors, and 2) token holders possess original assets instead of bridge-specific IOUs.  </p> <p>Considerations:</p> <ul> <li>What are the trust assumptions and security properties of the underlying messaging protocol?</li> <li>Transaction Failure Scenarios:<ul> <li>Does the protocol ensure atomicity of crosschain transactions? </li> <li>If not, how are failed transactions handled?</li> </ul> </li> </ul>"},{"location":"framework/20categories/30implementation/access-control/","title":"Access control","text":""},{"location":"framework/20categories/30implementation/access-control/#role-based-access-control","title":"Role Based Access Control","text":"<p>Role Based Access Control (RBAC)  allows different entites to be responsible for different configuration actions.  Systems that are managed by a single entity are inherently less secure  than those with narrowly-scoped privileges for different entities and specific contexts.</p> <p>With  contracts, this can be used to limit which accounts can execute which functions. For  example, imagine a contract that operates as a crosschain bridge. It could have a role  called <code>PAUSER</code>. This role could be required to call a function that enables  pausing of the contract. Any transaction submitted by an account that did not  have the <code>PAUSER</code> role would be reverted.</p> <p>Simplistic contracts might have a single role, <code>OWNER</code>, that can only be assigned to one account. For these contracts, the <code>owner</code> account is the only account  that can submit transactions that call configuration functions without reverting.</p> <p>The greater degree of flexibility afforded by Role Based Access Control compared  to simplistic <code>OWNER</code> style access control has security implications. For example,  a contract might be able to mint new tokens, and thus have a <code>MINTER</code> role to control this action. Minting new tokens could change the tokenomics of the contract, and hence  must only be executed if there is agreement between administrators. Access to this  configuration action might be limited to a multi-signature wallet account. The same  contract might have a <code>PAUSER</code> role that can be used to stop data processing within  the contract. The action to pause the contract needs to occur as quickly as possible, to halt an in-progress attack. However, access to the role needs to be limited to trusted accounts, to prevent attackers causing a Denial of Service attack on the contract, by continually pausing the contract. Using a multi-signature wallet to control this action is not ideal, as multiple parties would need to work together to pause the contract, thus  allowing attacks to continue longer than they otherwise would. In this situation,  multiple trusted accounts could be granted <code>PAUSER</code> role. Any one of the accounts  could then pause the contract.</p> <p>For a small project, when a contract is deployed, it might be tempting to use  simplistic <code>OWNER</code> style access control.  However, it is better to deploy a contract configured for fine grain Role Based Access Control, where all roles are initially assigned to the one account. In this way, as the project using the contract matures, new accounts can be granted roles and the original account's access can be revoked. It should be noted that the benefits of RBAC are only realised once  access for different roles is allocated to additional accounts. </p> <p>For Ethereum based projects, the OpenZeppelin project has an example contract AccessControl.sol that can be used to implement Role Based Access Control. Using this template, checking an address has been granted a role becomes as simple as calling  the function <code>hasRole</code>. The code below shows how this would work in practice.</p> <pre><code>contract Example is Pausable, AccessControl {\n    constructor() {\n        _setupRole(DEFAULT_ADMIN_ROLE, msg.sender);\n        _setupRole(PAUSER_ROLE, msg.sender);\n    }\n\n    function pause() external {\n        require(hasRole(PAUSER_ROLE, msg.sender), \"Must have PAUSER role\");\n        _pause();\n    }\n}\n</code></pre>"},{"location":"framework/20categories/30implementation/audit/","title":"Audit","text":""},{"location":"framework/20categories/30implementation/audit/#code-auditing","title":"Code Auditing","text":"<p>Code audits are necessary to ensure that a protocol's code performs as per its intended logic. Code that has not been audited is far more likely to contain bugs than code that has. Any protocol that does not have code audits should be trusted less by users and developers. However, code audits should not be viewed as a comprehensive security solution. For example, protocols sometimes conduct audits on specific parts of their architecture or deploy unaudited code for changes/new features, which can be a potential source of risk outside of the initial audit.</p> <p>Considerations:</p> <ul> <li> <p>Has the code been audited? How many audits have been completed? Were these audits conducted by different organizations?</p> <p>Several audits, ideally by different organizations, are more likely to uncover more potential vulnerabilities.</p> </li> <li> <p>When was the most recent audit? Has the protocol been upgraded since the last audit? How often is the protocol's code audited? </p> <p>Ensuring audits are up-to-date with code changes and are conducted frequently offers more assurance about their validity.</p> </li> <li> <p>What was the scope of the audit? Does it cover all of the key on-chain components?</p> <p>Wide audit scope offers assurances around more parts of the protocol. At a minimum, however, audits should cover all core on-chain contracts. </p> </li> <li> <p>Is the deployed version of the protocol's code audited?</p> </li> <li> <p>What were the findings of the audit? Were there critical findings that were left unaddressed? What are the scenarios in which these could be exploited?</p> <p>Sometimes findings are \"acknowledged\" by team members but not addressed either because the attack scenarios are mitigated by other means, are considered difficult to pull off, or the requested changes are difficult to make. Understanding these findings enables a better assessment of the potential implementation risks.</p> </li> <li> <p>What are the audit firm's track record and reputation?</p> <p>Not all audit firms are created equal. The level of confidence around the audit might need to be weighted by their track record, reputation, or other measures of the caliber of the team.</p> </li> <li> <p>Have changes made in response to audit findings been audited? If not, how significant are these changes?</p> <p>The critical bug that led to the Nomad hack in August 2022 was introduced during a response to the auditor's findings. While Nomad's team was under the impression that the post-remediation code changes were re-audited by the auditor, it was, in fact, not the case. The auditor's report only certified the state of the codebase prior to the changes. </p> </li> </ul> <p>While code audits are vital to ensure the robustness of a protocol, they do not guarantee security. In the past, protocols have been compromised despite completing several audits. Thus, audits should only be one of the risk management strategies used by protocols, but not their entire security stack against hacks.</p>"},{"location":"framework/20categories/30implementation/ban-address/","title":"Ban address","text":""},{"location":"framework/20categories/30implementation/ban-address/#ability-to-ban-addresses","title":"Ability to Ban Addresses","text":"<p>Addresses may be associated with stolen funds. Tornado Cash was  a project that had sanctions placed against it due to its  association with stolen funds. Projects that have the  ability to block these addresses, or freeze in-transit funds  are more likely to avoid this type of regulatory risk.</p>"},{"location":"framework/20categories/30implementation/bug-bounty/","title":"Bug bounty","text":""},{"location":"framework/20categories/30implementation/bug-bounty/#bug-bounty","title":"Bug Bounty","text":"<p>A public bug bounty program incentivizes whitehats to uncover and safely disclose vulnerabilities that might exist in a protocol. This increases the number of people that can thoroughly scrutinize a codebase and prevent exploits by malicious actors. Bug bounties have to offer adequate compensation and have clear scope covering the protocol's critical elements. The process requires trust and transparency and should ideally be managed by an independent third party (e.g., Immunefi).</p>"},{"location":"framework/20categories/30implementation/documentation/","title":"Documentation","text":""},{"location":"framework/20categories/30implementation/documentation/#documentation","title":"Documentation","text":"<p>More documentation makes a project easier to analyze. A lack  of documentation can lead to confusion and issues being  missed. Projects that have good documentation are easier  to maintain.</p> <p>Types of documentation a good project should have are:</p> <ul> <li>Architecture document that includes the component and deployment architecture.</li> <li>Thread model that includes all parts of the project.</li> <li>Sequence diagrams for all major data flows.</li> <li>Test plan describing how the project will be tested.</li> <li>Smart contract code comments at the contract and function level.</li> <li>Off-chain code with comments at the class and method level.</li> <li>Test code with at least a class level comment.</li> </ul>"},{"location":"framework/20categories/30implementation/formal-verification/","title":"Formal verification","text":""},{"location":"framework/20categories/30implementation/formal-verification/#formal-verification","title":"Formal Verification","text":"<p>Formally verified code should prove that the code matches the  specification. Hence, formal verification can not detect bugs  in the design of the project. However, it will pick-up  implementation bugs that testing might miss.</p>"},{"location":"framework/20categories/30implementation/known-language/","title":"Known language","text":""},{"location":"framework/20categories/30implementation/known-language/#well-known-smart-contract-programming-language","title":"Well Known Smart Contract Programming Language","text":"<p>More people are likely to be able to review and understand code  that has been created in programming languages that they are  familiar with. Solidity is the smart contract programming  language known by most blockchain developers. Hence, projects  that use Solidity are inherently less risky than projects that  use other smart contract programming languages.</p> <p>Solidity Assembler can be used to implement complex features not  available in standard Solidity. Assembler code is more complex  than Solidity code and is more likely to contain bugs and have  unexpected consequences.</p>"},{"location":"framework/20categories/30implementation/known-platform/","title":"Known platform","text":""},{"location":"framework/20categories/30implementation/known-platform/#well-known-platform","title":"Well Known Platform","text":"<p>More people are likely to be able to review and understand projects  that are created in environments that they are familiar with. The  majority of the blockchain developers in the world understand  Ethereum and the Ethereum Virtual Machine (EVM). Hence, projects  that use blockchains that support the EVM, or that are forks or  Ethereum, are inherently less risky than projects that involve  other blockchains.</p>"},{"location":"framework/20categories/30implementation/maturity/","title":"Maturity","text":""},{"location":"framework/20categories/30implementation/maturity/#product-development-maturity","title":"Product Development Maturity","text":"<p>Organisations that lack software development practices are likely to create lower quality software than organisations that have defined development practices. These practices are called the Software Development Lifecycle (SDLC).</p>"},{"location":"framework/20categories/30implementation/mixing-control-data-flow/","title":"Mixing control data flow","text":""},{"location":"framework/20categories/30implementation/mixing-control-data-flow/#mixing-of-control-and-data-plane","title":"Mixing of Control and Data Plane","text":"<p>The terms Control Plane and Data Plane come from networking [Wikipedia]. In the context of networking, the Control Plane configures the network topology  and routing tables, and the Data Plane is the information that is  communicated across the network. In the context of computing, the  Control Plane is the configuration of the system, and the Data Plane is the data processing. </p> <p>Functions in smart contracts can be ones that control the configuration  of the contract. These can be thought of as Control Plane functions.  For example, a function to pause the contract is a Control Plane function.  Data Plane functions are functions that process data. For example, a  function to mint some tokens is a Data Plane function.</p> <p>Poor project design can result in smart contract functions that contain  both Control Plane and Data Plane logic. Mixing these two planes in the  one function dramatically increases the risk of the project. An attacker  may be able to compromise the Data Plane part of a mixed processing function,  and then use that to change the configuration of the project, accessing the  Control Plane part of the mixed function. This can lead to the attacker  having the ability to control aspects of the project such as minting tokens.</p> <p>Example</p> <p>As example of this type of issue being exploited is the  August 2021 PolyNetwork issue. The  PolyNetwork code was written such that its <code>EthCrossChainManager</code> contract was the owner of the <code>EthCrossChainData</code> contract. The <code>EthCrossChainData</code>  contract held important information including the public keys used to verify crosschain requests. Doing this allows for function calls for <code>EthCrossChainData</code> to go via the <code>EthCrossChainManager</code> contract. Access from the <code>EthCrossChainManager</code> contract to the <code>EthCrossChainData</code> contract could be deemed part of the Control Plane.  The <code>EthCrossChainManager</code> contract also had a function  <code>verifyHeaderAndExecuteTx</code> that was used to process  Data Plane requests.  The attacker was able to create a carefully constructed call to <code>verifyHeaderAndExecuteTx</code> that allowed the Data Plane request to modify data in the <code>EthCrossChainData</code>, that ultimately led to the attacker being  able to steal funds. </p> <p>The PolyNetwork code would not have been vulnerable to this type  of attack if there had been a clear separation of Control Plane and Data  Plane. For example, rather than doing updates to the <code>EthCrossChainData</code>  contract via the <code>EthCrossChainManager</code> contract, updates could have been  only allowed from an Externally Owned Account (EOA) or a MultiSig Wallet account.</p>"},{"location":"framework/20categories/30implementation/open-source/","title":"Open source","text":""},{"location":"framework/20categories/30implementation/open-source/#open-source-code","title":"Open Source Code","text":"<p>If the code is stored in a public Github repository, it allows people  to review the code and the test system. If many people view the code,  then it is likely that defects in the code will be found. Additionally,  it allows for the assessment of such things as the number of tests.</p> <p>Some people argue that a private Github repository is more secure,  believing that issues can be hidden from attackers. However,  attackers who are sufficiently motivated often obtain access  of private repository or to a copy of the code, and are then  able to exploit any vulnerabilities. Not having the repository  public then hinders white hat developers from helping, in the  case of an attack.</p> <p>When using a public repository, it is important that issues that  relate to vulnerabilities and code fixes for vulnerabilities are  not put on the public repository before a release including the  vulnerability fix has been deployed. Not doing this equates to  publishing vulnerabilities that can be used to exploit the  project. The approach that should be taken is to review and  test the vulnerability fix using the private repo, deploy  from the private repo, and the push the fix to the public  repo. </p>"},{"location":"framework/20categories/30implementation/pause/","title":"Pause","text":""},{"location":"framework/20categories/30implementation/pause/#ability-to-pause-project","title":"Ability to Pause Project","text":"<p>This section described the implementation risks associated with being able to pause a project.  Operational risks related to pausing are covered in the Ability to Pause Operational Risk section.</p> <p>All Data Plane functions should be pausable. For example, a bridge contract could  have a function that could transfer coins based on actions on another blockchain.  The ability to pause a function in a  project allows administrators to stop functions from successfully  executing. If there is a vulnerability that is being actively  exploited in a project, having the ability to pause a function  could stop the exploitation of the project midway through the  attack.</p> <p>For Ethereum based projects, the OpenZeppelin project has an example   contract Pausable.sol that can be used to implement pausing. Using this template,  pausing a function becomes as simple as adding a modifier <code>whenNotPaused</code>.  The code below shows how this would work in practice.</p> <pre><code>contract Example is Pausable {\n    function pause() external onlyOwner {\n        _pause();\n    }\n    function transfer(\n        address _sender,\n        address _tokenContract,\n        address _recipient,\n        uint256 _amount\n    ) external whenNotPaused {\n        // Only executed when not paused\n</code></pre> <p>When analyzing whether a project can be paused, it is important to check whether all data processing functions can be paused, or just some parts of the project. </p> <p>Example</p> <p>For example, in August 2022 the Nomad Bridge had an issue (see Rekt for an analysis of the issue from  people outside the team). An attacker was able to determine a methodology for stealing funds using the <code>Replica</code>  contract's <code>process()</code> function. Depite most of the Data Plane processing functions  in the project being pausable, the <code>process()</code> function was not. This meant that the  attack was able to proceed without the administrators of the project being able to stop it. </p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/","title":"Protocol Implementation Risk","text":"<p>Building crosschain protocols involves creating complex on-chain and off-chain components while accounting for the peculiarities and pitfalls of different programming languages, frameworks, virtual machines, runtime environments, and protocols. Inevitably, such complexity increases the likelihood of bugs and vulnerabilities. This type of risk has thus far been the most common cause of bridge hacks witnessed over the last couple of years. </p> <p>The best practices learned over the years in building secure systems and blockchain applications apply directly in the context of crosschain protocols. Discussing each of these would be beyond the scope of this document and largely duplicative. Instead, we refer the reader to resources such as Ethereum Smart Contract Best Practices, which outlines best practices, patterns, anti-patterns, common attacks, and guiding philosophies for building and maintaining secure applications. It covers general principles such as the importance of simplicity, modularity, reuse of standard implementations, and planning for failures. All of which are critical considerations in crosschain protocols.</p> <p>This section discusses some of the salient principles and considerations for thinking about crosschain implementation risk. In general, protocol developers should mitigate implementation risk by reducing its likelihood upfront, uncovering extant risk, and having controls to respond to materialized risk. </p> <ul> <li> <p>Reducing risk</p> <ul> <li>Managing Complexity: Generally, the higher the complexity of a protocol's design, code, and runtime environments, the higher the implementation risk. Various ways to gauge complexity include: the size and intricacy of codebases (e.g., cyclomatic complexity), the diversity of execution environments, and the number of moving and coordinating pieces. </li> <li>Assurances of Correctness: Ensuring the correctness of the implementation of a protocol against its specification, at different levels of granularity, under a range of inputs and conditions is critical. There are numerous techniques for attaining varying degrees of confidence about the correctness of a protocol, ranging from formal verification to different types of testing. Rigorously employing such techniques reduces implementation risk. </li> <li>Principles of Least Privilege: Ensuring that fine-grained access controls are in-place reduces the impact of compromised entities or credentials.</li> <li>Principles of Diffuse Privilege: Ensuring that control of critical operations is decentralized offers checks and balances that mitigate the likelihood and impact of implementation risk.</li> <li>Nascency Risk: Cross-chain protocols are built to operate across disparate networks. Some of these ecosystems use tools, frameworks and execution environments that are less mature or well understood. This increases implementation risk.</li> </ul> </li> <li> <p>Uncovering extant risk: Protocols should enable, encourage and incentivize external review and scrutiny of their codebase. This enables vulnerabilities to be surfaced by good-faith actors and reduces the risk of exploits. Some practices that are critical aids to this include up-to-date audits, bug bounties, open-source codebases, and good documentation. </p> </li> <li> <p>Responding to materialized risk: Despite best efforts, hacks and exploits are likely to occur. Protocol implementations should include efficient mechanisms for responding to such incidents. Capabilities that enable this include the ability to monitor, detect anomalies, and pause protocols.</p> </li> </ul> <p>The rest of this section will discuss specific practices and considerations that expand on the above framework.</p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#reducing-risk","title":"Reducing Risk","text":""},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#mixing-of-control-and-data-plane","title":"Mixing of Control and Data Plane","text":"<p>The terms Control Plane and Data Plane come from networking [Wikipedia]. In the context of networking, the Control Plane configures the network topology  and routing tables, and the Data Plane is the information that is  communicated across the network. In the context of computing, the  Control Plane is the configuration of the system, and the Data Plane is the data processing. </p> <p>Functions in smart contracts can be ones that control the configuration  of the contract. These can be thought of as Control Plane functions.  For example, a function to pause the contract is a Control Plane function.  Data Plane functions are functions that process data. For example, a  function to mint some tokens is a Data Plane function.</p> <p>Poor project design can result in smart contract functions that contain  both Control Plane and Data Plane logic. Mixing these two planes in the  one function dramatically increases the risk of the project. An attacker  may be able to compromise the Data Plane part of a mixed processing function,  and then use that to change the configuration of the project, accessing the  Control Plane part of the mixed function. This can lead to the attacker  having the ability to control aspects of the project such as minting tokens.</p> <p>Example</p> <p>As example of this type of issue being exploited is the  August 2021 PolyNetwork issue. The  PolyNetwork code was written such that its <code>EthCrossChainManager</code> contract was the owner of the <code>EthCrossChainData</code> contract. The <code>EthCrossChainData</code>  contract held important information including the public keys used to verify crosschain requests. Doing this allows for function calls for <code>EthCrossChainData</code> to go via the <code>EthCrossChainManager</code> contract. Access from the <code>EthCrossChainManager</code> contract to the <code>EthCrossChainData</code> contract could be deemed part of the Control Plane.  The <code>EthCrossChainManager</code> contract also had a function  <code>verifyHeaderAndExecuteTx</code> that was used to process  Data Plane requests.  The attacker was able to create a carefully constructed call to <code>verifyHeaderAndExecuteTx</code> that allowed the Data Plane request to modify data in the <code>EthCrossChainData</code>, that ultimately led to the attacker being  able to steal funds. </p> <p>The PolyNetwork code would not have been vulnerable to this type  of attack if there had been a clear separation of Control Plane and Data  Plane. For example, rather than doing updates to the <code>EthCrossChainData</code>  contract via the <code>EthCrossChainManager</code> contract, updates could have been  only allowed from an Externally Owned Account (EOA) or a MultiSig Wallet account.</p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#role-based-access-control","title":"Role Based Access Control","text":"<p>Role Based Access Control (RBAC)  allows different entites to be responsible for different configuration actions.  Systems that are managed by a single entity are inherently less secure  than those with narrowly-scoped privileges for different entities and specific contexts.</p> <p>With  contracts, this can be used to limit which accounts can execute which functions. For  example, imagine a contract that operates as a crosschain bridge. It could have a role  called <code>PAUSER</code>. This role could be required to call a function that enables  pausing of the contract. Any transaction submitted by an account that did not  have the <code>PAUSER</code> role would be reverted.</p> <p>Simplistic contracts might have a single role, <code>OWNER</code>, that can only be assigned to one account. For these contracts, the <code>owner</code> account is the only account  that can submit transactions that call configuration functions without reverting.</p> <p>The greater degree of flexibility afforded by Role Based Access Control compared  to simplistic <code>OWNER</code> style access control has security implications. For example,  a contract might be able to mint new tokens, and thus have a <code>MINTER</code> role to control this action. Minting new tokens could change the tokenomics of the contract, and hence  must only be executed if there is agreement between administrators. Access to this  configuration action might be limited to a multi-signature wallet account. The same  contract might have a <code>PAUSER</code> role that can be used to stop data processing within  the contract. The action to pause the contract needs to occur as quickly as possible, to halt an in-progress attack. However, access to the role needs to be limited to trusted accounts, to prevent attackers causing a Denial of Service attack on the contract, by continually pausing the contract. Using a multi-signature wallet to control this action is not ideal, as multiple parties would need to work together to pause the contract, thus  allowing attacks to continue longer than they otherwise would. In this situation,  multiple trusted accounts could be granted <code>PAUSER</code> role. Any one of the accounts  could then pause the contract.</p> <p>For a small project, when a contract is deployed, it might be tempting to use  simplistic <code>OWNER</code> style access control.  However, it is better to deploy a contract configured for fine grain Role Based Access Control, where all roles are initially assigned to the one account. In this way, as the project using the contract matures, new accounts can be granted roles and the original account's access can be revoked. It should be noted that the benefits of RBAC are only realised once  access for different roles is allocated to additional accounts. </p> <p>For Ethereum based projects, the OpenZeppelin project has an example contract AccessControl.sol that can be used to implement Role Based Access Control. Using this template, checking an address has been granted a role becomes as simple as calling  the function <code>hasRole</code>. The code below shows how this would work in practice.</p> <pre><code>contract Example is Pausable, AccessControl {\n    constructor() {\n        _setupRole(DEFAULT_ADMIN_ROLE, msg.sender);\n        _setupRole(PAUSER_ROLE, msg.sender);\n    }\n\n    function pause() external {\n        require(hasRole(PAUSER_ROLE, msg.sender), \"Must have PAUSER role\");\n        _pause();\n    }\n}\n</code></pre>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#upgradable","title":"Upgradable","text":"<p>Like any software, smart contracts software can have bugs. This is true of both code that appears to be extremely simple and more complex code. Additionally, applications may require new features. As such, many projects have the ability to upgrade their smart contract code.</p> <p>Having the ability to upgrade a contract is inherently risky as it can lead to rug-pulling attacks, where the operators of a project change the contract logic and steal customer funds (for instance the Hunter Defi rug-pull). However, as a proportion of both the number of cypto rug pull attacks and as a proportion of the projects that use upgradable contracts, using contract upgrade as a method of stealing funds is very rare. We have no hard statistics on this; this is just an observation.</p> <p>Another major source of risk related to upgrading a contract is that vulnerabilities can either be introduced due to the new code, or the interaction of the new code with the old data. This was the source of the issue in the Nomad hack in August 2022.</p> <p>An important consideration is the processes and controls that govern contract upgrades. That is, who can perform upgrades, how decentralised is this privilege, are there timelocks such that upgrades take effect at some time after the upgrade is triggered. Many of these governance considerations are covered in the Role Based Access Control section.</p> <p>The three common methodologies for upgrading smart contracts are:</p> <ul> <li>Data Holder Upgrade Pattern: Have a data holder contract and a separate business logic contract. The business logic contracts are upgraded, and connect to the existing data holder contracts. Issues with this approach are that new versions of the business logic contract need to be able to utilise old data formats stored in the data holder contract.</li> <li>Transparent Upgrade Proxy Pattern: Have a transparent upgrade proxy contract and a business logic contract. The business logic contract executes in the context of the upgrade proxy contract. The upgrade logic resides in the proxy contract. Issues with this approach are that extreme caution needs to be exercised to ensure there are no storage slot collisions between the proxy and the business logic contracts, and between different versions of the business logic contract.</li> <li>Transparent Upgrade Proxy Pattern with Upgradable Upgrade Logic: As per the Transparent Upgrade Proxy Pattern described above, but with the upgrade logic in the business logic contract. The advantage of this approach is that governance that exists in the business logic contract can be used to approve the upgrade. Issues with this approach over and above the issues with the Transparent Upgrade Proxy Pattern approach is that bugs with the business logic contract can interfere with the upgrade logic, thus preventing upgrade, or enabling an attacker to maliciously upgrade the contract.</li> </ul> <p>In summary, having the ability to upgrade the contracts of a project has risks. However, not having the ability to upgrade contracts, thus resolving bugs, has other, possibly larger risks.</p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#secret-storage","title":"Secret Storage","text":"<p>Most projects use cryptographic keys to operate the system.  These keys could be stored in a network HSM or a hardware  wallet, and not in a file on disk on a server. </p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#product-development-maturity","title":"Product Development Maturity","text":"<p>Organisations that lack software development practices are likely to create lower quality software than organisations that have defined development practices. These practices are called the Software Development Lifecycle (SDLC).</p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#well-known-platform","title":"Well Known Platform","text":"<p>More people are likely to be able to review and understand projects  that are created in environments that they are familiar with. The  majority of the blockchain developers in the world understand  Ethereum and the Ethereum Virtual Machine (EVM). Hence, projects  that use blockchains that support the EVM, or that are forks or  Ethereum, are inherently less risky than projects that involve  other blockchains.</p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#well-known-smart-contract-programming-language","title":"Well Known Smart Contract Programming Language","text":"<p>More people are likely to be able to review and understand code  that has been created in programming languages that they are  familiar with. Solidity is the smart contract programming  language known by most blockchain developers. Hence, projects  that use Solidity are inherently less risky than projects that  use other smart contract programming languages.</p> <p>Solidity Assembler can be used to implement complex features not  available in standard Solidity. Assembler code is more complex  than Solidity code and is more likely to contain bugs and have  unexpected consequences.</p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#uncovering-extant-risk","title":"Uncovering Extant Risk","text":""},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#formal-verification","title":"Formal Verification","text":"<p>Formally verified code should prove that the code matches the  specification. Hence, formal verification can not detect bugs  in the design of the project. However, it will pick-up  implementation bugs that testing might miss.</p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#testing","title":"Testing","text":"<p>Code that is not tested is far more likely to contain bugs than code that has been tested. Comprehensive tests allow new features to be added without fear of breaking existing functionality. Hence, the more comprehensive the testing of the project, the less risky the project is. </p> <p>Testing falls into several categories:</p> <ul> <li>Unit Testing: Checks the operation of a single component, module, class, or contract in isolation. Because of the low level nature of this testing, it should be possible to check all error conditions. Mocking can be used to simulate the behavior of real components that are relied upon by the component to be tested.</li> <li>Integration Testing: Checks the operation of multiple components together. </li> <li>System Testing: Checks the operation of the entire product. This testing could check the system with no data, simulating a new install, with prefilled data simulating multiple years of operation, or could use real world data. A type of System Testing is Upgrade Testing. This type of testing checks that existing version(s) of the system can be upgraded to the new version of the system. System testing is also known as Regression Testing or End to End Testing. </li> <li>Performance Testing: Measures the latency, speed of operation, gas usage, transactions per second, or some other metric. These tests can be used to check that the performance of a system has not degraded from one software release to the next. Performance testing can be done at the unit, integration or system level. </li> <li>Acceptance Testing: Checks that the software can be deployed and that the deployed software operates as expected.</li> <li>Interoperability Testing: Checks that two software products can communicate based on a standard.</li> </ul> <p>Testing can be automated or manual. Automated tests allows software to be tested using scripts. Continuous Integration is a form of automated testing that runs a test script when code is committed to a source code repository. Manual testing requires people to perform a sequence of tests. As manual testing is labor intensive, there is the risk that it is performed for some software releases and not other software releases. As such, it is preferable to only rely on manual testing to do some Acceptance Testing, and not to rely on it to perform other forms of testing, for instance System Testing. </p> <p>Tests can be happy path tests that only check the operation of the software in ideal conditions. Unhappy path tests check what occurs when an error condition arises. Tests should check both happy and unhappy paths. </p> <p>Code Coverage describes what percentage of the code is tested, based on the lines of code. It provides a rough metric of how well code has been tested. It can be used to determine whether, when new code is added, more or less code overall is being tested. </p> <p>Considerations</p> <p>Unit Testing</p> <ul> <li>Mocking can lead to brittle tests. That is, if complex behavior is simulated in some mocked code, then the mocking code will need to be modified when the component it is mocking changes. An additional problem is that the component being mocked might change, but developers fail to update the mock of the component. In this case, the unit test passes, despite the fact that the component being tested would fail at integration and system testing. </li> </ul> <p>Code Coverage</p> <ul> <li>Code coverage should be higher for complex pieces of code. </li> </ul>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#code-auditing","title":"Code Auditing","text":"<p>Code audits are necessary to ensure that a protocol's code performs as per its intended logic. Code that has not been audited is far more likely to contain bugs than code that has. Any protocol that does not have code audits should be trusted less by users and developers. However, code audits should not be viewed as a comprehensive security solution. For example, protocols sometimes conduct audits on specific parts of their architecture or deploy unaudited code for changes/new features, which can be a potential source of risk outside of the initial audit.</p> <p>Considerations:</p> <ul> <li> <p>Has the code been audited? How many audits have been completed? Were these audits conducted by different organizations?</p> <p>Several audits, ideally by different organizations, are more likely to uncover more potential vulnerabilities.</p> </li> <li> <p>When was the most recent audit? Has the protocol been upgraded since the last audit? How often is the protocol's code audited? </p> <p>Ensuring audits are up-to-date with code changes and are conducted frequently offers more assurance about their validity.</p> </li> <li> <p>What was the scope of the audit? Does it cover all of the key on-chain components?</p> <p>Wide audit scope offers assurances around more parts of the protocol. At a minimum, however, audits should cover all core on-chain contracts. </p> </li> <li> <p>Is the deployed version of the protocol's code audited?</p> </li> <li> <p>What were the findings of the audit? Were there critical findings that were left unaddressed? What are the scenarios in which these could be exploited?</p> <p>Sometimes findings are \"acknowledged\" by team members but not addressed either because the attack scenarios are mitigated by other means, are considered difficult to pull off, or the requested changes are difficult to make. Understanding these findings enables a better assessment of the potential implementation risks.</p> </li> <li> <p>What are the audit firm's track record and reputation?</p> <p>Not all audit firms are created equal. The level of confidence around the audit might need to be weighted by their track record, reputation, or other measures of the caliber of the team.</p> </li> <li> <p>Have changes made in response to audit findings been audited? If not, how significant are these changes?</p> <p>The critical bug that led to the Nomad hack in August 2022 was introduced during a response to the auditor's findings. While Nomad's team was under the impression that the post-remediation code changes were re-audited by the auditor, it was, in fact, not the case. The auditor's report only certified the state of the codebase prior to the changes. </p> </li> </ul> <p>While code audits are vital to ensure the robustness of a protocol, they do not guarantee security. In the past, protocols have been compromised despite completing several audits. Thus, audits should only be one of the risk management strategies used by protocols, but not their entire security stack against hacks.</p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#open-source-code","title":"Open Source Code","text":"<p>If the code is stored in a public Github repository, it allows people  to review the code and the test system. If many people view the code,  then it is likely that defects in the code will be found. Additionally,  it allows for the assessment of such things as the number of tests.</p> <p>Some people argue that a private Github repository is more secure,  believing that issues can be hidden from attackers. However,  attackers who are sufficiently motivated often obtain access  of private repository or to a copy of the code, and are then  able to exploit any vulnerabilities. Not having the repository  public then hinders white hat developers from helping, in the  case of an attack.</p> <p>When using a public repository, it is important that issues that  relate to vulnerabilities and code fixes for vulnerabilities are  not put on the public repository before a release including the  vulnerability fix has been deployed. Not doing this equates to  publishing vulnerabilities that can be used to exploit the  project. The approach that should be taken is to review and  test the vulnerability fix using the private repo, deploy  from the private repo, and the push the fix to the public  repo. </p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#verified-code-on-block-explorer","title":"Verified Code on Block Explorer","text":"<p>Source code verification for all deployed smart contracts is critical for user safety. It ensures that the source code of a protocol\u2019s smart contract is the same as the one executed at the contract address. Moreover, it allows users interacting with a protocol\u2019s smart contract to read and audit it. This enables them to determine what code has been deployed and what types of risks the user is taking by interacting with the protocol. As a result, if a protocol\u2019s code isn\u2019t verified, it is considered less transparent and should be trusted less by users and developers. </p> <p>All deployed contracts should have source code uploaded and verified on Etherscan, or other block explorers specific to the chain if the contracts are deployed on an EVM-compatible chain. For instance, code for smart contracts on Polygon can be verified on Polygonscan, and those on Arbitrum can be verified on Arbiscan.  For non-EVM compatible chains, the practice of source-code verification through block explorers is not a standard and is typically not supported. However, there often exist other tools or processes that are considered a standard for source code verification for specific programming languages used by different non-EVM chains. For instance, Move Prover (MVP) is used to verify smart contracts written in the Move programming language for chains like Aptos and Sui. Thus, entities building applications on these need to find different ways to ensure the trustworthiness of their deployed smart contracts.</p> <p>Additionally, one should verify that the security parameters that govern the logic of smart contracts are initialized as expected. Any discrepancies at the initialization of a smart contract could be a risk vector. For instance, in the case of Celo\u2019s Optics bridge, the recovery mode timelock was initialized at only 1 second instead of the expected 1 day, leaving users\u2019 funds at risk.</p> <p>The process of verifying source code on a block explorer like Etherscan typically includes the following steps:</p> <ol> <li>Enter the contract address that needs to be verified.  </li> <li>Input the compilation settings (like compiler type and version, the open-source license) to a compiler. </li> <li>Provide the source code that makes up the smart contract.</li> <li>The verification tool compares the deployed bytecode with the recompiled bytecode. If the codes match, the contract is deemed verified.</li> <li>Once verified, the smart contract is marked \u201cverified\u201d and is curated under the \u201cVerified Contracts'' in the \u201cBlockchain\u201d tab. </li> </ol> <p>Considerations:</p> <ul> <li> <p>What tool has been used to verify the source code?</p> <p>Source code can be verified by different tools such as Etherscan, Sourcify, Tenderly, etc., but not all tools are created equal. The level of confidence around the source code verification must be assessed based on the tool used. For instance, for contracts deployed on Ethereum, Etherscan\u2019s verify contract code tool is considered a trustworthy tool.</p> </li> <li> <p>Are all smart contracts of the application verified?</p> <p>It\u2019s critical for the source code of all key smart contracts of a protocol to be verified. It\u2019s possible for protocols to verify only certain smart contracts while hiding malicious code to give a false perception of its smart contracts being verified.</p> </li> <li> <p>Could the protocol be less transparent about their source code on purpose? </p> <p>The rule should always be to trust, but verify. If the source code isn\u2019t verified, a protocol can be a potential rug, hiding the real intention of their smart contract. Or, the protocol could be following the practice of \u2018security through obscurity', keeping the code unverified and thus private to prevent people from learning about how a specific feature works and potentially misusing it.</p> </li> </ul>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#documentation","title":"Documentation","text":"<p>More documentation makes a project easier to analyze. A lack  of documentation can lead to confusion and issues being  missed. Projects that have good documentation are easier  to maintain.</p> <p>Types of documentation a good project should have are:</p> <ul> <li>Architecture document that includes the component and deployment architecture.</li> <li>Thread model that includes all parts of the project.</li> <li>Sequence diagrams for all major data flows.</li> <li>Test plan describing how the project will be tested.</li> <li>Smart contract code comments at the contract and function level.</li> <li>Off-chain code with comments at the class and method level.</li> <li>Test code with at least a class level comment.</li> </ul>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#bug-bounty","title":"Bug Bounty","text":"<p>A public bug bounty program incentivizes whitehats to uncover and safely disclose vulnerabilities that might exist in a protocol. This increases the number of people that can thoroughly scrutinize a codebase and prevent exploits by malicious actors. Bug bounties have to offer adequate compensation and have clear scope covering the protocol's critical elements. The process requires trust and transparency and should ideally be managed by an independent third party (e.g., Immunefi).</p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#responding-to-materialized-risk","title":"Responding to Materialized Risk","text":""},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#ability-to-pause-project","title":"Ability to Pause Project","text":"<p>This section described the implementation risks associated with being able to pause a project.  Operational risks related to pausing are covered in the Ability to Pause Operational Risk section.</p> <p>All Data Plane functions should be pausable. For example, a bridge contract could  have a function that could transfer coins based on actions on another blockchain.  The ability to pause a function in a  project allows administrators to stop functions from successfully  executing. If there is a vulnerability that is being actively  exploited in a project, having the ability to pause a function  could stop the exploitation of the project midway through the  attack.</p> <p>For Ethereum based projects, the OpenZeppelin project has an example   contract Pausable.sol that can be used to implement pausing. Using this template,  pausing a function becomes as simple as adding a modifier <code>whenNotPaused</code>.  The code below shows how this would work in practice.</p> <pre><code>contract Example is Pausable {\n    function pause() external onlyOwner {\n        _pause();\n    }\n    function transfer(\n        address _sender,\n        address _tokenContract,\n        address _recipient,\n        uint256 _amount\n    ) external whenNotPaused {\n        // Only executed when not paused\n</code></pre> <p>When analyzing whether a project can be paused, it is important to check whether all data processing functions can be paused, or just some parts of the project. </p> <p>Example</p> <p>For example, in August 2022 the Nomad Bridge had an issue (see Rekt for an analysis of the issue from  people outside the team). An attacker was able to determine a methodology for stealing funds using the <code>Replica</code>  contract's <code>process()</code> function. Depite most of the Data Plane processing functions  in the project being pausable, the <code>process()</code> function was not. This meant that the  attack was able to proceed without the administrators of the project being able to stop it. </p>"},{"location":"framework/20categories/30implementation/protocol-implementation-risk/#ability-to-ban-addresses","title":"Ability to Ban Addresses","text":"<p>Addresses may be associated with stolen funds. Tornado Cash was  a project that had sanctions placed against it due to its  association with stolen funds. Projects that have the  ability to block these addresses, or freeze in-transit funds  are more likely to avoid this type of regulatory risk.</p>"},{"location":"framework/20categories/30implementation/secret-storage/","title":"Secret storage","text":""},{"location":"framework/20categories/30implementation/secret-storage/#secret-storage","title":"Secret Storage","text":"<p>Most projects use cryptographic keys to operate the system.  These keys could be stored in a network HSM or a hardware  wallet, and not in a file on disk on a server. </p>"},{"location":"framework/20categories/30implementation/testing/","title":"Testing","text":""},{"location":"framework/20categories/30implementation/testing/#testing","title":"Testing","text":"<p>Code that is not tested is far more likely to contain bugs than code that has been tested. Comprehensive tests allow new features to be added without fear of breaking existing functionality. Hence, the more comprehensive the testing of the project, the less risky the project is. </p> <p>Testing falls into several categories:</p> <ul> <li>Unit Testing: Checks the operation of a single component, module, class, or contract in isolation. Because of the low level nature of this testing, it should be possible to check all error conditions. Mocking can be used to simulate the behavior of real components that are relied upon by the component to be tested.</li> <li>Integration Testing: Checks the operation of multiple components together. </li> <li>System Testing: Checks the operation of the entire product. This testing could check the system with no data, simulating a new install, with prefilled data simulating multiple years of operation, or could use real world data. A type of System Testing is Upgrade Testing. This type of testing checks that existing version(s) of the system can be upgraded to the new version of the system. System testing is also known as Regression Testing or End to End Testing. </li> <li>Performance Testing: Measures the latency, speed of operation, gas usage, transactions per second, or some other metric. These tests can be used to check that the performance of a system has not degraded from one software release to the next. Performance testing can be done at the unit, integration or system level. </li> <li>Acceptance Testing: Checks that the software can be deployed and that the deployed software operates as expected.</li> <li>Interoperability Testing: Checks that two software products can communicate based on a standard.</li> </ul> <p>Testing can be automated or manual. Automated tests allows software to be tested using scripts. Continuous Integration is a form of automated testing that runs a test script when code is committed to a source code repository. Manual testing requires people to perform a sequence of tests. As manual testing is labor intensive, there is the risk that it is performed for some software releases and not other software releases. As such, it is preferable to only rely on manual testing to do some Acceptance Testing, and not to rely on it to perform other forms of testing, for instance System Testing. </p> <p>Tests can be happy path tests that only check the operation of the software in ideal conditions. Unhappy path tests check what occurs when an error condition arises. Tests should check both happy and unhappy paths. </p> <p>Code Coverage describes what percentage of the code is tested, based on the lines of code. It provides a rough metric of how well code has been tested. It can be used to determine whether, when new code is added, more or less code overall is being tested. </p> <p>Considerations</p> <p>Unit Testing</p> <ul> <li>Mocking can lead to brittle tests. That is, if complex behavior is simulated in some mocked code, then the mocking code will need to be modified when the component it is mocking changes. An additional problem is that the component being mocked might change, but developers fail to update the mock of the component. In this case, the unit test passes, despite the fact that the component being tested would fail at integration and system testing. </li> </ul> <p>Code Coverage</p> <ul> <li>Code coverage should be higher for complex pieces of code. </li> </ul>"},{"location":"framework/20categories/30implementation/upgrade/","title":"Upgrade","text":""},{"location":"framework/20categories/30implementation/upgrade/#upgradable","title":"Upgradable","text":"<p>Like any software, smart contracts software can have bugs. This is true of both code that appears to be extremely simple and more complex code. Additionally, applications may require new features. As such, many projects have the ability to upgrade their smart contract code.</p> <p>Having the ability to upgrade a contract is inherently risky as it can lead to rug-pulling attacks, where the operators of a project change the contract logic and steal customer funds (for instance the Hunter Defi rug-pull). However, as a proportion of both the number of cypto rug pull attacks and as a proportion of the projects that use upgradable contracts, using contract upgrade as a method of stealing funds is very rare. We have no hard statistics on this; this is just an observation.</p> <p>Another major source of risk related to upgrading a contract is that vulnerabilities can either be introduced due to the new code, or the interaction of the new code with the old data. This was the source of the issue in the Nomad hack in August 2022.</p> <p>An important consideration is the processes and controls that govern contract upgrades. That is, who can perform upgrades, how decentralised is this privilege, are there timelocks such that upgrades take effect at some time after the upgrade is triggered. Many of these governance considerations are covered in the Role Based Access Control section.</p> <p>The three common methodologies for upgrading smart contracts are:</p> <ul> <li>Data Holder Upgrade Pattern: Have a data holder contract and a separate business logic contract. The business logic contracts are upgraded, and connect to the existing data holder contracts. Issues with this approach are that new versions of the business logic contract need to be able to utilise old data formats stored in the data holder contract.</li> <li>Transparent Upgrade Proxy Pattern: Have a transparent upgrade proxy contract and a business logic contract. The business logic contract executes in the context of the upgrade proxy contract. The upgrade logic resides in the proxy contract. Issues with this approach are that extreme caution needs to be exercised to ensure there are no storage slot collisions between the proxy and the business logic contracts, and between different versions of the business logic contract.</li> <li>Transparent Upgrade Proxy Pattern with Upgradable Upgrade Logic: As per the Transparent Upgrade Proxy Pattern described above, but with the upgrade logic in the business logic contract. The advantage of this approach is that governance that exists in the business logic contract can be used to approve the upgrade. Issues with this approach over and above the issues with the Transparent Upgrade Proxy Pattern approach is that bugs with the business logic contract can interfere with the upgrade logic, thus preventing upgrade, or enabling an attacker to maliciously upgrade the contract.</li> </ul> <p>In summary, having the ability to upgrade the contracts of a project has risks. However, not having the ability to upgrade contracts, thus resolving bugs, has other, possibly larger risks.</p>"},{"location":"framework/20categories/30implementation/verified-code/","title":"Verified code","text":""},{"location":"framework/20categories/30implementation/verified-code/#verified-code-on-block-explorer","title":"Verified Code on Block Explorer","text":"<p>Source code verification for all deployed smart contracts is critical for user safety. It ensures that the source code of a protocol\u2019s smart contract is the same as the one executed at the contract address. Moreover, it allows users interacting with a protocol\u2019s smart contract to read and audit it. This enables them to determine what code has been deployed and what types of risks the user is taking by interacting with the protocol. As a result, if a protocol\u2019s code isn\u2019t verified, it is considered less transparent and should be trusted less by users and developers. </p> <p>All deployed contracts should have source code uploaded and verified on Etherscan, or other block explorers specific to the chain if the contracts are deployed on an EVM-compatible chain. For instance, code for smart contracts on Polygon can be verified on Polygonscan, and those on Arbitrum can be verified on Arbiscan.  For non-EVM compatible chains, the practice of source-code verification through block explorers is not a standard and is typically not supported. However, there often exist other tools or processes that are considered a standard for source code verification for specific programming languages used by different non-EVM chains. For instance, Move Prover (MVP) is used to verify smart contracts written in the Move programming language for chains like Aptos and Sui. Thus, entities building applications on these need to find different ways to ensure the trustworthiness of their deployed smart contracts.</p> <p>Additionally, one should verify that the security parameters that govern the logic of smart contracts are initialized as expected. Any discrepancies at the initialization of a smart contract could be a risk vector. For instance, in the case of Celo\u2019s Optics bridge, the recovery mode timelock was initialized at only 1 second instead of the expected 1 day, leaving users\u2019 funds at risk.</p> <p>The process of verifying source code on a block explorer like Etherscan typically includes the following steps:</p> <ol> <li>Enter the contract address that needs to be verified.  </li> <li>Input the compilation settings (like compiler type and version, the open-source license) to a compiler. </li> <li>Provide the source code that makes up the smart contract.</li> <li>The verification tool compares the deployed bytecode with the recompiled bytecode. If the codes match, the contract is deemed verified.</li> <li>Once verified, the smart contract is marked \u201cverified\u201d and is curated under the \u201cVerified Contracts'' in the \u201cBlockchain\u201d tab. </li> </ol> <p>Considerations:</p> <ul> <li> <p>What tool has been used to verify the source code?</p> <p>Source code can be verified by different tools such as Etherscan, Sourcify, Tenderly, etc., but not all tools are created equal. The level of confidence around the source code verification must be assessed based on the tool used. For instance, for contracts deployed on Ethereum, Etherscan\u2019s verify contract code tool is considered a trustworthy tool.</p> </li> <li> <p>Are all smart contracts of the application verified?</p> <p>It\u2019s critical for the source code of all key smart contracts of a protocol to be verified. It\u2019s possible for protocols to verify only certain smart contracts while hiding malicious code to give a false perception of its smart contracts being verified.</p> </li> <li> <p>Could the protocol be less transparent about their source code on purpose? </p> <p>The rule should always be to trust, but verify. If the source code isn\u2019t verified, a protocol can be a potential rug, hiding the real intention of their smart contract. Or, the protocol could be following the practice of \u2018security through obscurity', keeping the code unverified and thus private to prevent people from learning about how a specific feature works and potentially misusing it.</p> </li> </ul>"},{"location":"framework/20categories/40operation/ability-pause/","title":"Ability pause","text":""},{"location":"framework/20categories/40operation/ability-pause/#ability-to-pause","title":"Ability to Pause","text":"<p>The pausing capability described in the Ability to Pause Implementation Risk section is only effective if the <code>pause()</code> function can be executed expeditiously. Typically, attacks on protocols are mounted in time periods ranging from minutes to hours. As such, pausing a project several hours after an attack has commenced  is unlikely to be effective, as by this time, the project may have already been drained of funds.</p> <p>To prevent malicious parties unnecessarily halting the project by calling the <code>pause()</code> function, <code>pause()</code> functions need to have some form of access control. </p> <p>For projects operated by a single organization, a simple administration set-up could be used. However, as described below, this has serious issues. For example, a single administrator account (that is an owner account) could be the only party authorized to call the <code>pause()</code> function. However, to be responsive to the need to pause the project, the private key belonging to the administrator account would need to be shared with support staff who live in timezones around the world. The issue with sharing a single private key is that it would be impossible to determine which support staff member used the key to pause the project. Additionally, if one of the support staff left the company or were compromised, then the shared key would need to be changed.</p> <p>A better approach to using a shared key is to provide each support staff member with their own administrator account, and provide all accounts with the Pauser Role. The advantage of this approach over using a shared key is that the account that pauses the project can be associated with a specific support staff member. Additionally, if one of the support staff left the company or were compromised, then only their account would need to be disabled. This would allow the other support staff to operate without changing their keys.</p> <p>For projects that are operated by multiple organizations the pausing capability should be controlled by a multi-signature wallet. Multi-signature wallets have a threshold number of owners that must vote for a proposed transaction. In the case of pausing, the proposed transaction would be to call the <code>pause()</code> function. Within the application contract, the multi-signature wallet contract would be authorized to call the <code>pause()</code> function.</p> <p>Many projects also incorporate services that monitor the operation of the project. The services could be authorized to call the <code>pause()</code> function automatically based on the detection of anomalous conditions. This automatic pausing capability needs to operate in parallel with the other manual approaches described above.</p> <p>The pausing operations described above typically are performed by Bridge Operators. Granting Bridge Validators the right to pause bridges has merit as the validators role is to verify state updates. They are likely to be able to detect anomalous behavior. </p> <p>Things to consider when setting up a multi-signature wallet and the threshold, are:</p> <ul> <li>How timezone dispersed the owners are. If they are mostly located in the one timezone region, then pausing will be difficult if an attack is mounted when most are asleep. The threshold for pausing could be lowered to match the number of owners in various timezones across the world. In this way, the project to be paused even if the time an attack is mounted is when most owners are asleep.</li> <li>How engaged are the owners. Owners who are volunteers may not be as responsive as is needed to pause a project expeditiously.</li> <li>If the threshold is too low, then perhaps a subset of owners who are not happy with the project's direction could choose to disrupt the project by pausing the project.</li> <li>How independent are the owners? If multiple owners rely on a single party to hold or operate their keys, then that party effectively has multiple votes.</li> <li>Attackers could target owners, aiming to gain access to their key. They could pause the project if they can gain access to the threshold number of keys.</li> </ul>"},{"location":"framework/20categories/40operation/decentralization/","title":"Decentralization","text":""},{"location":"framework/20categories/40operation/decentralization/#decentralization-of-operations","title":"Decentralization of Operations","text":"<p>Third-party Attestation Protocols rely on sets of independent parties. For example, in a Proof of Authority protocol messages are deemed valid if at least <code>M</code> of <code>N</code> parties sign messages. The Third-party Attestation Protocols section described a set of considerations that should be taken into account when reviewing these protocols. This section highlights the critical importance of ensuring the operation of a protocol delivers on the security guarantees of the protocol design. </p> <p>When external parties attempt to audit the security of the protocol deployment, they will reason about the security of the protocol based on the threshold number of signers (<code>M</code>) and the total number of signers (<code>N</code>). They will expect that at least <code>M</code> parties would need to be compromised, or choose to maliciously sign a value, for a malicious message to be trusted. If one party controls multiple signers, then the true security of the system is different to what it first appears. For example, if one party controls <code>M - 1</code> signers, then an attacker would only need to compromise that party, and one of the other independent parties. This is what occurred in the Ronin bridge hack.</p> <p>Another operational consideration is latency and compensation. Parties might only be compensated if they sign messages. If a message is submitted to a contract immediately after (<code>M</code>) parties have signed a message, then it may be that the (<code>M</code>) parties that have lowest latency between each other sign most or all of the messages. In this situation, parties with high latency relative to other parties are not as heavily incentivized as parties that have low latency.</p> <p>All parties could be compensated to participate, whether their signature is one of the <code>M</code> signatures used or not. In this situation, parties that have high latency relative to other parties are still compensated. Additionally, this means that parties that are temporarily offline are also compensated. A challenge for protocols like this is to prove that all <code>N</code> signers are usually online and are actively participating in the protocol. </p> <p>Complex inter-node communications mechanisms can be setup to ping nodes, to check that the parties are participating in the protocol. However, the question then is how to prove that a party did not reply and how to prove this in a forum, probably on-chain, that can be used to slash parties not following the protocol.</p>"},{"location":"framework/20categories/40operation/diversity-code/","title":"Diversity code","text":""},{"location":"framework/20categories/40operation/diversity-code/#codebase-diversity","title":"Codebase Diversity","text":"<p>Is there just one implementation, or have multiple parties implemented the protocol?</p>"},{"location":"framework/20categories/40operation/offchain-security/","title":"Offchain security","text":""},{"location":"framework/20categories/40operation/offchain-security/#security-of-off-chain-systems","title":"Security of off-chain systems","text":"<p>TODO</p> <p>(e.g. validators) Standard security practices such as ISO27001</p>"},{"location":"framework/20categories/40operation/operational-security/","title":"Operational security","text":""},{"location":"framework/20categories/40operation/operational-security/#operational-security","title":"Operational Security","text":"<p>Operational Security (also known as OPSEC) is a process used to protect sensitive information. The idea is to determine how to protect sensitive information by viewing operations from the perspective of an attacker. The processes originated during the Vietnam War. The following sections discuss the five steps of the Operational Security process.</p>"},{"location":"framework/20categories/40operation/operational-security/#identification-of-sensitive-information","title":"Identification of Sensitive Information","text":"<p>The first step of Operational Security is identifying what information needs to be protected, and the relative sensitivity level of each type of information. In the context of a crosschain protocol, sensitive information will to include:</p> <ul> <li>Private Keys used to sign blockchain transactions.</li> <li>Private Keys used to attest to the validity of information in the crosschain protocol.</li> <li>Private Keys used as part of blockchain consensus protocols.</li> <li>Private Keys associated with a Transport Layer Security (TLS) web server certificate. </li> <li>Private Keys used with key agreement and asymmetric encryption protocols. </li> <li>Private Keys used with PGP and other signed and encrypted email.</li> <li>Passwords.</li> <li>Information about and code fixes for security vulnerabilities that have not yet been deployed into production.</li> </ul> <p>Sensitive information could also include:</p> <ul> <li>The organization's Org Chart. This allows attackers to identify specific individuals to target with Spear Phishing attacks. Note that social media platforms such as LinkedIn are used by attackers to determine organizations' org charts.</li> <li>Identities of validators or other entities that help operate the crosschain protocol. Attackers could target entities involved in the protocol with Spear Phishing attacks.</li> <li>Internal organizational procedures. Sensitive procedures include obvious ones such as vulnerability response procedures and what security software is installed on company computers, but also includes whether employees use company issued computers or use their own computer (that is Bring Your Own Device), software development practices, and HR policies.</li> <li>Architecture and design information. Most crosschain protocols publish their system architecture and design information; hoping that this will provide users of their protocol greater assurance of the trustworthiness of the protocol. However, publishing design information makes it easier for attackers to identify potential weak points in the system.</li> <li>Source code. Most crosschain protocol code is open source. This allows everyone to review the code, thus helping to provide users with assurance that the code has been written with security in mind. However, attackers are also able to view the code, and may be able to identify vulnerabilities in the code.  </li> <li>Known issues with source code. As most crosschain protocol code is open source, it is common for reported issues to be also publicly available. Sometimes the reported issues, though appearing to be innocuous, may highlight security issues.</li> <li>Server log file information. This information is likely to indicate the usage of the protocol, which may be commercially sensitive. It may also provide insights into unexpected behavior within the protocol. Attackers may use this unexpected behavior to mount attacks.</li> </ul>"},{"location":"framework/20categories/40operation/operational-security/#analysis-of-threats","title":"Analysis of Threats","text":"<p>The second step of Operational Security is identifying possible actors for each of the categories of sensitive information and analyzing their capabilities. For crosschain protocols threats are likely to come from several groups:</p> <ul> <li>Attackers aiming to steal funds from the crosschain protocol. These attackers can range in sophistication from people new to blockchain to state sponsored hackers such as North Korea's Lazarus Group.</li> <li>Attackers or competitors aiming to discredit or reduce trust in the crosschain protocol.</li> <li>General Front Running Bots viewing transactions in the transaction pool and submitting similar transactions ahead of the original transactions. These bots could see an attack in progress and would then attempt to execute the attack repeatedly automatically. </li> <li>White Hat Hacker hoping to earn a bug bounty for identifying an issue.</li> <li>University researchers aiming to identify vulnerabilities in protocols. If they can claim credit for finding the vulnerability, then they will be able to write an academic paper about the issue, and gain academic recognition. This is particularly important for Doctoral Candidates who need to contribute some original research to complete their doctorate.</li> <li>Disgruntled employees and other insiders acting maliciously.</li> </ul>"},{"location":"framework/20categories/40operation/operational-security/#analysis-of-weaknesses","title":"Analysis of Weaknesses","text":"<p>Given the information being protected, and the possible threat actors, assess the current safeguards that are in place. From there, and determine what weaknesses exist.</p>"},{"location":"framework/20categories/40operation/operational-security/#assessment-of-risk","title":"Assessment of Risk","text":"<p>The next step is to rank each of the weaknesses to determine the likelihood of the attack happening and the likely impact of the attack. The likely impact will include the immediate financial loss, reputational damage, and the time to address the attack. The more likely an attack and the higher the likely loss, the higher the priority should be to mitigate the weakness.</p>"},{"location":"framework/20categories/40operation/operational-security/#application-of-countermeasures","title":"Application of Countermeasures","text":"<p>The final step of Operational Security is to mitigate risks. The range of possible countermeasures is vast and beyond the scope of this document. However, two important mitigations are Responsible Disclosure and Bug Bounty Programs. White Hackers will have a means of being compensated for finding issues with a Bug Bounty Program. University researchers will have a means of reporting their findings and be sure to be able to claim recognition with a Responsible Disclosure process. Not having these programs in place may lead White Hat Hackers to attack the system and return some percentage of their attack earnings, while retaining the rest as a Bug Bounty, and may lead university researchers to publish their results prior to contacting the crosschain project. </p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/","title":"Protocol Operation Risk","text":""},{"location":"framework/20categories/40operation/protocol-operation-risk/#operational-security","title":"Operational Security","text":"<p>Operational Security (also known as OPSEC) is a process used to protect sensitive information. The idea is to determine how to protect sensitive information by viewing operations from the perspective of an attacker. The processes originated during the Vietnam War. The following sections discuss the five steps of the Operational Security process.</p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#identification-of-sensitive-information","title":"Identification of Sensitive Information","text":"<p>The first step of Operational Security is identifying what information needs to be protected, and the relative sensitivity level of each type of information. In the context of a crosschain protocol, sensitive information will to include:</p> <ul> <li>Private Keys used to sign blockchain transactions.</li> <li>Private Keys used to attest to the validity of information in the crosschain protocol.</li> <li>Private Keys used as part of blockchain consensus protocols.</li> <li>Private Keys associated with a Transport Layer Security (TLS) web server certificate. </li> <li>Private Keys used with key agreement and asymmetric encryption protocols. </li> <li>Private Keys used with PGP and other signed and encrypted email.</li> <li>Passwords.</li> <li>Information about and code fixes for security vulnerabilities that have not yet been deployed into production.</li> </ul> <p>Sensitive information could also include:</p> <ul> <li>The organization's Org Chart. This allows attackers to identify specific individuals to target with Spear Phishing attacks. Note that social media platforms such as LinkedIn are used by attackers to determine organizations' org charts.</li> <li>Identities of validators or other entities that help operate the crosschain protocol. Attackers could target entities involved in the protocol with Spear Phishing attacks.</li> <li>Internal organizational procedures. Sensitive procedures include obvious ones such as vulnerability response procedures and what security software is installed on company computers, but also includes whether employees use company issued computers or use their own computer (that is Bring Your Own Device), software development practices, and HR policies.</li> <li>Architecture and design information. Most crosschain protocols publish their system architecture and design information; hoping that this will provide users of their protocol greater assurance of the trustworthiness of the protocol. However, publishing design information makes it easier for attackers to identify potential weak points in the system.</li> <li>Source code. Most crosschain protocol code is open source. This allows everyone to review the code, thus helping to provide users with assurance that the code has been written with security in mind. However, attackers are also able to view the code, and may be able to identify vulnerabilities in the code.  </li> <li>Known issues with source code. As most crosschain protocol code is open source, it is common for reported issues to be also publicly available. Sometimes the reported issues, though appearing to be innocuous, may highlight security issues.</li> <li>Server log file information. This information is likely to indicate the usage of the protocol, which may be commercially sensitive. It may also provide insights into unexpected behavior within the protocol. Attackers may use this unexpected behavior to mount attacks.</li> </ul>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#analysis-of-threats","title":"Analysis of Threats","text":"<p>The second step of Operational Security is identifying possible actors for each of the categories of sensitive information and analyzing their capabilities. For crosschain protocols threats are likely to come from several groups:</p> <ul> <li>Attackers aiming to steal funds from the crosschain protocol. These attackers can range in sophistication from people new to blockchain to state sponsored hackers such as North Korea's Lazarus Group.</li> <li>Attackers or competitors aiming to discredit or reduce trust in the crosschain protocol.</li> <li>General Front Running Bots viewing transactions in the transaction pool and submitting similar transactions ahead of the original transactions. These bots could see an attack in progress and would then attempt to execute the attack repeatedly automatically. </li> <li>White Hat Hacker hoping to earn a bug bounty for identifying an issue.</li> <li>University researchers aiming to identify vulnerabilities in protocols. If they can claim credit for finding the vulnerability, then they will be able to write an academic paper about the issue, and gain academic recognition. This is particularly important for Doctoral Candidates who need to contribute some original research to complete their doctorate.</li> <li>Disgruntled employees and other insiders acting maliciously.</li> </ul>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#analysis-of-weaknesses","title":"Analysis of Weaknesses","text":"<p>Given the information being protected, and the possible threat actors, assess the current safeguards that are in place. From there, and determine what weaknesses exist.</p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#assessment-of-risk","title":"Assessment of Risk","text":"<p>The next step is to rank each of the weaknesses to determine the likelihood of the attack happening and the likely impact of the attack. The likely impact will include the immediate financial loss, reputational damage, and the time to address the attack. The more likely an attack and the higher the likely loss, the higher the priority should be to mitigate the weakness.</p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#application-of-countermeasures","title":"Application of Countermeasures","text":"<p>The final step of Operational Security is to mitigate risks. The range of possible countermeasures is vast and beyond the scope of this document. However, two important mitigations are Responsible Disclosure and Bug Bounty Programs. White Hackers will have a means of being compensated for finding issues with a Bug Bounty Program. University researchers will have a means of reporting their findings and be sure to be able to claim recognition with a Responsible Disclosure process. Not having these programs in place may lead White Hat Hackers to attack the system and return some percentage of their attack earnings, while retaining the rest as a Bug Bounty, and may lead university researchers to publish their results prior to contacting the crosschain project. </p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#ability-to-pause","title":"Ability to Pause","text":"<p>The pausing capability described in the Ability to Pause Implementation Risk section is only effective if the <code>pause()</code> function can be executed expeditiously. Typically, attacks on protocols are mounted in time periods ranging from minutes to hours. As such, pausing a project several hours after an attack has commenced  is unlikely to be effective, as by this time, the project may have already been drained of funds.</p> <p>To prevent malicious parties unnecessarily halting the project by calling the <code>pause()</code> function, <code>pause()</code> functions need to have some form of access control. </p> <p>For projects operated by a single organization, a simple administration set-up could be used. However, as described below, this has serious issues. For example, a single administrator account (that is an owner account) could be the only party authorized to call the <code>pause()</code> function. However, to be responsive to the need to pause the project, the private key belonging to the administrator account would need to be shared with support staff who live in timezones around the world. The issue with sharing a single private key is that it would be impossible to determine which support staff member used the key to pause the project. Additionally, if one of the support staff left the company or were compromised, then the shared key would need to be changed.</p> <p>A better approach to using a shared key is to provide each support staff member with their own administrator account, and provide all accounts with the Pauser Role. The advantage of this approach over using a shared key is that the account that pauses the project can be associated with a specific support staff member. Additionally, if one of the support staff left the company or were compromised, then only their account would need to be disabled. This would allow the other support staff to operate without changing their keys.</p> <p>For projects that are operated by multiple organizations the pausing capability should be controlled by a multi-signature wallet. Multi-signature wallets have a threshold number of owners that must vote for a proposed transaction. In the case of pausing, the proposed transaction would be to call the <code>pause()</code> function. Within the application contract, the multi-signature wallet contract would be authorized to call the <code>pause()</code> function.</p> <p>Many projects also incorporate services that monitor the operation of the project. The services could be authorized to call the <code>pause()</code> function automatically based on the detection of anomalous conditions. This automatic pausing capability needs to operate in parallel with the other manual approaches described above.</p> <p>The pausing operations described above typically are performed by Bridge Operators. Granting Bridge Validators the right to pause bridges has merit as the validators role is to verify state updates. They are likely to be able to detect anomalous behavior. </p> <p>Things to consider when setting up a multi-signature wallet and the threshold, are:</p> <ul> <li>How timezone dispersed the owners are. If they are mostly located in the one timezone region, then pausing will be difficult if an attack is mounted when most are asleep. The threshold for pausing could be lowered to match the number of owners in various timezones across the world. In this way, the project to be paused even if the time an attack is mounted is when most owners are asleep.</li> <li>How engaged are the owners. Owners who are volunteers may not be as responsive as is needed to pause a project expeditiously.</li> <li>If the threshold is too low, then perhaps a subset of owners who are not happy with the project's direction could choose to disrupt the project by pausing the project.</li> <li>How independent are the owners? If multiple owners rely on a single party to hold or operate their keys, then that party effectively has multiple votes.</li> <li>Attackers could target owners, aiming to gain access to their key. They could pause the project if they can gain access to the threshold number of keys.</li> </ul>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#codebase-diversity","title":"Codebase Diversity","text":"<p>Is there just one implementation, or have multiple parties implemented the protocol?</p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#decentralization-of-operations","title":"Decentralization of Operations","text":"<p>Third-party Attestation Protocols rely on sets of independent parties. For example, in a Proof of Authority protocol messages are deemed valid if at least <code>M</code> of <code>N</code> parties sign messages. The Third-party Attestation Protocols section described a set of considerations that should be taken into account when reviewing these protocols. This section highlights the critical importance of ensuring the operation of a protocol delivers on the security guarantees of the protocol design. </p> <p>When external parties attempt to audit the security of the protocol deployment, they will reason about the security of the protocol based on the threshold number of signers (<code>M</code>) and the total number of signers (<code>N</code>). They will expect that at least <code>M</code> parties would need to be compromised, or choose to maliciously sign a value, for a malicious message to be trusted. If one party controls multiple signers, then the true security of the system is different to what it first appears. For example, if one party controls <code>M - 1</code> signers, then an attacker would only need to compromise that party, and one of the other independent parties. This is what occurred in the Ronin bridge hack.</p> <p>Another operational consideration is latency and compensation. Parties might only be compensated if they sign messages. If a message is submitted to a contract immediately after (<code>M</code>) parties have signed a message, then it may be that the (<code>M</code>) parties that have lowest latency between each other sign most or all of the messages. In this situation, parties with high latency relative to other parties are not as heavily incentivized as parties that have low latency.</p> <p>All parties could be compensated to participate, whether their signature is one of the <code>M</code> signatures used or not. In this situation, parties that have high latency relative to other parties are still compensated. Additionally, this means that parties that are temporarily offline are also compensated. A challenge for protocols like this is to prove that all <code>N</code> signers are usually online and are actively participating in the protocol. </p> <p>Complex inter-node communications mechanisms can be setup to ping nodes, to check that the parties are participating in the protocol. However, the question then is how to prove that a party did not reply and how to prove this in a forum, probably on-chain, that can be used to slash parties not following the protocol.</p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#security-of-off-chain-systems","title":"Security of off-chain systems","text":"<p>TODO</p> <p>(e.g. validators) Standard security practices such as ISO27001</p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#vulnerability-response-plan","title":"Vulnerability Response Plan","text":"<p>A Vulnerability Response Plan is a process of agreed steps to take when an issue is reported with a crosschain protocol (or any other software system). The term vulnerability should be used carefully. When an issue is first reported, it should be considered a possible Security Issue. A Security Issue could be classified as a Vulnerability (also known as a Security Vulnerability) if the issue can be exploited to cause some sort of damage to the crosschain protocol. </p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#identify-a-vulnerability-response-virtual-team","title":"Identify a Vulnerability Response Virtual Team","text":"<p>The Vulnerability Response Virtual Team is a cross functional team that will manage the vulnerability response process. The team should include domain experts such as the lead protocol designer, system architects, and lead engineer, and representatives from teams such as DevOps, SecOps, Product Management, Public Relations, and Executive Management. The team is a virtual team as it draws on team members on an as needs basis. </p> <p>If the team is too large, then the probability of information about the vulnerability leaking increases. Additionally, the more people in the team, the more people who have their focus diverted from their core work. Having the team too small may mean that people who could provide useful insights are excluded. Experts could be brought into a small team on an as needs basis. However, this approach assumes that members of the team can identify the correct people to temporarily bring into the team.</p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#reporting-mechanism","title":"Reporting Mechanism","text":"<p>Organizations should identify and advertise how they expect vulnerabilities to be reported. External parties such as White Hat Hackers and University Researchers (see Section Operational Security) need a mechanism communicate with the Vulnerability Response Virtual Team. This could be via a group email alias or via a web form. </p> <p>People within the organization should have a defined way of reporting vulnerabilities. Using the standard bug tracking system will advertise the issue to anyone who can access the system. Additionally, the true significance of the issue may not be fully understood, and other higher priority issues may be resolved ahead of the vulnerability. Reporting to an individual such as a manager again might mean that the significance of the issue is not fully understood. Allowing the person to directly contact the Vulnerability Response Virtual Team, possibly by the same mechanism as external parties, will ensure the issue is appropriately triaged.</p> <p>Once a vulnerability has been reported to the Vulnerability Response Virtual Team, someone from the team needs to take responsibility as the contact point for the person who reported the issue (from now on, the vulnerability reporter) for the duration of the vulnerability response.  They need to assure the the vulnerability reporter that they are being taken seriously, and that the issue is being triaged. They should provide a realistic schedule for when they will respond to the the vulnerability reporter with the results of the triage process. </p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#triage","title":"Triage","text":"<p>Once a possible Security Issue has been reported to the Vulnerability Response Virtual Team, the issue needs to be triaged. The team can analyze the issue against the following criteria:</p> <ul> <li>Scope: This could be:<ul> <li>Fundamental cryptographic building block: For example, an issue found in a cryptographic algorithm such as SHA256 would affect all protocols and systems using that protocol, and their implementations in all programming languages.</li> <li>A protocol or system: For example, an issue found in a communications protocol such as Transport Layer Security (TLS) would affect all applications that use TLS, independent of programming language.</li> <li>Software Library: All applications and systems using a software library. </li> <li>Crosschain Protocol: The issue just pertains to this crosschain protocol. If the protocol is implemented in a variety of programming languages, does the issue apply to all languages, or just one implementation.</li> </ul> </li> <li>On-chain or off-chain components: Does the issue relate to contracts that are on-chain or off-chain services?</li> <li>Not deployed, Deployed, or Historic: Does the issue relate to code that has never been deployed, is currently deployed, or was deployed previously, but has subsequently been superseded?</li> <li>Direct Impact: What is the direct impact of exploiting the issue? Could funds be stolen? Could a Denial of Service (DOS) be mounted against the protocol? Could private information such as customer data be stolen?</li> <li>Reputational Impact: Could the issue cause reputational loss?</li> </ul> <p>Contact the vulnerability reporter once the triage process has been completed. Discuss the findings of the process and give feedback to the the vulnerability reporter. They may highlight some misunderstandings that the Vulnerability Response Virtual Team has. If the Vulnerability Response Virtual Team feels that there is no substantive issue, it would be good if they could convince the the vulnerability reporter of this, so that they don't go public with their perception that there is a serious issue with the protocol. Assuming there is a vulnerability, the the vulnerability reporter needs to be given the planned schedule of events that will culminate in the vulnerability fix being deployed and the issue being publicly announced.</p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#creating-validating-and-deploying-a-fix","title":"Creating, Validating, and Deploying a Fix","text":"<p>Once how the vulnerability will be addressed is determined, the code for the fix will need to be written, tested, and then deployed. Even if the project uses an open source repository for their main development effort, a private repository must be used for developing, testing and deploying the vulnerability fix code. The reason for this is that submitting vulnerability fix code to a public repository is tantamount to publishing the vulnerability. Even if the time between submitting the vulnerability fix code and deploying it is a matter of ten minutes, this will be long enough for an attacker who is already aware of the vulnerability. The attacker may have been preparing to mount an attack. Faced with the prospect of the vulnerability fix code being deployed soon, the attacker will launch their attack. </p> <p>Prior to deploying the fix, it may be helpful to again reach out to the the vulnerability reporter to check that they too believe the fix will address the vulnerability.</p>"},{"location":"framework/20categories/40operation/protocol-operation-risk/#publishing-a-root-cause-analysis","title":"Publishing a Root Cause Analysis","text":"<p>Immediately after the vulnerability code has been deployed, a Root Cause Analysis should be published. This should identify what the issue was, possible impacts if it had been exploited, how it was resolved, actions that users should take, any bug bounty that has been paid, and, most importantly, it should attribute finding of the vulnerability to the the vulnerability reporter. The publication of this analysis should be coordinated with the the vulnerability reporter as they may wish to publish their own press release. The details of the analysis should be checked with the the vulnerability reporter to ensure they agree with what has been said in the analysis. </p>"},{"location":"framework/20categories/40operation/vulnerability/","title":"Vulnerability","text":""},{"location":"framework/20categories/40operation/vulnerability/#vulnerability-response-plan","title":"Vulnerability Response Plan","text":"<p>A Vulnerability Response Plan is a process of agreed steps to take when an issue is reported with a crosschain protocol (or any other software system). The term vulnerability should be used carefully. When an issue is first reported, it should be considered a possible Security Issue. A Security Issue could be classified as a Vulnerability (also known as a Security Vulnerability) if the issue can be exploited to cause some sort of damage to the crosschain protocol. </p>"},{"location":"framework/20categories/40operation/vulnerability/#identify-a-vulnerability-response-virtual-team","title":"Identify a Vulnerability Response Virtual Team","text":"<p>The Vulnerability Response Virtual Team is a cross functional team that will manage the vulnerability response process. The team should include domain experts such as the lead protocol designer, system architects, and lead engineer, and representatives from teams such as DevOps, SecOps, Product Management, Public Relations, and Executive Management. The team is a virtual team as it draws on team members on an as needs basis. </p> <p>If the team is too large, then the probability of information about the vulnerability leaking increases. Additionally, the more people in the team, the more people who have their focus diverted from their core work. Having the team too small may mean that people who could provide useful insights are excluded. Experts could be brought into a small team on an as needs basis. However, this approach assumes that members of the team can identify the correct people to temporarily bring into the team.</p>"},{"location":"framework/20categories/40operation/vulnerability/#reporting-mechanism","title":"Reporting Mechanism","text":"<p>Organizations should identify and advertise how they expect vulnerabilities to be reported. External parties such as White Hat Hackers and University Researchers (see Section Operational Security) need a mechanism communicate with the Vulnerability Response Virtual Team. This could be via a group email alias or via a web form. </p> <p>People within the organization should have a defined way of reporting vulnerabilities. Using the standard bug tracking system will advertise the issue to anyone who can access the system. Additionally, the true significance of the issue may not be fully understood, and other higher priority issues may be resolved ahead of the vulnerability. Reporting to an individual such as a manager again might mean that the significance of the issue is not fully understood. Allowing the person to directly contact the Vulnerability Response Virtual Team, possibly by the same mechanism as external parties, will ensure the issue is appropriately triaged.</p> <p>Once a vulnerability has been reported to the Vulnerability Response Virtual Team, someone from the team needs to take responsibility as the contact point for the person who reported the issue (from now on, the vulnerability reporter) for the duration of the vulnerability response.  They need to assure the the vulnerability reporter that they are being taken seriously, and that the issue is being triaged. They should provide a realistic schedule for when they will respond to the the vulnerability reporter with the results of the triage process. </p>"},{"location":"framework/20categories/40operation/vulnerability/#triage","title":"Triage","text":"<p>Once a possible Security Issue has been reported to the Vulnerability Response Virtual Team, the issue needs to be triaged. The team can analyze the issue against the following criteria:</p> <ul> <li>Scope: This could be:<ul> <li>Fundamental cryptographic building block: For example, an issue found in a cryptographic algorithm such as SHA256 would affect all protocols and systems using that protocol, and their implementations in all programming languages.</li> <li>A protocol or system: For example, an issue found in a communications protocol such as Transport Layer Security (TLS) would affect all applications that use TLS, independent of programming language.</li> <li>Software Library: All applications and systems using a software library. </li> <li>Crosschain Protocol: The issue just pertains to this crosschain protocol. If the protocol is implemented in a variety of programming languages, does the issue apply to all languages, or just one implementation.</li> </ul> </li> <li>On-chain or off-chain components: Does the issue relate to contracts that are on-chain or off-chain services?</li> <li>Not deployed, Deployed, or Historic: Does the issue relate to code that has never been deployed, is currently deployed, or was deployed previously, but has subsequently been superseded?</li> <li>Direct Impact: What is the direct impact of exploiting the issue? Could funds be stolen? Could a Denial of Service (DOS) be mounted against the protocol? Could private information such as customer data be stolen?</li> <li>Reputational Impact: Could the issue cause reputational loss?</li> </ul> <p>Contact the vulnerability reporter once the triage process has been completed. Discuss the findings of the process and give feedback to the the vulnerability reporter. They may highlight some misunderstandings that the Vulnerability Response Virtual Team has. If the Vulnerability Response Virtual Team feels that there is no substantive issue, it would be good if they could convince the the vulnerability reporter of this, so that they don't go public with their perception that there is a serious issue with the protocol. Assuming there is a vulnerability, the the vulnerability reporter needs to be given the planned schedule of events that will culminate in the vulnerability fix being deployed and the issue being publicly announced.</p>"},{"location":"framework/20categories/40operation/vulnerability/#creating-validating-and-deploying-a-fix","title":"Creating, Validating, and Deploying a Fix","text":"<p>Once how the vulnerability will be addressed is determined, the code for the fix will need to be written, tested, and then deployed. Even if the project uses an open source repository for their main development effort, a private repository must be used for developing, testing and deploying the vulnerability fix code. The reason for this is that submitting vulnerability fix code to a public repository is tantamount to publishing the vulnerability. Even if the time between submitting the vulnerability fix code and deploying it is a matter of ten minutes, this will be long enough for an attacker who is already aware of the vulnerability. The attacker may have been preparing to mount an attack. Faced with the prospect of the vulnerability fix code being deployed soon, the attacker will launch their attack. </p> <p>Prior to deploying the fix, it may be helpful to again reach out to the the vulnerability reporter to check that they too believe the fix will address the vulnerability.</p>"},{"location":"framework/20categories/40operation/vulnerability/#publishing-a-root-cause-analysis","title":"Publishing a Root Cause Analysis","text":"<p>Immediately after the vulnerability code has been deployed, a Root Cause Analysis should be published. This should identify what the issue was, possible impacts if it had been exploited, how it was resolved, actions that users should take, any bug bounty that has been paid, and, most importantly, it should attribute finding of the vulnerability to the the vulnerability reporter. The publication of this analysis should be coordinated with the the vulnerability reporter as they may wish to publish their own press release. The details of the analysis should be checked with the the vulnerability reporter to ensure they agree with what has been said in the analysis. </p>"},{"location":"framework/30scoring/architecture/","title":"Architecture","text":""},{"location":"framework/30scoring/architecture/#architectural-risk-scoring","title":"Architectural Risk Scoring","text":"<p>No aspects of Architectural Risk have been considered when determining the Architectural Risk Score.</p> <p>The equation for the Architecture Risk Score is:</p> <pre><code>Architectural Risk Score = 0\n</code></pre>"},{"location":"framework/30scoring/implementation/","title":"Implementation","text":""},{"location":"framework/30scoring/implementation/#implementation-risk-scoring","title":"Implementation Risk Scoring","text":"<p>Implementation Risk Scoring is based on the Implementation Risk section.</p> <p>The equation for the Implementation Risk Score is:</p> <pre><code>Implementation Risk Score = Maximum of (Reducing Implementation Risk Score, Uncovering Extant Risk Score, and Responding to Materialized Risk Score)\n</code></pre>"},{"location":"framework/30scoring/implementation/#reducing-implementation-risk","title":"Reducing Implementation Risk","text":"<pre><code>Reducing Implementation Risk Score = \n Mixing of Control and Data Plane Risk Score +\n Role Based Access Control Risk Score +\n Upgradable Risk Score +\n Secret Storage Risk Score +\n Product Development Maturity Risk Score +\n Well Known Platform Risk Score +\n Well Known Smart Contract Programming Language Risk Score\n</code></pre>"},{"location":"framework/30scoring/implementation/#mixing-of-control-and-data-plane-risk-score","title":"Mixing of Control and Data Plane Risk Score","text":"<p>Mixing of Control and Data Plane is described in the  Mixing of Control and Data Plane section. If the Control and Data Plane are mixed, then the Mixing of Control and Data Plane Risk Score is 20, or 0 otherwise.</p> <p>The Control and Data Plane are considered mixed if the answer to any of the following questions is yes:</p> <ul> <li>Can Control Plane functions be called from Data Plane functions without some additional authentication checks?</li> <li>If Control Plane messages are sent across the crosschain communications channel, are Control Plane messages signed by the same keys as Data Plane messages?</li> </ul>"},{"location":"framework/30scoring/implementation/#role-based-access-control-risk-score","title":"Role Based Access Control Risk Score","text":"<p>Role Based Access Control is described in the Role Based Access Control section.</p> <p>The Role Based Access Control Risk Score depends on the permissioned control / ownership of the bridge contracts. If there are multiple contracts, and they  are configured differently, then score the highest score.</p> <ul> <li>There is no permissioned ownership feature: Score 0.</li> <li>There a single EOA as the owner: Score 10.</li> <li>Role Based Access Control has been implemented: Score 0.</li> <li>There is no Role Based Access Control, but a threshold number of signers need to approve administrative actions. If number of signers is five or more score 3, otherwise score 5. Additionally, if the number of signers that need to sign is more than 50%, score 0, otherwise score 5.</li> </ul>"},{"location":"framework/30scoring/implementation/#upgradable-risk-score","title":"Upgradable Risk Score","text":"<p>Upgradable Risk is decribed in the Upgradability section.</p> <p>The risks associated with being able to upgrade contracts appear to be similar to the risks associated with not being able to upgrade a contract. As such, the Upgradable Risk Score is always 0.</p>"},{"location":"framework/30scoring/implementation/#secret-storage-risk-score","title":"Secret Storage Risk Score","text":"<p>Secret Storage is described in the Secret Storage section. The Secret Storage Risk Score is defined by the equation below.</p> <pre><code>Secret Storage Risk Score = I401\n</code></pre> Question ID Question I401 Are any private keys, symmetric keys, passwords, or passcodes used in the project stored on disk in a plain text file? If yes, score 20, if no score 0."},{"location":"framework/30scoring/implementation/#product-development-maturity-risk-score","title":"Product Development Maturity Risk Score","text":"<p>Product Development Maturity is described in the Product Development Maturity section. The Product Development Maturity Risk Score is defined by the equation below.</p> <pre><code>Product Development Maturity Risk Score = I501\n</code></pre> Question ID Question I501 Does the organisation building the project have a documented SDLC approach? If yes, score 0, if no score 20."},{"location":"framework/30scoring/implementation/#well-known-platform-risk-score","title":"Well Known Platform Risk Score","text":"<p>The risks associated with not using Well Known Platforms is contained in the Well Known Platform section.</p> <p>Scoring of this category has proven to be controvertial. At present, the risk score for this category is 0.</p>"},{"location":"framework/30scoring/implementation/#well-known-smart-contract-programming-language-risk-score","title":"Well Known Smart Contract Programming Language Risk Score","text":"<p>The risks associated with not using a Well Known Smart Contract Programming Language is contained in the Well Known Smart Contract Programming Language section. </p> <p>Scoring of this category has proven to be controvertial. At present, the risk score for this category is 0.</p>"},{"location":"framework/30scoring/implementation/#uncovering-extant-risk-score","title":"Uncovering Extant Risk Score","text":"<pre><code>Uncovering Extant Risk Score = \n Formal Verification Risk Score +\n Test Risk Score +\n Code Auditing Risk Score + \n Open Source Code Risk Score +\n Verified Code on Block Explorer Risk Score +\n Documentation Risk Score +\n Bug Bounty Risk Score \n</code></pre>"},{"location":"framework/30scoring/implementation/#formal-verification-risk-score","title":"Formal Verification Risk Score","text":"<p>The risks of not formally verifying code is contained in the Formal Verification section.</p> <p>The Formal Verification Risk Score is 5 if the code has not been formally verified, and 0 if it has been formally verified.</p>"},{"location":"framework/30scoring/implementation/#test-risk-score","title":"Test Risk Score","text":"<p>The risks associated with not thoroughly testing an application are described in the Testing section. The Test Risk Score is defined by the equation below.</p> <pre><code>Test Risk Score = I901 + I902 + I903 + I904 + I905 + I906 \n</code></pre> Question ID Question I901 Is there a test plan documenting which tests scenarios should be tested? If yes, score 0, if no score 10. I902 Are contracts unit tested? If yes, score 0, if no score 10. I903 Are their system tests that check the operation of the entire system? If yes, score 0, if no score 10. I904 Is their a continuous integration system that executes unit and system tests automatically on commit to a source code respository? If yes, score 0, if no score 10. I905 Are any of the tests executed by the continuous integration system unreliable (that is, some times unexpectedly fail)? If yes, score 5, if no score 0. I906 Can a product release occur if any test is failing? If yes, score 10, if no score 0."},{"location":"framework/30scoring/implementation/#code-auditing-risk-score","title":"Code Auditing Risk Score","text":"<p>Code auditing is described in detail in the Code Auditing section. The equation for the Code Auditing Risk Score is:</p> <pre><code>Code Audit Risk Score = I1011 + I1012 + I1014 + I1015 + I1013\n</code></pre> Question ID Question I1011 How many times has the on-chain components of the system been audited? If none, score 50, and score 0 for questions I1012, I1013, and I1014. If once score 10, if twice or more score 0. I1012 Has any version of the on-chain components of the system been audited by more than one audit organisation? If yes, score 0. If no, score 5. I1013 For the most recent audit, were all critical issues addressed? If yes, score 0. If no, score 10. I1014 Has the deployed version of the on-chain components of the system been audited? If yes, score 0. If no, score 20. I1015 Has any version of the off-chain components of the system been audited? If yes, score 0. If no, score 20. If the system contains no off-chain components, then score 0. <p>Rationale for scoring:</p> <ul> <li>Unaddressed critical issues could indicate vulnerabilites.</li> <li>Having an audit, addressing issues, and then deploying the revised code without re-auditing can result in vulnerabilities.</li> <li>The quality of audit firms is not factored in the score as this is very subjective. </li> </ul>"},{"location":"framework/30scoring/implementation/#open-source-code-risk-score","title":"Open Source Code Risk Score","text":"<p>The risks of not using open source code for a project are discussed in the Open Source Code section. The equation for the Open Source Code Risk Score is:</p> <pre><code>Open Source Code Risk Score = I1101 + I1102\n</code></pre> Question ID Question I1101 Is the source code of the project in a public code respository? If yes, score 0, otherwise score 10. I1102 Is it possible to develop code and deploy the project from a private repository? That is, can vulnerability fixes be resolved without publishing on the public code repsotory? If yes, score 0, otherwise score 20."},{"location":"framework/30scoring/implementation/#verified-code-on-block-explorer-risk-score","title":"Verified Code on Block Explorer Risk Score","text":"<p>The risks associated with not publishing code to blockchain explorers is covered in the  Verified Code on Block Explorer section. The equation for the Verified Code on Blockchain Explorer Risk Score is:</p> <pre><code>Verified Code on Block Explorer Risk Score = I1201\n</code></pre> Question ID Question I1201 Do all deployed contracts have verified code uploaded to block explorers? If yes, score 0, otherwise score 50."},{"location":"framework/30scoring/implementation/#documentation-risk-score","title":"Documentation Risk Score","text":"<p>The risks associated with not documenting a project well are discussed in the Documentation section. The equation for the Documentation Risk Score is:</p> <pre><code>Documentation Risk Score = I1301 + I1302 + I1303 + I1304 + I1305 + I1306\n</code></pre> Question ID Question I1301 Does the project have architectural documentation? If yes, score 0, otherwise score 5. I1302 Does the project have a documented threat model? If yes, score 0, otherwise score 5. I1303 Does the project have sequence diagrams for all major data flows? If yes, score 0, otherwise score 5. I1304 Are there code comments in smart contract code? If yes, score 0, otherwise score 20. I1305 Are there code comments in the off-chain code? If yes, score 0, otherwise score 5. I1306 Are there code comments in the test code? If yes, score 0, otherwise score 5."},{"location":"framework/30scoring/implementation/#bug-bounty-risk-score","title":"Bug Bounty Risk Score","text":"<p>Bug Bounties are described in detail in the Bug Bounty section. The equation for the Bug Bounty Risk Score is:</p> <pre><code>Bug Bounty Risk Score = I1401\n</code></pre> Question ID Question I1401 Is there a bug bounty for the project?  How big is the bug bounty? <ul><li>There is no bug bounty: Score 15.</li><li>Less than US$10,000: Score 5.</li><li>US$10,000 but less than US$100,000: Score 2.</li><li>More than US$100,000: Score 0.</li></ul>"},{"location":"framework/30scoring/implementation/#responding-to-materialized-risk-score","title":"Responding to Materialized Risk Score","text":"<pre><code>Responding to Materialized Risk Score = \n Ability to Pause Risk Score + \n Ability to Ban Addresses Risk Score\n</code></pre>"},{"location":"framework/30scoring/implementation/#ability-to-pause-risk-score","title":"Ability to Pause Risk Score","text":"<p>The ability to pause a project is described in the Ability to Pause Project section. The equation for the Ability to Pause Risk Score is:</p> <pre><code>Ability to Pause Score = I1501\n</code></pre> Question ID Question I1501 Can all data plane code paths be paused? If yes score 0, otherwise score 20."},{"location":"framework/30scoring/implementation/#ability-to-ban-addresses-risk-score","title":"Ability to Ban Addresses Risk Score","text":"<p>The ability to ban specific addresses is described in the Ability to Ban Addresses section. This capability is in contrast to the censorship resistance property that is of utmost importance to many protocols. So as to not downrank protocols that strive to provide censorship resistance over protocols that provide the ability to ban addresses, the ability to ban addresses is not scored. As such, the Ability to Ban Addresses Risk Score is always 0.</p>"},{"location":"framework/30scoring/network/","title":"Network","text":""},{"location":"framework/30scoring/network/#network-consensus-risk-scoring","title":"Network Consensus Risk Scoring","text":"<p>The Network Consensus Risk Score assesses the risk posed by the Network Consensus properties of the blockchains being bridged.</p> <p>The equation for the Network Consensus Risk Score is:</p> <pre><code>Network Consensus Risk Score = (N001 + N002 + N003 + N004) x 10 / 17\n</code></pre> Question ID Question N001 Finality: Does the crosschain protocol wait for transactions to be final on the source chain prior to acting upon them? <ul><li> Transactions are final: Score 0. </li><li>Transactions are probably final, assuming the maximum sized attack possible with US$100M rented hardware, with a probability of greater than one in 1,000,000,000,000: Score 0.</li><li>Transactions are probably final, assuming the maximum sized attack possible with US$100M rented hardware, with a probability of greater than one in 1,000,000,000: Score 3. </li><li>Transactions are probably final, assuming the maximum sized attack possible with US$100M rented hardware, with a probability of greater than one in 1,000,000: Score 4.</li><li>Transactions are probably final, assuming the maximum sized attack possible with US$100M rented hardware, with a probability of less than one in 1,000,000: Score 5.</li></ul> N002 Network Delays and Liveness Reliability: Has the source chain been offline (excluding planned network upgrades)? <ul><li>Never: Score 0.</li><li>Once in the past year for an hour or less: Score 3.</li><li>More than once in the past year or just once but for longer than an hour: Score 5.</li></ul> N003 Network Delays and Liveness Congestion: Has the source chain been congested such that transactions can not be submitted and included in the blockchain? <ul><li>Never: Score 0.</li><li>Once in the past year for an hour or less: Score 1.</li><li>More than once in the past year or just once but for longer than an hour: Score 2.</li></ul> N004 Network Safety Violations: Has the source chain had any safety violations? <ul><li>Never: Score 0.</li><li>Once in the past year: Score 4.</li><li>More than once in the past year: Score 5.</li></ul> <p>Rationale for scoring:</p> <ul> <li>The ideal configuration is a protocol that only uses information based on transaction that are final on the source chain, and the source chain has never has any liveness or safety issues.</li> </ul>"},{"location":"framework/30scoring/operational/","title":"Operational","text":""},{"location":"framework/30scoring/operational/#operational-risk-scoring","title":"Operational Risk Scoring","text":"<p>The following aspects of Operational Risk are currently not taken into account when assessing the Operational Risk Score: Decentralization of Operations, Diversity of Codebase, and Off-chain Security.</p> <p>The equation for the Operational Risk Score is:</p> <pre><code>Operational Risk Score = (Operational Security Score + Operational Ability to Pause Score + Vulnerability Response Planning Score) x 100 / 29 \n</code></pre>"},{"location":"framework/30scoring/operational/#operational-security-score","title":"Operational Security Score","text":"<p>Operational Security is defined by the ability to meet the properties defined in the Operational Security section. The equation for the Operational Security Score is:</p> <pre><code>Operational Security Score = O001 + O002\n</code></pre> <p>The Operational Security Score ranges from 0 to 2.</p> Question ID Question O001 Has sensitive information as defined in the Operational Security section been identified? Has this information been documented? If yes, score 0. If no, score 1. O002 Is a complete Operational Security process, as described in the Operational Security section implemented? If yes, score 0. If no, score 1."},{"location":"framework/30scoring/operational/#operational-ability-to-pause-score","title":"Operational Ability to Pause Score","text":"<p>The Operational Ability to Pause is defined by the ability to meet the properties defined in the Operational Ability to Pause section. The equation for the Operational Ability to Pause Score is:</p> <pre><code>Operational Ability to Pause Score = O101 + O103 + O104 + O105\n</code></pre> <p>The Operational Ability to Pause Score ranges from 0 to 27.</p> Question ID Question O101 Type of pausing access control: <ul><li>None: Score 10.</li><li>Single EOA controls pausing: Score 8.</li><li>Role Based Access Control with multiple accounts (EOA or contract): Score 5.</li><li>A multisig wallet controls pausing: Score is answer to Question ID O102.</li></ul> O102 Multisig Wallets: Is the threshold of the multisig wallet greater than one? Are all signers independent? If either answers is no, the score 5, otherwise score 0. O103 Automated Pausing: Does the project operate services that monitor the health of the protocol? <ul><li>No: Score 5.</li><li>Yes: The monitoring service contacts people who can pause the project if unexpected behavior is detected: Score 4.</li><li>Yes: The monitoring service has the ability to pause the protocol if unexpected behavior is detected: Score 3.</li><li>Yes: The monitoring service contacts people who can pause the project and has the ability to pause the protocol if unexpected behavior is detected: Score 0.</li></ul> O104 Geographic separation of pausers: Are people who can pause the project spread across time zones? <ul><li>No: Score 2.</li><li>Across multiple timezones, but not complete coverage: Score 1.</li><li>Full coverage: Follow the sun support: Score 0.</li></ul> O105 Shared keys: Are any accounts / private keys used for pausing the protocol shared with multiple people. If yes, score 10. If no, score 0. <p>Rationale for scoring:</p> <ul> <li>The ideal configuration is Role Based Access Control, with active monitoring and a geographically dispersed support team. For decentralized projects, in addition to the automated monitoring system, pausing could be controlled a multisig wallet behind one or more of the accounts of the Role Based Access Control.</li> <li>Shared keys indicates poor security management. This indicates that there may be other poor practices in the system that are not known.</li> </ul>"},{"location":"framework/30scoring/operational/#vulnerability-response-planning-score","title":"Vulnerability Response Planning Score","text":"<p>Vulnerability Response Planning is defined by the ability to meet the properties defined in the  Vulnerability Response Planning section. The equation for the Vulnerability Response Planning Score is:</p> <pre><code>Vulnerability Response Planning Score = O501 + O502 + O503 + O504\n</code></pre> <p>The Vulnerability Response Planning Score ranges from 0 to 10.</p> Question ID Question O501 Is there a defined Vulnerability Response Virtual Team? If yes, score 0, otherwise score 1. O502 Is there a vulnerability reporting mechanism that allows issues to be reported without making them public? If yes, score 0, otherwise score 3. O503 Is there a defined triage process for vulnerabilities?  If yes, score 0, otherwise score 1. O504 Can vulnerabilities fixes be deployed without needing to put code into a public repository? If yes, score 0, otherwise score 4. O505 Are Root Cause Analyses published? If yes, score 0, otherwise score 1. <p>Rationale for scoring:</p> <ul> <li>It is important that vulnerabilities can be reported, and then vulnerability fixes worked on, and then deployed without having to make them public. </li> </ul>"},{"location":"framework/30scoring/overview/","title":"Overview","text":""},{"location":"framework/30scoring/overview/#risk-scoring-overview","title":"Risk Scoring Overview","text":"<p>The overall risk score is calculated as the maximum of the risk scores of each of the categories:</p> <pre><code>Overall Risk Score = Maximum of (Network Consensus Risk, Architectural Risk, Implementation Risk, and Operational Risk)\n</code></pre> <p>All of the risk scores range from 0 to 100, where 0 is a perfect score. That is, a low risk project will have a low risk score. The rationale for using the worst risk score (maximum value) across the categories is that a weakness in any part of a crosschain project render the entire project vulnerable to attack.</p>"},{"location":"framework/30scoring/scoring/","title":"Risk Scores","text":"<p>This section provides a model for developing a risk score for a project based on the answer to many questions. The score is a combination of the network consensus, architectural, implementation, and operational risks. A protocol that scores well in all categories will have a high overall score. However, a protocol that scores well in three of the four categories, but scores very poorly in one, will have a low overall score. This reflects how risks materialize in Web3 projects: small single point issues can cause great projects to suffer catastrophic failures. </p> <p>How the risk score questions below are answered is subjective. Whereas one person may interpret that a project has complied with a certain consideration, and hence should answer, \"yes\" to a question, someone else may feel that the project partially complies, and hence the answer should be \"no\".</p> <p>A project will receive different scores depending on the information available to the person reviewing the project. As such, it might be expected that a project team that has all the information about a project available to them may be able to score a project accurately. However, a user or external reviewer may not have all of the information available, and may have to make some assumptions. The internal project team may not have adequate perspective or experience to review their own project, hence, even a project team may not be able to provide a completely accurate score. </p> <p>A project is likely to receive different scores over time. Based on this risk framework, the project team may take steps to improve their score. Issues that have been undetected could surface and reduce the project's score. Additionally, a project team might issue an upgrade of their protocol. This could invalidate the projects previous risk score. </p> <p>Determining the trustworthiness of one crosschain protocol relative to other protocols is an extremely complex task. This risk score model below is just a very preliminary step. Please provide feedback to help us improve this scoring system.</p>"},{"location":"framework/30scoring/scoring/#risk-scoring-overview","title":"Risk Scoring Overview","text":"<p>The overall risk score is calculated as the maximum of the risk scores of each of the categories:</p> <pre><code>Overall Risk Score = Maximum of (Network Consensus Risk, Architectural Risk, Implementation Risk, and Operational Risk)\n</code></pre> <p>All of the risk scores range from 0 to 100, where 0 is a perfect score. That is, a low risk project will have a low risk score. The rationale for using the worst risk score (maximum value) across the categories is that a weakness in any part of a crosschain project render the entire project vulnerable to attack.</p>"},{"location":"framework/30scoring/scoring/#network-consensus-risk-scoring","title":"Network Consensus Risk Scoring","text":"<p>The Network Consensus Risk Score assesses the risk posed by the Network Consensus properties of the blockchains being bridged.</p> <p>The equation for the Network Consensus Risk Score is:</p> <pre><code>Network Consensus Risk Score = (N001 + N002 + N003 + N004) x 10 / 17\n</code></pre> Question ID Question N001 Finality: Does the crosschain protocol wait for transactions to be final on the source chain prior to acting upon them? <ul><li> Transactions are final: Score 0. </li><li>Transactions are probably final, assuming the maximum sized attack possible with US$100M rented hardware, with a probability of greater than one in 1,000,000,000,000: Score 0.</li><li>Transactions are probably final, assuming the maximum sized attack possible with US$100M rented hardware, with a probability of greater than one in 1,000,000,000: Score 3. </li><li>Transactions are probably final, assuming the maximum sized attack possible with US$100M rented hardware, with a probability of greater than one in 1,000,000: Score 4.</li><li>Transactions are probably final, assuming the maximum sized attack possible with US$100M rented hardware, with a probability of less than one in 1,000,000: Score 5.</li></ul> N002 Network Delays and Liveness Reliability: Has the source chain been offline (excluding planned network upgrades)? <ul><li>Never: Score 0.</li><li>Once in the past year for an hour or less: Score 3.</li><li>More than once in the past year or just once but for longer than an hour: Score 5.</li></ul> N003 Network Delays and Liveness Congestion: Has the source chain been congested such that transactions can not be submitted and included in the blockchain? <ul><li>Never: Score 0.</li><li>Once in the past year for an hour or less: Score 1.</li><li>More than once in the past year or just once but for longer than an hour: Score 2.</li></ul> N004 Network Safety Violations: Has the source chain had any safety violations? <ul><li>Never: Score 0.</li><li>Once in the past year: Score 4.</li><li>More than once in the past year: Score 5.</li></ul> <p>Rationale for scoring:</p> <ul> <li>The ideal configuration is a protocol that only uses information based on transaction that are final on the source chain, and the source chain has never has any liveness or safety issues.</li> </ul>"},{"location":"framework/30scoring/scoring/#architectural-risk-scoring","title":"Architectural Risk Scoring","text":"<p>No aspects of Architectural Risk have been considered when determining the Architectural Risk Score.</p> <p>The equation for the Architecture Risk Score is:</p> <pre><code>Architectural Risk Score = 0\n</code></pre>"},{"location":"framework/30scoring/scoring/#implementation-risk-scoring","title":"Implementation Risk Scoring","text":"<p>Implementation Risk Scoring is based on the Implementation Risk section.</p> <p>The equation for the Implementation Risk Score is:</p> <pre><code>Implementation Risk Score = Maximum of (Reducing Implementation Risk Score, Uncovering Extant Risk Score, and Responding to Materialized Risk Score)\n</code></pre>"},{"location":"framework/30scoring/scoring/#reducing-implementation-risk","title":"Reducing Implementation Risk","text":"<pre><code>Reducing Implementation Risk Score = \n Mixing of Control and Data Plane Risk Score +\n Role Based Access Control Risk Score +\n Upgradable Risk Score +\n Secret Storage Risk Score +\n Product Development Maturity Risk Score +\n Well Known Platform Risk Score +\n Well Known Smart Contract Programming Language Risk Score\n</code></pre>"},{"location":"framework/30scoring/scoring/#mixing-of-control-and-data-plane-risk-score","title":"Mixing of Control and Data Plane Risk Score","text":"<p>Mixing of Control and Data Plane is described in the  Mixing of Control and Data Plane section. If the Control and Data Plane are mixed, then the Mixing of Control and Data Plane Risk Score is 20, or 0 otherwise.</p> <p>The Control and Data Plane are considered mixed if the answer to any of the following questions is yes:</p> <ul> <li>Can Control Plane functions be called from Data Plane functions without some additional authentication checks?</li> <li>If Control Plane messages are sent across the crosschain communications channel, are Control Plane messages signed by the same keys as Data Plane messages?</li> </ul>"},{"location":"framework/30scoring/scoring/#role-based-access-control-risk-score","title":"Role Based Access Control Risk Score","text":"<p>Role Based Access Control is described in the Role Based Access Control section.</p> <p>The Role Based Access Control Risk Score depends on the permissioned control / ownership of the bridge contracts. If there are multiple contracts, and they  are configured differently, then score the highest score.</p> <ul> <li>There is no permissioned ownership feature: Score 0.</li> <li>There a single EOA as the owner: Score 10.</li> <li>Role Based Access Control has been implemented: Score 0.</li> <li>There is no Role Based Access Control, but a threshold number of signers need to approve administrative actions. If number of signers is five or more score 3, otherwise score 5. Additionally, if the number of signers that need to sign is more than 50%, score 0, otherwise score 5.</li> </ul>"},{"location":"framework/30scoring/scoring/#upgradable-risk-score","title":"Upgradable Risk Score","text":"<p>Upgradable Risk is decribed in the Upgradability section.</p> <p>The risks associated with being able to upgrade contracts appear to be similar to the risks associated with not being able to upgrade a contract. As such, the Upgradable Risk Score is always 0.</p>"},{"location":"framework/30scoring/scoring/#secret-storage-risk-score","title":"Secret Storage Risk Score","text":"<p>Secret Storage is described in the Secret Storage section. The Secret Storage Risk Score is defined by the equation below.</p> <pre><code>Secret Storage Risk Score = I401\n</code></pre> Question ID Question I401 Are any private keys, symmetric keys, passwords, or passcodes used in the project stored on disk in a plain text file? If yes, score 20, if no score 0."},{"location":"framework/30scoring/scoring/#product-development-maturity-risk-score","title":"Product Development Maturity Risk Score","text":"<p>Product Development Maturity is described in the Product Development Maturity section. The Product Development Maturity Risk Score is defined by the equation below.</p> <pre><code>Product Development Maturity Risk Score = I501\n</code></pre> Question ID Question I501 Does the organisation building the project have a documented SDLC approach? If yes, score 0, if no score 20."},{"location":"framework/30scoring/scoring/#well-known-platform-risk-score","title":"Well Known Platform Risk Score","text":"<p>The risks associated with not using Well Known Platforms is contained in the Well Known Platform section.</p> <p>Scoring of this category has proven to be controvertial. At present, the risk score for this category is 0.</p>"},{"location":"framework/30scoring/scoring/#well-known-smart-contract-programming-language-risk-score","title":"Well Known Smart Contract Programming Language Risk Score","text":"<p>The risks associated with not using a Well Known Smart Contract Programming Language is contained in the Well Known Smart Contract Programming Language section. </p> <p>Scoring of this category has proven to be controvertial. At present, the risk score for this category is 0.</p>"},{"location":"framework/30scoring/scoring/#uncovering-extant-risk-score","title":"Uncovering Extant Risk Score","text":"<pre><code>Uncovering Extant Risk Score = \n Formal Verification Risk Score +\n Test Risk Score +\n Code Auditing Risk Score + \n Open Source Code Risk Score +\n Verified Code on Block Explorer Risk Score +\n Documentation Risk Score +\n Bug Bounty Risk Score \n</code></pre>"},{"location":"framework/30scoring/scoring/#formal-verification-risk-score","title":"Formal Verification Risk Score","text":"<p>The risks of not formally verifying code is contained in the Formal Verification section.</p> <p>The Formal Verification Risk Score is 5 if the code has not been formally verified, and 0 if it has been formally verified.</p>"},{"location":"framework/30scoring/scoring/#test-risk-score","title":"Test Risk Score","text":"<p>The risks associated with not thoroughly testing an application are described in the Testing section. The Test Risk Score is defined by the equation below.</p> <pre><code>Test Risk Score = I901 + I902 + I903 + I904 + I905 + I906 \n</code></pre> Question ID Question I901 Is there a test plan documenting which tests scenarios should be tested? If yes, score 0, if no score 10. I902 Are contracts unit tested? If yes, score 0, if no score 10. I903 Are their system tests that check the operation of the entire system? If yes, score 0, if no score 10. I904 Is their a continuous integration system that executes unit and system tests automatically on commit to a source code respository? If yes, score 0, if no score 10. I905 Are any of the tests executed by the continuous integration system unreliable (that is, some times unexpectedly fail)? If yes, score 5, if no score 0. I906 Can a product release occur if any test is failing? If yes, score 10, if no score 0."},{"location":"framework/30scoring/scoring/#code-auditing-risk-score","title":"Code Auditing Risk Score","text":"<p>Code auditing is described in detail in the Code Auditing section. The equation for the Code Auditing Risk Score is:</p> <pre><code>Code Audit Risk Score = I1011 + I1012 + I1014 + I1015 + I1013\n</code></pre> Question ID Question I1011 How many times has the on-chain components of the system been audited? If none, score 50, and score 0 for questions I1012, I1013, and I1014. If once score 10, if twice or more score 0. I1012 Has any version of the on-chain components of the system been audited by more than one audit organisation? If yes, score 0. If no, score 5. I1013 For the most recent audit, were all critical issues addressed? If yes, score 0. If no, score 10. I1014 Has the deployed version of the on-chain components of the system been audited? If yes, score 0. If no, score 20. I1015 Has any version of the off-chain components of the system been audited? If yes, score 0. If no, score 20. If the system contains no off-chain components, then score 0. <p>Rationale for scoring:</p> <ul> <li>Unaddressed critical issues could indicate vulnerabilites.</li> <li>Having an audit, addressing issues, and then deploying the revised code without re-auditing can result in vulnerabilities.</li> <li>The quality of audit firms is not factored in the score as this is very subjective. </li> </ul>"},{"location":"framework/30scoring/scoring/#open-source-code-risk-score","title":"Open Source Code Risk Score","text":"<p>The risks of not using open source code for a project are discussed in the Open Source Code section. The equation for the Open Source Code Risk Score is:</p> <pre><code>Open Source Code Risk Score = I1101 + I1102\n</code></pre> Question ID Question I1101 Is the source code of the project in a public code respository? If yes, score 0, otherwise score 10. I1102 Is it possible to develop code and deploy the project from a private repository? That is, can vulnerability fixes be resolved without publishing on the public code repsotory? If yes, score 0, otherwise score 20."},{"location":"framework/30scoring/scoring/#verified-code-on-block-explorer-risk-score","title":"Verified Code on Block Explorer Risk Score","text":"<p>The risks associated with not publishing code to blockchain explorers is covered in the  Verified Code on Block Explorer section. The equation for the Verified Code on Blockchain Explorer Risk Score is:</p> <pre><code>Verified Code on Block Explorer Risk Score = I1201\n</code></pre> Question ID Question I1201 Do all deployed contracts have verified code uploaded to block explorers? If yes, score 0, otherwise score 50."},{"location":"framework/30scoring/scoring/#documentation-risk-score","title":"Documentation Risk Score","text":"<p>The risks associated with not documenting a project well are discussed in the Documentation section. The equation for the Documentation Risk Score is:</p> <pre><code>Documentation Risk Score = I1301 + I1302 + I1303 + I1304 + I1305 + I1306\n</code></pre> Question ID Question I1301 Does the project have architectural documentation? If yes, score 0, otherwise score 5. I1302 Does the project have a documented threat model? If yes, score 0, otherwise score 5. I1303 Does the project have sequence diagrams for all major data flows? If yes, score 0, otherwise score 5. I1304 Are there code comments in smart contract code? If yes, score 0, otherwise score 20. I1305 Are there code comments in the off-chain code? If yes, score 0, otherwise score 5. I1306 Are there code comments in the test code? If yes, score 0, otherwise score 5."},{"location":"framework/30scoring/scoring/#bug-bounty-risk-score","title":"Bug Bounty Risk Score","text":"<p>Bug Bounties are described in detail in the Bug Bounty section. The equation for the Bug Bounty Risk Score is:</p> <pre><code>Bug Bounty Risk Score = I1401\n</code></pre> Question ID Question I1401 Is there a bug bounty for the project?  How big is the bug bounty? <ul><li>There is no bug bounty: Score 15.</li><li>Less than US$10,000: Score 5.</li><li>US$10,000 but less than US$100,000: Score 2.</li><li>More than US$100,000: Score 0.</li></ul>"},{"location":"framework/30scoring/scoring/#responding-to-materialized-risk-score","title":"Responding to Materialized Risk Score","text":"<pre><code>Responding to Materialized Risk Score = \n Ability to Pause Risk Score + \n Ability to Ban Addresses Risk Score\n</code></pre>"},{"location":"framework/30scoring/scoring/#ability-to-pause-risk-score","title":"Ability to Pause Risk Score","text":"<p>The ability to pause a project is described in the Ability to Pause Project section. The equation for the Ability to Pause Risk Score is:</p> <pre><code>Ability to Pause Score = I1501\n</code></pre> Question ID Question I1501 Can all data plane code paths be paused? If yes score 0, otherwise score 20."},{"location":"framework/30scoring/scoring/#ability-to-ban-addresses-risk-score","title":"Ability to Ban Addresses Risk Score","text":"<p>The ability to ban specific addresses is described in the Ability to Ban Addresses section. This capability is in contrast to the censorship resistance property that is of utmost importance to many protocols. So as to not downrank protocols that strive to provide censorship resistance over protocols that provide the ability to ban addresses, the ability to ban addresses is not scored. As such, the Ability to Ban Addresses Risk Score is always 0.</p>"},{"location":"framework/30scoring/scoring/#operational-risk-scoring","title":"Operational Risk Scoring","text":"<p>The following aspects of Operational Risk are currently not taken into account when assessing the Operational Risk Score: Decentralization of Operations, Diversity of Codebase, and Off-chain Security.</p> <p>The equation for the Operational Risk Score is:</p> <pre><code>Operational Risk Score = (Operational Security Score + Operational Ability to Pause Score + Vulnerability Response Planning Score) x 100 / 29 \n</code></pre>"},{"location":"framework/30scoring/scoring/#operational-security-score","title":"Operational Security Score","text":"<p>Operational Security is defined by the ability to meet the properties defined in the Operational Security section. The equation for the Operational Security Score is:</p> <pre><code>Operational Security Score = O001 + O002\n</code></pre> <p>The Operational Security Score ranges from 0 to 2.</p> Question ID Question O001 Has sensitive information as defined in the Operational Security section been identified? Has this information been documented? If yes, score 0. If no, score 1. O002 Is a complete Operational Security process, as described in the Operational Security section implemented? If yes, score 0. If no, score 1."},{"location":"framework/30scoring/scoring/#operational-ability-to-pause-score","title":"Operational Ability to Pause Score","text":"<p>The Operational Ability to Pause is defined by the ability to meet the properties defined in the Operational Ability to Pause section. The equation for the Operational Ability to Pause Score is:</p> <pre><code>Operational Ability to Pause Score = O101 + O103 + O104 + O105\n</code></pre> <p>The Operational Ability to Pause Score ranges from 0 to 27.</p> Question ID Question O101 Type of pausing access control: <ul><li>None: Score 10.</li><li>Single EOA controls pausing: Score 8.</li><li>Role Based Access Control with multiple accounts (EOA or contract): Score 5.</li><li>A multisig wallet controls pausing: Score is answer to Question ID O102.</li></ul> O102 Multisig Wallets: Is the threshold of the multisig wallet greater than one? Are all signers independent? If either answers is no, the score 5, otherwise score 0. O103 Automated Pausing: Does the project operate services that monitor the health of the protocol? <ul><li>No: Score 5.</li><li>Yes: The monitoring service contacts people who can pause the project if unexpected behavior is detected: Score 4.</li><li>Yes: The monitoring service has the ability to pause the protocol if unexpected behavior is detected: Score 3.</li><li>Yes: The monitoring service contacts people who can pause the project and has the ability to pause the protocol if unexpected behavior is detected: Score 0.</li></ul> O104 Geographic separation of pausers: Are people who can pause the project spread across time zones? <ul><li>No: Score 2.</li><li>Across multiple timezones, but not complete coverage: Score 1.</li><li>Full coverage: Follow the sun support: Score 0.</li></ul> O105 Shared keys: Are any accounts / private keys used for pausing the protocol shared with multiple people. If yes, score 10. If no, score 0. <p>Rationale for scoring:</p> <ul> <li>The ideal configuration is Role Based Access Control, with active monitoring and a geographically dispersed support team. For decentralized projects, in addition to the automated monitoring system, pausing could be controlled a multisig wallet behind one or more of the accounts of the Role Based Access Control.</li> <li>Shared keys indicates poor security management. This indicates that there may be other poor practices in the system that are not known.</li> </ul>"},{"location":"framework/30scoring/scoring/#vulnerability-response-planning-score","title":"Vulnerability Response Planning Score","text":"<p>Vulnerability Response Planning is defined by the ability to meet the properties defined in the  Vulnerability Response Planning section. The equation for the Vulnerability Response Planning Score is:</p> <pre><code>Vulnerability Response Planning Score = O501 + O502 + O503 + O504\n</code></pre> <p>The Vulnerability Response Planning Score ranges from 0 to 10.</p> Question ID Question O501 Is there a defined Vulnerability Response Virtual Team? If yes, score 0, otherwise score 1. O502 Is there a vulnerability reporting mechanism that allows issues to be reported without making them public? If yes, score 0, otherwise score 3. O503 Is there a defined triage process for vulnerabilities?  If yes, score 0, otherwise score 1. O504 Can vulnerabilities fixes be deployed without needing to put code into a public repository? If yes, score 0, otherwise score 4. O505 Are Root Cause Analyses published? If yes, score 0, otherwise score 1. <p>Rationale for scoring:</p> <ul> <li>It is important that vulnerabilities can be reported, and then vulnerability fixes worked on, and then deployed without having to make them public. </li> </ul>"},{"location":"reference/ref/","title":"Reference","text":"<p>The Crosschain Risk Framework builds on the authors experience in  the crosschain and bridges space. We suggest readers new to the space consider the following works on crosschain communications.</p> <ul> <li>Arjun Chand, With Bridges, Trust is a Spectrum: A Quantified Framework, (2022), https://blog.li.fi/with-bridges-trust-is-a-spectrum-a-quantified-framework-57d2dd622cfd</li> <li>Bartek Kiepuszewski, Viabhav Chellani, L2Bridge Risk Framework, https://gov.l2beat.com/t/l2bridge-risk-framework/31</li> <li>Joel John, Assessing Blockchain Bridges, (2022), https://mirror.xyz/0xD4977DF3e967ddb604bB4f4D0d263f69B6c8A3e4/uPhBOMcQQ-TeY2n0naf3M8aLQnb04X2YcO41eaWpFN4</li> <li>Weijia Zhang, Peter Robinson, Aiman Baharna, EEA CIW - Crosschain Security Guidelines Version 1.0, Tech. rep., Enterprise Ethereum Alliance (2021), https://entethalliance.github.io/crosschain-interoperability/crosschainsecurityguidelines.html</li> <li>Ermyas Abebe, Security of Crosschain Transactions and Bridges, YouTube, (2022) https://www.youtube.com/watch?v=DJyEJVaXMNo</li> <li>Peter Robinson, Blockchain / Crosschain / DeFi Bridge Design, YouTube, (2021), https://www.youtube.com/watch?v=zq4cbS3q-lY</li> <li>Arjun Chand, Navigating Arbitrary Messaging Bridges: A Comparison Framework, (2022), https://blog.li.fi/navigating-arbitrary-messaging-bridges-a-comparison-framework-8720f302e2aa</li> <li>Vitalik Buterin, Chain interoperability., R3 Res. (2016), https://www.r3.com/wp-content/uploads/2017/06/chain_interoperability_r3.pdf</li> <li>Sandra Johnson, Peter Robinson, John Brainard, Sidechains and interoperability, ArXiv e-prints (2019). https://arxiv.org/abs/1903.04077</li> <li>Peter Robinson, Survey of crosschain communications protocols, Elsevier's Computer Networks (2021). https://doi.org/10.1016/j.comnet.2021.108488.</li> <li>Rafael Belchior, A survey on blockchain interoperability: Past, present, and future trends, CoRR, (2020) https://arxiv.org/abs/2005.14282</li> <li>Alexei Zamyatin, Mustafa Al-Bassam, Dionysis Zindros, Eleftherios Kokoris-Kogias, Pedro Moreno-Sanchez, Aggelos Kiayias, William Knottenbelt, SoK: Communication Across Distributed Ledgers, Financial Cryptography and Data Security (2021), https://fc21.ifca.ai/papers/139.pdf</li> <li>Peter Robinson, Crosschain Communications: Blockchain Discovery, Atomic Crosschain Function Calls, and Blockchain State Pinning, University of Queensland (2022), https://espace.library.uq.edu.au/data/UQ_250c9d2/s4461812_phd_thesis.pdf</li> </ul>"}]}